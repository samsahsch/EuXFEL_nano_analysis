{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1746583d",
   "metadata": {},
   "source": [
    "Implemented hit selection, events scatter, ion heatmap, electrons time of flight, ions time of flight, merging multiple runs, spatial selection view, calibration choice of lines with corresponding zoomed-in views, calibration curve fit and apply with mq column, make multiple threshold selections, spatial selection view with angle, fish plots, binning by number of events, choose appropriate binning for mq and ion tof, background with multiple runs downsampled to selected number of pulses, waterfall plots, heatmaps for binned number of events, normalized absolute plots, waterfall plots for electrons, improved fish plots, correlation mq heatmap by numpy cov, correlation etof and ion tof heatmap by numpy cov, 1d correlation mq plot by numpy cov, correlation mq heatmap with taran code, partial correlation mq heatmap, partial correlation mq heatmap with varying alpha, incorporate ion merging, nevents_binning for ion only, big mq plot.\n",
    "\n",
    "Additions:\n",
    "\n",
    "pulse filtering\n",
    "fixes covariances\n",
    "improves histograms\n",
    "new plots\n",
    "fixes bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956d22d",
   "metadata": {},
   "source": [
    "Need to install reading methods the first time:\n",
    "\n",
    "pip install --user tables   ### to read dataframe\n",
    "pip install h5netcdf        ### to read xarrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7c8b9",
   "metadata": {},
   "source": [
    "# Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea9e54",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab55594",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "TIME_BETWEEN_PULSES = 3.54462e-6\n",
    "CHANNELS_PER_PULSE = 14080\n",
    "\n",
    "\n",
    "    \n",
    "def read(runid):\n",
    "    'Read the preprocessed data of run with ID runid saved in the h5 file with a corresponding name'\n",
    "    'Outputs dataframes per event, per pulse, and xarrays etof, pnccd in that order'\n",
    "    \n",
    "    filename = '../preprocess/datarun' + str(runid) + '.h5'\n",
    "    \n",
    "    dfevent = pd.read_hdf(filename, 'dfevent')\n",
    "    dfpulse = pd.read_hdf(filename, 'dfpulse')\n",
    "    \n",
    "    etof = xr.open_dataarray(filename, group=\"etof\")\n",
    "    pnccd = xr.open_dataarray(filename, group=\"pnccd\")\n",
    "    \n",
    "    return dfevent, dfpulse, etof, pnccd\n",
    "\n",
    "\n",
    "\n",
    "def events_selection(runs,thresholds,num_pulses=None):\n",
    "    'Reads one or multiple runs from h5 files'\n",
    "    'Makes a pulse selection based on the number of events per pulse between the defined thresholds'\n",
    "    'If multiple runs are passed, will merge the runs, once hit selected'\n",
    "    'Thresholds can be between one and three tuples (lower threshold, upper threshold)'\n",
    "    'Downsamples by num_pulses'\n",
    "    \n",
    "    lower_threshold1, upper_threshold1 = thresholds[0]\n",
    "    selected_dfevents1 = list()\n",
    "    selected_dfpulses1 = list()\n",
    "    selected_etofs1 = list()\n",
    "    \n",
    "    if len(thresholds) > 1:\n",
    "        lower_threshold2, upper_threshold2 = thresholds[1]\n",
    "        selected_dfevents2 = list()\n",
    "        selected_dfpulses2 = list()\n",
    "        selected_etofs2 = list()\n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        lower_threshold3, upper_threshold3 = thresholds[2]  \n",
    "        selected_dfevents3 = list()\n",
    "        selected_dfpulses3 = list()\n",
    "        selected_etofs3 = list()\n",
    "    \n",
    "    dataframes = dict()\n",
    "    \n",
    "    if type(num_pulses) == int:\n",
    "        num_pulses_run = int(num_pulses/len(runs))\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        dfevent, dfpulse, etof, pnccd = read(run)\n",
    "        \n",
    "        selections = list()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.scatter(dfpulse.pulseId,dfpulse.nevents_pulse,c='black',label='All pulses')\n",
    "        \n",
    "        if type(num_pulses) == int:\n",
    "            dfpulse = dfpulse.sample(n=num_pulses_run)\n",
    "            \n",
    "        selected_dfpulse1 = dfpulse[lower_threshold1 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold1]\n",
    "        selected_dfevent1 = dfevent[dfevent.pulseId.isin(selected_dfpulse1.pulseId)]\n",
    "        selected_etof1 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse1.pulseId))\n",
    "        selections.append((selected_dfevent1, selected_dfpulse1, selected_etof1))\n",
    "        plt.scatter(selected_dfpulse1.pulseId,selected_dfpulse1.nevents_pulse,c='r',label=f'Between {lower_threshold1} and {upper_threshold1}')\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            \n",
    "            selected_dfpulse2 = dfpulse[lower_threshold2 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold2]\n",
    "            selected_dfevent2 = dfevent[dfevent.pulseId.isin(selected_dfpulse2.pulseId)]\n",
    "            selected_etof2 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse2.pulseId))\n",
    "            selections.append((selected_dfevent2, selected_dfpulse2, selected_etof2))\n",
    "            plt.scatter(selected_dfpulse2.pulseId,selected_dfpulse2.nevents_pulse,c='blue',label=f'Between {lower_threshold2} and {upper_threshold2}')\n",
    "            \n",
    "        if len(thresholds) > 2:\n",
    "            \n",
    "            selected_dfpulse3 = dfpulse[lower_threshold3 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold3]\n",
    "            selected_dfevent3 = dfevent[dfevent.pulseId.isin(selected_dfpulse3.pulseId)]\n",
    "            selected_etof3 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse3.pulseId))\n",
    "            selections.append((selected_dfevent3, selected_dfpulse3, selected_etof3))\n",
    "            plt.scatter(selected_dfpulse3.pulseId,selected_dfpulse3.nevents_pulse,c='g',label=f'Between {lower_threshold3} and {upper_threshold3}')  \n",
    "        \n",
    "        dataframes[run] = selections\n",
    "          \n",
    "        plt.xlabel('Pulse ID')\n",
    "        plt.ylabel('Number of events per pulse')\n",
    "        plt.legend()\n",
    "        plt.title(f'Events per pulse with respect to pulse ID for run {run}')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    for key, values in dataframes.items():\n",
    "        \n",
    "        selected_dfevents1.append(values[0][0])\n",
    "        selected_dfpulses1.append(values[0][1])\n",
    "        selected_etofs1.append(values[0][2])\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            selected_dfevents2.append(values[1][0])\n",
    "            selected_dfpulses2.append(values[1][1])\n",
    "            selected_etofs2.append(values[1][2])\n",
    "            \n",
    "        if len(thresholds) > 2: \n",
    "            selected_dfevents3.append(values[2][0])\n",
    "            selected_dfpulses3.append(values[2][1])\n",
    "            selected_etofs3.append(values[2][2])\n",
    "        \n",
    "        \n",
    "    merged_selection = list()\n",
    "    \n",
    "    merged_dfevent1 = pd.concat(selected_dfevents1)\n",
    "    merged_dfevent1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_dfpulse1 = pd.concat(selected_dfpulses1)\n",
    "    merged_dfpulse1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_etof1 = xr.concat(selected_etofs1, dim='pulseId')\n",
    "    \n",
    "    merged_selection.append((merged_dfevent1, merged_dfpulse1, merged_etof1))\n",
    "    \n",
    "    print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold1} and {upper_threshold1} events: {len(merged_dfpulse1)}\")\n",
    "       \n",
    "        \n",
    "    if len(thresholds) > 1:\n",
    "        merged_dfevent2 = pd.concat(selected_dfevents2)\n",
    "        merged_dfevent2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse2 = pd.concat(selected_dfpulses2)\n",
    "        merged_dfpulse2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_etof2 = xr.concat(selected_etofs2, dim='pulseId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent2, merged_dfpulse2, merged_etof2))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold2} and {upper_threshold2} events: {len(merged_dfpulse2)}\")\n",
    "    \n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        merged_dfevent3 = pd.concat(selected_dfevents3)\n",
    "        merged_dfevent3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse3 = pd.concat(selected_dfpulses3)\n",
    "        merged_dfpulse3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_etof3 = xr.concat(selected_etofs3, dim='pulseId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent3, merged_dfpulse3, merged_etof3))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold3} and {upper_threshold3} events: {len(merged_dfpulse3)}\")\n",
    "        \n",
    "    \n",
    "    return merged_selection\n",
    "\n",
    "\n",
    "\n",
    "def read_ion(runid):\n",
    "    'Read the preprocessed data of run with ID runid saved in the h5 file with a corresponding name'\n",
    "    'Outputs dataframes per event and per pulse'\n",
    "    \n",
    "    filename = '../preprocess/datarun' + str(runid) + '.h5'\n",
    "    \n",
    "    dfevent = pd.read_hdf(filename, 'dfevent')\n",
    "    dfpulse = pd.read_hdf(filename, 'dfpulse')\n",
    "    \n",
    "    return dfevent, dfpulse\n",
    "\n",
    "\n",
    "\n",
    "def ion_selection(runs,thresholds,num_pulses=None):\n",
    "    'Only handles ion data'\n",
    "    'Reads one or multiple runs from h5 files'\n",
    "    'Makes a pulse selection based on the number of events per pulse between the defined thresholds'\n",
    "    'If multiple runs are passed, will merge the runs, once hit selected'\n",
    "    'Thresholds can be between one and three tuples (lower threshold, upper threshold)'\n",
    "    'Downsamples by num_pulses'\n",
    "    \n",
    "    lower_threshold1, upper_threshold1 = thresholds[0]\n",
    "    selected_dfevents1 = list()\n",
    "    selected_dfpulses1 = list()\n",
    "    \n",
    "    if len(thresholds) > 1:\n",
    "        lower_threshold2, upper_threshold2 = thresholds[1]\n",
    "        selected_dfevents2 = list()\n",
    "        selected_dfpulses2 = list()\n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        lower_threshold3, upper_threshold3 = thresholds[2]  \n",
    "        selected_dfevents3 = list()\n",
    "        selected_dfpulses3 = list()\n",
    "    \n",
    "    dataframes = dict()\n",
    "    \n",
    "    if type(num_pulses) == int:\n",
    "        num_pulses_run = int(num_pulses/len(runs))\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        print('Handling run', run)\n",
    "        dfevent, dfpulse = read_ion(run)\n",
    "        \n",
    "        selections = list()\n",
    "        \n",
    "        if type(num_pulses) == int:\n",
    "            dfpulse = dfpulse.sample(n=num_pulses_run)\n",
    "            \n",
    "        selected_dfpulse1 = dfpulse[lower_threshold1 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold1]\n",
    "        selected_dfevent1 = dfevent[dfevent.pulseId.isin(selected_dfpulse1.pulseId)]\n",
    "        selections.append((selected_dfevent1, selected_dfpulse1))\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            \n",
    "            selected_dfpulse2 = dfpulse[lower_threshold2 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold2]\n",
    "            selected_dfevent2 = dfevent[dfevent.pulseId.isin(selected_dfpulse2.pulseId)]\n",
    "            selections.append((selected_dfevent2, selected_dfpulse2))\n",
    "            \n",
    "        if len(thresholds) > 2:\n",
    "            \n",
    "            selected_dfpulse3 = dfpulse[lower_threshold3 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold3]\n",
    "            selected_dfevent3 = dfevent[dfevent.pulseId.isin(selected_dfpulse3.pulseId)]\n",
    "            selections.append((selected_dfevent3, selected_dfpulse3))\n",
    "        \n",
    "        dataframes[run] = selections\n",
    "\n",
    "        \n",
    "    for key, values in dataframes.items():\n",
    "        \n",
    "        selected_dfevents1.append(values[0][0])\n",
    "        selected_dfpulses1.append(values[0][1])\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            selected_dfevents2.append(values[1][0])\n",
    "            selected_dfpulses2.append(values[1][1])\n",
    "            \n",
    "        if len(thresholds) > 2: \n",
    "            selected_dfevents3.append(values[2][0])\n",
    "            selected_dfpulses3.append(values[2][1])\n",
    "        \n",
    "        \n",
    "    merged_selection = list()\n",
    "    \n",
    "    merged_dfevent1 = pd.concat(selected_dfevents1)\n",
    "    merged_dfevent1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_dfpulse1 = pd.concat(selected_dfpulses1)\n",
    "    merged_dfpulse1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_selection.append((merged_dfevent1, merged_dfpulse1))\n",
    "    \n",
    "    print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold1} and {upper_threshold1} events: {len(merged_dfpulse1)}\")\n",
    "       \n",
    "        \n",
    "    if len(thresholds) > 1:\n",
    "        merged_dfevent2 = pd.concat(selected_dfevents2)\n",
    "        merged_dfevent2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse2 = pd.concat(selected_dfpulses2)\n",
    "        merged_dfpulse2.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        merged_selection.append((merged_dfevent2, merged_dfpulse2))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold2} and {upper_threshold2} events: {len(merged_dfpulse2)}\")\n",
    "    \n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        merged_dfevent3 = pd.concat(selected_dfevents3)\n",
    "        merged_dfevent3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse3 = pd.concat(selected_dfpulses3)\n",
    "        merged_dfpulse3.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        merged_selection.append((merged_dfevent3, merged_dfpulse3))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold3} and {upper_threshold3} events: {len(merged_dfpulse3)}\")\n",
    "        \n",
    "    \n",
    "    return merged_selection\n",
    "\n",
    "\n",
    "\n",
    "def heatmap(dfevent):\n",
    "    'Creates heatmap of the ions hits, based on a dfevent dataframe'\n",
    "    \n",
    "    counts_df = dfevent.groupby(['x', 'y']).size().reset_index(name='count')\n",
    "    heatmap_data = counts_df.pivot(index='y', columns='x', values='count')\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = sns.heatmap(heatmap_data, cmap='viridis',cbar_kws={'label': 'Number of events'})\n",
    "    plt.title('Ion heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "def ion_tof(dfevent):\n",
    "    'Plots ion time of flight data using dfevent dataframe'\n",
    "    \n",
    "    bounded_dfevent = dfevent[dfevent.tof < TIME_BETWEEN_PULSES]\n",
    "    hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=1000)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(bin_edges[:-1], hist)\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Number of hits per bin')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.show()   \n",
    "    \n",
    "    \n",
    "    \n",
    "def e_tof(etof):\n",
    "    'Plots electron time of flight data using etof xarray data'\n",
    "    \n",
    "    channel_time = TIME_BETWEEN_PULSES/CHANNELS_PER_PULSE\n",
    "    \n",
    "    xaxis = np.arange(14080)*channel_time\n",
    "    avg_selected_etof = -np.mean(etof, axis=0)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(xaxis,avg_selected_etof/max(avg_selected_etof))\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Normalized signal')\n",
    "    plt.title('Electrons time of flight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def events_selection_plots(runs,thresholds,downsampling=None):\n",
    "    'Runs functions events_selection, heatmap, e_tof, ion_tof'\n",
    "    'Downsamples by downsampling integer value if one is given'\n",
    "    \n",
    "    selections = events_selection(runs,thresholds,downsampling)\n",
    "    \n",
    "    print(f'\\n Plots for selection between {thresholds[0][0]} and {thresholds[0][1]} events:')\n",
    "    selected_dfevent1, selected_dfpulse1, selected_etof1 = selections[0]\n",
    "    heatmap(selected_dfevent1)\n",
    "    ion_tof(selected_dfevent1)\n",
    "    e_tof(selected_etof1)\n",
    "    \n",
    "    if len(selections) > 1:\n",
    "        print(f'Plots for selection between {thresholds[1][0]} and {thresholds[1][1]} events:')\n",
    "        selected_dfevent2, selected_dfpulse2, selected_etof2 = selections[1]\n",
    "        heatmap(selected_dfevent2)\n",
    "        ion_tof(selected_dfevent2)\n",
    "        e_tof(selected_etof2)\n",
    "    \n",
    "    elif len(selections) > 2:\n",
    "        print(f'Plots for selection between {thresholds[2][0]} and {thresholds[2][1]} events:')\n",
    "        selected_dfevent3, selected_dfpulse3, selected_etof3 = selections[2]\n",
    "        heatmap(selected_dfevent3)\n",
    "        ion_tof(selected_dfevent3)\n",
    "        e_tof(selected_etof3)\n",
    "    \n",
    "    return selections\n",
    "\n",
    "\n",
    "\n",
    "def pulse_filtered_ion_tof(dfevent,pulse_number=None,xlim=TIME_BETWEEN_PULSES):\n",
    "    'Plots ion time of flight data using dfevent dataframe'\n",
    "    \n",
    "    if pulse_number != None:\n",
    "        pulse_filtered_dfevent = dfevent[dfevent.pulseId.astype(str).str.endswith(pulse_number)]\n",
    "    else:\n",
    "        pulse_filtered_dfevent = dfevent\n",
    "    \n",
    "    bounded_dfevent = pulse_filtered_dfevent[pulse_filtered_dfevent.tof < TIME_BETWEEN_PULSES]\n",
    "    hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=1000)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(bin_edges[:-1], hist/max(hist))\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Normalized signal')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.xlim(0,xlim)\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(bin_edges[:-1], hist/max(hist))\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Normalized signal')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.xlim(0,TIME_BETWEEN_PULSES)\n",
    "    plt.yscale('log')\n",
    "    plt.show()  \n",
    "    \n",
    "    \n",
    "    \n",
    "def heatmap_with_zones(dfevent,zones):\n",
    "    'Creates heatmap of the ions hits, based on a dfevent dataframe'\n",
    "    'Draws a rectangle around zones defined by a list of tuples where each tuple represents a tilted zone (xstart, ystart, width, height, angle in degrees)'\n",
    "    \n",
    "    counts_df = dfevent.groupby(['x', 'y']).size().reset_index(name='count')\n",
    "    heatmap_data = counts_df.pivot(index='y', columns='x', values='count')\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = sns.heatmap(heatmap_data, cmap='viridis', cbar_kws={'label': 'Number of events'})\n",
    "    \n",
    "    xlim = int(ax.get_xticklabels()[0].get_text())\n",
    "    ylim = int(ax.get_yticklabels()[0].get_text())\n",
    "\n",
    "    for zone in zones:\n",
    "        x, y, width, height, angle = zone\n",
    "        x_adjusted = x - xlim\n",
    "        y_adjusted = y - ylim\n",
    "        \n",
    "        rect = plt.Rectangle((x_adjusted, y_adjusted), width, height, fill=False, edgecolor='red', lw=1, angle=angle)\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.title('Ion heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "        \n",
    "def spatial_ion_selection(dfevent,dfpulse,etof,zones):\n",
    "    'Square selection from the heatmap using spatial coordinates'\n",
    "    'Zone is a tuple representing a zone that is not tilted (xstart, ystart, width, height)'\n",
    "    'Returns spatially selected dfevent,dfpulse,etof'\n",
    "    \n",
    "    heatmap_with_zones(dfevent,zones)\n",
    "    \n",
    "    selected_dfevents = []\n",
    "    \n",
    "    for zone in zones:\n",
    "        \n",
    "        xstart,ystart,width,height,angle = zone\n",
    "    \n",
    "        spatial_selected_dfevent = dfevent[dfevent.x > xstart][dfevent.x < xstart+width][dfevent.y > ystart][dfevent.y < ystart+height]\n",
    "        selected_dfevents.append(spatial_selected_dfevent)\n",
    "        \n",
    "    merged_dfevent = pd.concat(selected_dfevents)\n",
    "    merged_dfevent.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    spatial_selected_dfpulse = dfpulse[dfpulse.pulseId.isin(merged_dfevent.pulseId)]\n",
    "    spatial_selected_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(merged_dfevent.pulseId))\n",
    "    \n",
    "    return merged_dfevent,spatial_selected_dfpulse,spatial_selected_etof\n",
    "\n",
    "\n",
    "\n",
    "def big_ion_tof(dfevent):\n",
    "    'Plots widget of big ion time of flight data using dfevent dataframe'\n",
    "    \n",
    "    bounded_dfevent = dfevent[dfevent.tof < TIME_BETWEEN_PULSES]\n",
    "    hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=1000)\n",
    "    \n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.plot(bin_edges[:-1], hist, c='g')\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Number of hits per bin')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    \n",
    "def autoscale_y(ax,margin=0.1):\n",
    "    \"\"\"This function rescales the y-axis based on the data that is visible given the current xlim of the axis.\n",
    "    ax -- a matplotlib axes object\n",
    "    margin -- the fraction of the total height of the y-data to pad the upper and lower ylims\"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    def get_bottom_top(line):\n",
    "        xd = line.get_xdata()\n",
    "        yd = line.get_ydata()\n",
    "        lo,hi = ax.get_xlim()\n",
    "        y_displayed = yd[((xd>lo) & (xd<hi))]\n",
    "        h = np.max(y_displayed) - np.min(y_displayed)\n",
    "        bot = np.min(y_displayed)-margin*h\n",
    "        top = np.max(y_displayed)+margin*h\n",
    "        return bot,top\n",
    "\n",
    "    lines = ax.get_lines()\n",
    "    bot,top = np.inf, -np.inf\n",
    "\n",
    "    for line in lines:\n",
    "        new_bot, new_top = get_bottom_top(line)\n",
    "        if new_bot < bot: bot = new_bot\n",
    "        if new_top > top: top = new_top\n",
    "\n",
    "    ax.set_ylim(bot,top)\n",
    "    \n",
    "    \n",
    "    \n",
    "def zoomed_ion_tof(dfevent,anchor):\n",
    "    'Plots zoom around anchor point of ion time of flight data using dfevent dataframe'\n",
    "    \n",
    "    bounded_dfevent = dfevent[dfevent.tof < TIME_BETWEEN_PULSES]\n",
    "    hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=1000)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(bin_edges[:-1], hist, c='g')\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Number of hits per bin')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.xlim(anchor-1e-7,anchor+1e-7)\n",
    "    autoscale_y(ax)\n",
    "    ax.axvline(x=anchor, color='black', linestyle='--')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def power_law(x, a, b):\n",
    "    'Calibration fit power law'\n",
    "    return a * x**b\n",
    "\n",
    "\n",
    "\n",
    "def compute_calibration(calibration_lines):\n",
    "\n",
    "    # Corresponding m/q argon values\n",
    "    mq_lines = [40,20,40/3,40/4,40/5]\n",
    "    \n",
    "    # Initial guesses for parameters a and b\n",
    "    initial_guess = [1.6e13, 2]\n",
    "\n",
    "    # Perform the curve fitting\n",
    "    params, covariance = curve_fit(power_law, calibration_lines, mq_lines, p0=initial_guess, maxfev=10000)\n",
    "\n",
    "    # Extract the fitted values for a and b\n",
    "    a_fit, b_fit = params\n",
    "\n",
    "    print(f\"The fit looks as follows: m/q = {a_fit:.2e} * tof^{b_fit:.2f}\")\n",
    "    \n",
    "    return a_fit, b_fit\n",
    "\n",
    "\n",
    "\n",
    "def calibrate(backgrd_dfevent):\n",
    "    'Computes calibration by least mean squares using backgrd_dfevent'\n",
    "    'Uses user input to compute fit based on displayed plots'\n",
    "    \n",
    "    # Show a large widget ion tof\n",
    "    big_ion_tof(backgrd_dfevent)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "\n",
    "        # Ask for five numbers input\n",
    "        anchors = []\n",
    "        for i in range(5):\n",
    "            value = input(f\"Enter value Ar{i + 1}: \")\n",
    "            try:\n",
    "                anchors.append(float(value))\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a number.\")\n",
    "\n",
    "        # Show five additional plots based on inputs\n",
    "        %matplotlib inline\n",
    "        for anchor in anchors:\n",
    "            zoomed_ion_tof(backgrd_dfevent,anchor)\n",
    "\n",
    "        # Ask if the user is done\n",
    "        done_response = input(\"Are you done? (y/n): \").strip().lower()\n",
    "        if done_response == 'y':\n",
    "            done = True\n",
    "    \n",
    "    # Compute calibration fit\n",
    "    a_fit, b_fit = compute_calibration(anchors)\n",
    "    \n",
    "    return a_fit, b_fit\n",
    "\n",
    "\n",
    "\n",
    "def apply_calibration(dfevents,a_fit,b_fit):\n",
    "    'Applies calibration to each dfevent of the list of dfevents and outputs calibrated_dfevents list of dataframes with m/q column'\n",
    "        \n",
    "    calibrated_dfevents = list()\n",
    "        \n",
    "    for dfevent in dfevents:\n",
    "        dfevent['mq'] = a_fit * dfevent.tof ** b_fit\n",
    "        calibrated_dfevents.append(dfevent)\n",
    "        \n",
    "    return calibrated_dfevents\n",
    "\n",
    "\n",
    "\n",
    "def mq_selection(calibrated_dfevent,dfpulse,etof,lower_mq,upper_mq):\n",
    "    'Selects based on m/q values. Need to input calibrated_dfevent! Returns m/q selected dfevent,dfpulse,etof.'\n",
    "    \n",
    "    mqselected_dfevent = calibrated_dfevent[lower_mq < calibrated_dfevent.mq][calibrated_dfevent.mq < upper_mq]\n",
    "    mqselected_dfpulse = dfpulse[dfpulse.pulseId.isin(mqselected_dfevent.pulseId)]\n",
    "    mqselected_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(mqselected_dfevent.pulseId))\n",
    "    \n",
    "    return mqselected_dfevent,mqselected_dfpulse,mqselected_etof\n",
    "\n",
    "\n",
    "\n",
    "def find_rectangle_corners(zone):\n",
    "    \n",
    "    x, y, width, height, angle_degrees = zone\n",
    "    \n",
    "    angle_radians = np.deg2rad(angle_degrees)\n",
    "    c, s = np.cos(angle_radians), np.sin(angle_radians)\n",
    "    \n",
    "    # Calculate the coordinates of the other three corners\n",
    "    corners = np.array([\n",
    "        [x, y],\n",
    "        [x + width * c, y + width * s],\n",
    "        [x + width * c - height * s, y + width * s + height * c],\n",
    "        [x - height * s, y + height * c]\n",
    "    ])\n",
    "    \n",
    "    return corners\n",
    "\n",
    "\n",
    "\n",
    "def find_integer_coordinates(corners, zone):\n",
    "    \n",
    "    min_x, min_y = np.floor(np.min(corners, axis=0))\n",
    "    max_x, max_y = np.ceil(np.max(corners, axis=0))\n",
    "\n",
    "    integer_coordinates = []\n",
    "    for x in range(int(min_x), int(max_x) + 1):\n",
    "        for y in range(int(min_y), int(max_y) + 1):\n",
    "            if is_inside(x, y, corners, zone):\n",
    "                integer_coordinates.append((x, y))\n",
    "    \n",
    "    return integer_coordinates\n",
    "\n",
    "\n",
    "\n",
    "def is_inside(x, y, corners, zone):\n",
    "    \n",
    "    ox, oy, width, height, angle_degrees = zone\n",
    "    \n",
    "    angle_radians = np.deg2rad(angle_degrees)\n",
    "    c, s = np.cos(angle_radians), np.sin(angle_radians)\n",
    "    \n",
    "    rotated_x = (x-ox)*c + (y-oy)*s + ox\n",
    "    rotated_y = -(x-ox)*s + (y-oy)*c + oy\n",
    "    \n",
    "    return ox <= rotated_x <= ox + width and oy <= rotated_y <= oy + height\n",
    "\n",
    "\n",
    "\n",
    "def tilted_spatial_ion_selection(dfevent,dfpulse,etof,zones):\n",
    "    'Selection from the heatmap using spatial coordinates'\n",
    "    'Zones is a list of tuple representing zones - tilted or not - (xstart, ystart, width, height, angle in degrees)'\n",
    "    'Returns spatially selected dfevent,dfpulse,etof'\n",
    "    \n",
    "    heatmap_with_zones(dfevent,zones)\n",
    "    \n",
    "    integer_coordinates = []\n",
    "    for zone in zones:\n",
    "        corners = find_rectangle_corners(zone)\n",
    "        integer_coordinates.extend(find_integer_coordinates(corners, zone))\n",
    "    \n",
    "    x_coords, y_coords = zip(*integer_coordinates)\n",
    "    \n",
    "    spatial_selected_dfevent = dfevent[dfevent.x.isin(x_coords)][dfevent.y.isin(y_coords)]\n",
    "    spatial_selected_dfpulse = dfpulse[dfpulse.pulseId.isin(spatial_selected_dfevent.pulseId)]\n",
    "    spatial_selected_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(spatial_selected_dfevent.pulseId))\n",
    "    \n",
    "    return spatial_selected_dfevent,spatial_selected_dfpulse,spatial_selected_etof\n",
    "\n",
    "\n",
    "\n",
    "def fish_plot_ion_selection(dfevent,zone):\n",
    "    'Selection from the heatmap using spatial coordinates'\n",
    "    'Zone is a tuple representing a zone - tilted or not - (xstart, ystart, width, height, angle in degrees)'\n",
    "    'Returns spatially selected dfevent'\n",
    "    \n",
    "    heatmap_with_zones(dfevent,[zone])\n",
    "    \n",
    "    corners = find_rectangle_corners(zone)\n",
    "    integer_coordinates = find_integer_coordinates(corners, zone)\n",
    "    \n",
    "    x_coords, y_coords = zip(*integer_coordinates)\n",
    "    \n",
    "    spatial_selected_dfevent = dfevent[dfevent.x.isin(x_coords)][dfevent.y.isin(y_coords)]\n",
    "    \n",
    "    return spatial_selected_dfevent\n",
    "    \n",
    "\n",
    "\n",
    "def fish_plot_x(dfevent,zone,tof_bins=1000,mq_bins=500):\n",
    "    'Produces fish plots along x with respect to time of flight and m/q from dfevent dataframe and a zone defined as (startx, starty, width, height, angle in degrees)'\n",
    "    \n",
    "    fish_dfevent = fish_plot_ion_selection(dfevent,zone)\n",
    "    \n",
    "    tof_bin_edges = np.linspace(0,TIME_BETWEEN_PULSES,tof_bins+1)\n",
    "    fish_dfevent['tof_binned'] = pd.cut(fish_dfevent['tof'], bins=tof_bin_edges, labels=tof_bin_edges[:-1].astype('str'))\n",
    "    tof_pivot_table = fish_dfevent.pivot_table(index='x', columns='tof_binned', aggfunc='size', fill_value=0)\n",
    "    max_tof_value = tof_pivot_table.values.max()\n",
    "    normalized_tof = tof_pivot_table.values / max_tof_value\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "    fish_dfevent['mq_binned'] = pd.cut(fish_dfevent['mq'], bins=mq_bin_edges, labels=mq_bin_edges[:-1].astype('str'))\n",
    "    mq_pivot_table = fish_dfevent.pivot_table(index='x', columns='mq_binned', aggfunc='size', fill_value=0)\n",
    "    max_mq_value = mq_pivot_table.values.max()\n",
    "    normalized_mq = mq_pivot_table.values / max_mq_value\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(30, 12))\n",
    "    \n",
    "    cax_tof = axes[0].imshow(normalized_tof, cmap='viridis', aspect='auto', norm=LogNorm(), extent=[tof_bin_edges.min(), tof_bin_edges.max(), 0, 1])\n",
    "    axes[0].set_xlabel('Time of flight (s)')\n",
    "    axes[0].set_ylabel('x')\n",
    "    axes[0].set_yticklabels(np.linspace(256,0,6,dtype=int))\n",
    "    axes[0].set_title('Fish plot along x with respect to time of flight')\n",
    "    cbar = plt.colorbar(cax_tof, ax=axes[0], label='Normalized number of events', norm=LogNorm())\n",
    "    \n",
    "    cax_mq = axes[1].imshow(normalized_mq, cmap='viridis', aspect='auto', norm=LogNorm(), extent=[mq_bin_edges.min(), mq_bin_edges.max(), 0, 1])\n",
    "    axes[1].set_xlabel('m/q')\n",
    "    axes[1].set_ylabel('x')\n",
    "    axes[1].set_yticklabels(np.linspace(256,0,6,dtype=int))\n",
    "    axes[1].set_title('Fish plot along x with respect to m/q')\n",
    "    cbar = plt.colorbar(cax_mq, ax=axes[1], label='Normalized number of events', norm=LogNorm())\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "def fish_plot_y(dfevent,zone,tof_bins=1000,mq_bins=500):\n",
    "    'Produces a fish plot along y from dfevent dataframe and a zone defined as (startx, starty, width, height, angle in degrees)'\n",
    "    \n",
    "    fish_dfevent = fish_plot_ion_selection(dfevent,zone)\n",
    "    \n",
    "    tof_bin_edges = np.linspace(0,TIME_BETWEEN_PULSES,tof_bins+1)\n",
    "    fish_dfevent['tof_binned'] = pd.cut(fish_dfevent['tof'], bins=tof_bin_edges, labels=tof_bin_edges[:-1].astype('str'))\n",
    "    tof_pivot_table = fish_dfevent.pivot_table(index='y', columns='tof_binned', aggfunc='size', fill_value=0)\n",
    "    max_tof_value = tof_pivot_table.values.max()\n",
    "    normalized_tof = tof_pivot_table.values / max_tof_value\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "    fish_dfevent['mq_binned'] = pd.cut(fish_dfevent['mq'], bins=mq_bin_edges, labels=mq_bin_edges[:-1].astype('str'))\n",
    "    mq_pivot_table = fish_dfevent.pivot_table(index='y', columns='mq_binned', aggfunc='size', fill_value=0)\n",
    "    max_mq_value = mq_pivot_table.values.max()\n",
    "    normalized_mq = mq_pivot_table.values / max_mq_value\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(30, 12))\n",
    "    \n",
    "    cax_tof = axes[0].imshow(normalized_tof, cmap='viridis', aspect='auto', norm=LogNorm(), extent=[tof_bin_edges.min(), tof_bin_edges.max(), 0, 1])\n",
    "    axes[0].set_xlabel('Time of flight (s)')\n",
    "    axes[0].set_ylabel('y')\n",
    "    axes[0].set_yticklabels(np.linspace(256,0,6,dtype=int))\n",
    "    axes[0].set_title('Fish plot along y with respect to time of flight')\n",
    "    cbar = plt.colorbar(cax_tof, ax=axes[0], label='Normalized number of events', norm=LogNorm())\n",
    "    \n",
    "    cax_mq = axes[1].imshow(normalized_mq, cmap='viridis', aspect='auto', norm=LogNorm(), extent=[mq_bin_edges.min(), mq_bin_edges.max(), 0, 1])\n",
    "    axes[1].set_xlabel('m/q')\n",
    "    axes[1].set_ylabel('y')\n",
    "    axes[1].set_yticklabels(np.linspace(256,0,6,dtype=int))\n",
    "    axes[1].set_title('Fish plot along y with respect to m/q')\n",
    "    cbar = plt.colorbar(cax_mq, ax=axes[1], label='Normalized number of events', norm=LogNorm())\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def big_mq_plot(dfevent,nbins_mq=1500,xlimits=(0,200)):\n",
    "    'Plots big intensity vs m/q plot using dfevent'\n",
    "    \n",
    "    x_lower, x_upper = xlimits\n",
    "    \n",
    "    plt.figure(figsize=(18,8))\n",
    "        \n",
    "    hist, bin_edges = np.histogram(dfevent.mq, bins=np.linspace(0,200,nbins_mq+1))\n",
    "    plt.plot(bin_edges[:-1], hist/max(hist))\n",
    "    \n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Relatively normalized number of hits per bin')\n",
    "    plt.title('Normalized ions time of flight')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16d2ff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def nevents_binning(dfevent,dfpulse,etof,nbins_events,nbins_mq):\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse) and nbins sized list of histograms'\n",
    "    'hists is divided by number of pulses in a certain number of events bin'\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfevents = []\n",
    "    filtered_dfpulses = []\n",
    "    filtered_etofs = []\n",
    "    hists = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "        filtered_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(filtered_dfpulse.pulseId))\n",
    "\n",
    "        filtered_dfevents.append(filtered_dfevent)\n",
    "        filtered_dfpulses.append(filtered_dfpulse)\n",
    "        filtered_etofs.append(filtered_etof)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.mq, bins=np.linspace(0,200,nbins_mq+1),range=(0,200))\n",
    "        hist_smooth = gaussian_filter(hist/len(filtered_dfpulse), sigma=.2)\n",
    "        hists.append(hist_smooth)\n",
    "        \n",
    "    return filtered_dfevents, filtered_dfpulses, filtered_etofs, hists, bins\n",
    "\n",
    "\n",
    "\n",
    "def nions_binning(dfevent,dfpulse,nbins_events,nbins_mq):\n",
    "    'Only handles ions'\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse) and nbins sized list of histograms'\n",
    "    'hists is divided by number of pulses in a certain number of events bin'\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfevents = []\n",
    "    filtered_dfpulses = []\n",
    "    hists = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "\n",
    "        filtered_dfevents.append(filtered_dfevent)\n",
    "        filtered_dfpulses.append(filtered_dfpulse)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.mq, bins=np.linspace(0,200,nbins_mq+1),range=(0,200))\n",
    "        hist_smooth = gaussian_filter(hist/len(filtered_dfpulse), sigma=.2)\n",
    "        hists.append(hist_smooth)\n",
    "        \n",
    "    return filtered_dfevents, filtered_dfpulses, hists, bins\n",
    "\n",
    "\n",
    "\n",
    "def nevents_binning_cov(dfevent,dfpulse,etof,nbins_events,nbins_ion_tof,nbins_e_tof,max_ion_limit=TIME_BETWEEN_PULSES,max_e_limit=TIME_BETWEEN_PULSES):\n",
    "    'Binning dfevent and etof by numbers of events, and number of bins along time of flight'\n",
    "    'Can select maximal time limit for electrons and ions'\n",
    "    \n",
    "    channel_time = TIME_BETWEEN_PULSES/CHANNELS_PER_PULSE\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    max_int_ion_limit = int(max_ion_limit/channel_time)\n",
    "    new_int_ion_limit = max_int_ion_limit - max_int_ion_limit % nbins_ion_tof\n",
    "    new_ion_limit = new_int_ion_limit*channel_time\n",
    "    \n",
    "    max_int_e_limit = int(max_e_limit/channel_time)\n",
    "    new_int_e_limit = max_int_e_limit - max_int_e_limit % nbins_e_tof\n",
    "    e_group_size = int(new_int_e_limit/nbins_e_tof)\n",
    "    \n",
    "    shortened_dfevent = calibrated_selected_dfevent[calibrated_selected_dfevent.tof < new_ion_limit]\n",
    "    shortened_etof = selected_etof[:,:new_int_e_limit]\n",
    "    \n",
    "    hists = []\n",
    "    hists_etof = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = shortened_dfevent[shortened_dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "        filtered_etof = shortened_etof.sel(pulseId=shortened_etof.coords['pulseId'].isin(filtered_dfpulse.pulseId))\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.tof, bins=nbins_ion_tof)\n",
    "        hists.append(hist)\n",
    "        \n",
    "        numpy_etof = filtered_etof.to_numpy()\n",
    "        reshaped_etof = numpy_etof.reshape((numpy_etof.shape[0], -1, e_group_size))\n",
    "        summed_etof = np.sum(reshaped_etof, axis=-1)\n",
    "        avg_etof = -np.mean(summed_etof, axis=0)\n",
    "        hists_etof.append(avg_etof)\n",
    "        \n",
    "    hists = np.array(hists)\n",
    "    hists_etof = np.array(hists_etof)\n",
    "        \n",
    "    return hists, hists_etof, bins\n",
    "\n",
    "\n",
    "\n",
    "def nevents_binning1(dfevent,dfpulse,nbins):\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse)'\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins+1).astype(int)\n",
    "    \n",
    "    filtered_dfs = []\n",
    "    plt.figure(figsize=(20,8))\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "\n",
    "        filtered_dfs.append((filtered_dfevent,filtered_dfpulse))\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.mq, bins=np.linspace(0,200,1500),range=(0,200))\n",
    "        \n",
    "        plt.plot(bin_edges[:-1], hist/max(hist), label=f'{start_edge}-{end_edge}')\n",
    "        \n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Relatively normalized number of hits per bin')\n",
    "    plt.title('Normalized ions time of flight')\n",
    "    plt.legend()\n",
    "    plt.show()   \n",
    "        \n",
    "    return filtered_dfs\n",
    "\n",
    "\n",
    "\n",
    "def waterfall_rel(hists,nbins_mq,xlimits=(0,200)):\n",
    "    \"Waterfall plot of relative normalization with respect to m/q using hists, which is a list of histograms\"\n",
    "\n",
    "    x_lower, x_upper = xlimits\n",
    "    nbins_events = len(hists)\n",
    "    bin_edges = np.linspace(0, 200, nbins_mq+1)\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    colormap = plt.cm.inferno\n",
    "    color_index = np.linspace(0.2, 0.8, nbins_events)\n",
    "\n",
    "    for i in range(nbins_events):\n",
    "        \n",
    "        hist_norm = hists[i] / max(hists[i]) + i\n",
    "\n",
    "        line_color = colormap(color_index[i])\n",
    "        plt.plot(bin_edges[:-1], hist_norm, color=line_color)\n",
    "\n",
    "    plt.title('Relative waterfall plot')\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Relative normalized counts')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "def nevents_heatmap_rel(hists,nbins_mq,bins,xlimits=(0,200)):\n",
    "    \"Heatmap of relative normalized counts with number of events slices on the y axis, with respect to m/q on the x axis using hists, which is a list of histograms\"\n",
    "    \n",
    "    precision = 200/nbins_mq\n",
    "    x_lower, x_upper = xlimits\n",
    "    hist_lower, hist_upper = int(x_lower/precision), int(x_upper/precision)\n",
    "    nbins_events = len(hists)\n",
    "    hists_norm = []\n",
    "\n",
    "    for i in range(nbins_events):\n",
    "\n",
    "        shortened_hist = hists[i][hist_lower:hist_upper]\n",
    "        hist_norm = shortened_hist / max(shortened_hist)\n",
    "        hists_norm.append(hist_norm)\n",
    "\n",
    "    x_edges = np.linspace(x_lower, x_upper, hist_upper-hist_lower)\n",
    "    y_edges = bins[:-1]\n",
    "    X, Y = np.meshgrid(x_edges, y_edges)\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    c = plt.pcolormesh(X, Y, hists_norm, shading='auto')\n",
    "    plt.colorbar(c, label='Relative normalized counts', extend='max')\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Number of events slice')\n",
    "    plt.title('Relative heatmap for number of events slices with respect to m/q')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()\n",
    "   \n",
    "    \n",
    "    \n",
    "def waterfall_abs(hists,nbins_mq,xlimits=(0,200)):\n",
    "    \"Waterfall plot of absolute normalization with respect to m/q using hists, which is a list of histograms\"\n",
    "\n",
    "    x_lower, x_upper = xlimits\n",
    "    nbins_events = len(hists)\n",
    "    bin_edges = np.linspace(0, 200, nbins_mq+1)\n",
    "    hists_norm = hists/np.max(hists)\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    colormap = plt.cm.inferno\n",
    "    color_index = np.linspace(0.2, 0.8, nbins_events)\n",
    "\n",
    "    for i in range(nbins_events):\n",
    "\n",
    "        line_color = colormap(color_index[i])\n",
    "        plt.plot(bin_edges[:-1], hists_norm[i] + i, color=line_color)\n",
    "\n",
    "    plt.title('Absolute waterfall plot')\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Relative normalized counts')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "def nevents_heatmap_abs(hists,nbins_mq,bins,xlimits=(0,200)):\n",
    "    \"Heatmap of absolute normalized counts with number of events slices on the y axis, with respect to m/q on the x axis using hists, which is a list of histograms\"\n",
    "    \n",
    "    precision = 200/nbins_mq\n",
    "    x_lower, x_upper = xlimits\n",
    "    hist_lower, hist_upper = int(x_lower/precision), int(x_upper/precision)\n",
    "    hists_shortened = hists[:][hist_lower:hist_upper]\n",
    "    nbins_events = len(hists_shortened)\n",
    "    hists_norm = hists_shortened/np.max(hists_shortened)\n",
    "\n",
    "    x_edges = np.linspace(0, 200, 1500)\n",
    "    y_edges = bins[:-1]\n",
    "    X, Y = np.meshgrid(x_edges, y_edges)\n",
    "    \n",
    "    plt.figure(figsize=(20, 8))\n",
    "    c = plt.pcolormesh(X, Y, hists_norm, shading='auto')\n",
    "    plt.colorbar(c, label='Relative normalized counts', extend='max')\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Number of events slice')\n",
    "    plt.title('Absolute heatmap for number of events slices with respect to m/q')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def waterfall_etof(filtered_etofs,xlimits=(0,200)):\n",
    "    'Waterfall plot of etof data using list of etofs filtered_etofs'\n",
    "\n",
    "    x_lower, x_upper = xlimits\n",
    "    nbins = len(filtered_etofs)\n",
    "    channel_time = TIME_BETWEEN_PULSES/CHANNELS_PER_PULSE\n",
    "    xaxis = np.arange(14080)*channel_time\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    colormap = plt.cm.inferno\n",
    "    color_index = np.linspace(0.2, 0.8, nbins)\n",
    "\n",
    "    for i in range(nbins):\n",
    "        \n",
    "        summed_etof = -np.sum(filtered_etofs[i],axis=0)\n",
    "        line_color = colormap(color_index[i])\n",
    "        plt.plot(xaxis, summed_etof/np.max(summed_etof) + i, color=line_color)\n",
    "\n",
    "    plt.title('Relative electron waterfall plot')\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Normalized signal')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "def mq_np_covariance(dfevent,mq_bins=200,log=True,vmin=None,vmax=None):\n",
    "    'Produces a positive and a negative covariance map of m/q vs m/q employing the numpy cov function'\n",
    "    'Uses dfevent as input, can select number of mq bins, can produce plot as log, standard, or between defined ranges'\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "\n",
    "    dfevent['mq_bin'] = pd.cut(dfevent['mq'], bins=mq_bin_edges)\n",
    "\n",
    "    result_matrix = pd.crosstab(dfevent['pulseId'], dfevent['mq_bin'])\n",
    "    result_numpy_matrix = result_matrix.values\n",
    "    \n",
    "    cov_matrix = np.cov(result_numpy_matrix, rowvar=False)\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if log == True:\n",
    "        ax = sns.heatmap(cov_matrix, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "    elif vmax == None:\n",
    "        ax = sns.heatmap(cov_matrix, cmap='viridis', fmt='.2f')\n",
    "    else:\n",
    "        ax = sns.heatmap(cov_matrix, cmap='viridis', fmt='.2f', vmin=0, vmax=vmax)\n",
    "\n",
    "    tick_positions = np.linspace(0, mq_bins, 11)\n",
    "    tick_labels = np.linspace(0, 200, 11).astype(int)\n",
    "\n",
    "    ax.set_xticks(tick_positions)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    ax.set_yticks(tick_positions)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.title('Positive Numpy Covariance Heatmap  m/q vs m/q')\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('m/q')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if log == True:\n",
    "        ax = sns.heatmap(-cov_matrix, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "    elif vmin == None:\n",
    "        ax = sns.heatmap(-cov_matrix, cmap='viridis', fmt='.2f')\n",
    "    else:\n",
    "        ax = sns.heatmap(-cov_matrix, cmap='viridis', fmt='.2f', vmin=0, vmax=-vmin)\n",
    "\n",
    "    tick_positions = np.linspace(0, mq_bins, 11)\n",
    "    tick_labels = np.linspace(0, 200, 11).astype(int)\n",
    "\n",
    "    ax.set_xticks(tick_positions)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    ax.set_yticks(tick_positions)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.title('Negative Numpy Covariance Heatmap  m/q vs m/q')\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('m/q')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def mq_covariance_1d(dfevent,mq_bin_range,mq_bins=200):\n",
    "    'Produces 1d covariance of an m/q bin range vs m/q employing the numpy cov function'\n",
    "    'Uses dfevent as input, can select number of mq bins'\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "\n",
    "    dfevent['mq_bin'] = pd.cut(dfevent['mq'], bins=mq_bin_edges)\n",
    "\n",
    "    result_matrix = pd.crosstab(dfevent['pulseId'], dfevent['mq_bin'])\n",
    "    result_numpy_matrix = result_matrix.values\n",
    "\n",
    "    array_hyd = result_matrix.values[:,mq_bin_range[0]:mq_bin_range[1]].sum(axis=1)\n",
    "    shape = result_numpy_matrix.shape[1]\n",
    "\n",
    "    # Calculate the covariance between each row of result_numpy_matrix and array_hyd\n",
    "    covariances = np.array([np.cov(np.column_stack((result_numpy_matrix[:, j], array_hyd)), rowvar=False)[0, 1] for j in range(shape)])\n",
    "\n",
    "    xaxis = np.linspace(0,200,shape)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xaxis,covariances)\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Covariance with m/q')\n",
    "    plt.title(f'Covariance Plot between m/q bin range {mq_bin_range} and m/q')\n",
    "    ax.set_yscale('symlog', linthresh=10)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def fix_missing_row(dfevent,dfpulse,mq_bins=200):\n",
    "    'Fixes the missing row in dfevent dataframe when computing the cross-tabulation of pulseId and mq_bin'\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "\n",
    "    dfevent['mq_bin'] = pd.cut(dfevent['mq'], bins=mq_bin_edges)\n",
    "\n",
    "    result_matrix = pd.crosstab(dfevent['pulseId'], dfevent['mq_bin'])\n",
    "    result_numpy_matrix = result_matrix.values\n",
    "    \n",
    "    resultlist = result_matrix.index.to_list()\n",
    "    resultlist.append(0)\n",
    "    selectedlist = dfpulse[dfpulse.pulseId.isin(dfevent.pulseId)].pulseId.to_list()\n",
    "    truefalse = np.equal(resultlist,selectedlist)\n",
    "    first_instance = np.argmax(~truefalse)\n",
    "    missing_pulse = int(dfpulse.iloc[first_instance].pulseId)\n",
    "\n",
    "    new_dfevent = dfevent[dfevent.pulseId != missing_pulse]\n",
    "    \n",
    "    return new_dfevent\n",
    "\n",
    "\n",
    "\n",
    "def calc_corrs(array1, array2, pcovparams, alpha=1):\n",
    "    print('calculating covariance')\n",
    "\n",
    "    assert len(pcovparams)==len(array1)==len(array2)\n",
    "    numshots=len(array1)\n",
    "    \n",
    "    # heavy stuff\n",
    "    syx=np.einsum('ij,ik->jk', array1, array2)\n",
    "    print('calculated syx')\n",
    "    syi=np.einsum('ij,i->j', array1, pcovparams)\n",
    "    print('calculated syi')\n",
    "    six=np.einsum('ij,i->j', array2, pcovparams)\n",
    "    print('calculated six')\n",
    "\n",
    "    # lighter stuff\n",
    "    sy=array1.sum(axis=0)\n",
    "    sx=array2.sum(axis=0)\n",
    "    si=pcovparams.sum(axis=0)\n",
    "    \n",
    "    syy=(array1**2).sum(axis=0)\n",
    "    sxx=(array2**2).sum(axis=0)\n",
    "    sii=(pcovparams**2).sum()\n",
    "\n",
    "    sysx=np.outer(sy, sx)\n",
    "    sisx=si*sx\n",
    "    sysi=sy*si\n",
    "    \n",
    "    # calculate covariances\n",
    "    covyx=(syx-sysx/numshots)/(numshots-1)\n",
    "    covyi=(syi-sysi/numshots)/(numshots-1)\n",
    "    covix=(six-sisx/numshots)/(numshots-1)\n",
    "\n",
    "    covyy=(syy-sy**2/numshots)/(numshots-1)\n",
    "    covxx=(sxx-sx**2/numshots)/(numshots-1)\n",
    "    covii=(sii-si**2/numshots)/(numshots-1) # renamed from varii\n",
    "\n",
    "    # calculate partial covariances\n",
    "    pcovyx=(numshots-1)/(numshots-2) * (covyx - alpha * np.outer(covyi, covix)/covii)\n",
    "    pcovyy=(numshots-1)/(numshots-2) * (covyy - (covyi**2)/covii)\n",
    "    pcovxx=(numshots-1)/(numshots-2) * (covxx - (covix**2)/covii)\n",
    "    \n",
    "    # calculate correlation\n",
    "    corryx = covyx / np.sqrt(np.outer(covyy, covxx))\n",
    "    # calculate partial correlation\n",
    "    pcorryx = pcovyx / np.sqrt(np.outer(pcovyy, pcovxx))\n",
    "    \n",
    "    return covyx, pcovyx, corryx, pcorryx\n",
    "\n",
    "\n",
    "\n",
    "def mq_covariance(dfevent,dfpulse,mq_bins=200,log=True,vmin=None,vmax=None):\n",
    "    'Produces covariance maps of m/q vs m/q employing the calc_corrs function'\n",
    "    'Uses dfevent and dfpulse as inputs, can select number of mq bins, can produce plot as log, standard, or between defined ranges'\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "\n",
    "    dfevent['mq_bin'] = pd.cut(dfevent['mq'], bins=mq_bin_edges)\n",
    "\n",
    "    result_matrix = pd.crosstab(dfevent['pulseId'], dfevent['mq_bin'])\n",
    "    result_numpy_matrix = result_matrix.values\n",
    "    \n",
    "    nevents_pulse = dfpulse[dfpulse.pulseId.isin(dfevent.pulseId)].nevents_pulse\n",
    "    \n",
    "    covyx, pcovyx, corryx, pcorryx = calc_corrs(result_numpy_matrix, result_numpy_matrix, nevents_pulse)\n",
    "    \n",
    "    \n",
    "    tick_positions = np.linspace(0, mq_bins, 11)\n",
    "    tick_labels = np.linspace(0, 200, 11).astype(int)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if log == True:\n",
    "        ax = sns.heatmap(covyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Positive Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        ax = sns.heatmap(-covyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Negative Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "    \n",
    "    elif vmax == None:\n",
    "        ax = sns.heatmap(covyx, cmap='seismic', fmt='.2f')\n",
    "        \n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        ax = sns.heatmap(covyx, cmap='seismic', fmt='.2f', vmin=vmin, vmax=vmax)\n",
    "        \n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "def mq_partial_covariance(dfevent,dfpulse,mq_bins=200,alpha=1,log=True,vmin=None,vmax=None):\n",
    "    'Produces partial covariance maps of m/q vs m/q employing the calc_corrs function'\n",
    "    'Uses dfevent and dfpulse as inputs, can select number of mq bins and factor alpha, can produce plot as log, standard, or between defined ranges'\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "\n",
    "    dfevent['mq_bin'] = pd.cut(dfevent['mq'], bins=mq_bin_edges)\n",
    "\n",
    "    result_matrix = pd.crosstab(dfevent['pulseId'], dfevent['mq_bin'])\n",
    "    result_numpy_matrix = result_matrix.values\n",
    "    \n",
    "    nevents_pulse = dfpulse[dfpulse.pulseId.isin(dfevent.pulseId)].nevents_pulse\n",
    "    \n",
    "    covyx, pcovyx, corryx, pcorryx = calc_corrs(result_numpy_matrix, result_numpy_matrix, nevents_pulse, alpha)\n",
    "    \n",
    "    \n",
    "    tick_positions = np.linspace(0, mq_bins, 11)\n",
    "    tick_labels = np.linspace(0, 200, 11).astype(int)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if log == True:\n",
    "        ax = sns.heatmap(pcovyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Positive Partial Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        ax = sns.heatmap(-pcovyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Negative Partial Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "    \n",
    "    elif vmax == None:\n",
    "        ax = sns.heatmap(pcovyx, cmap='seismic', fmt='.2f')\n",
    "        \n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Partial Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        ax = sns.heatmap(pcovyx, cmap='seismic', fmt='.2f', vmin=vmin, vmax=vmax)\n",
    "        \n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Partial Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "def etof_ion_covariance(dfevent,dfpulse,etof,nbins_ion_tof,nbins_e_tof,max_ion_limit=TIME_BETWEEN_PULSES,max_e_limit=TIME_BETWEEN_PULSES,alpha=1,log=True,vmin=None,vmax=None):\n",
    "    'Produces numpy covariance maps of etof vs ion employing the calc_corrs function'\n",
    "    'Uses dfevent and etof as inputs, can select number of bins along ion tof and electron tof, can produce plot as log, standard, or between defined ranges, and set alpha'\n",
    "    'Can select maximal time limit for electrons and ions'\n",
    "    \n",
    "    ion_tof_bin_edges = np.linspace(0,max_ion_limit,nbins_ion_tof+1)\n",
    "    dfevent['tof_bin'] = pd.cut(dfevent['tof'], bins=ion_tof_bin_edges)\n",
    "\n",
    "    ion_matrix = pd.crosstab(dfevent['pulseId'], dfevent['tof_bin'])\n",
    "\n",
    "\n",
    "    coords_etof = selected_etof.assign_coords(data=np.arange(0,TIME_BETWEEN_PULSES,channel_time))\n",
    "\n",
    "    e_tof_bin_edges = np.linspace(0,max_e_limit,nbins_e_tof+1)\n",
    "    binned_etof = coords_etof.groupby_bins(\"data\", e_tof_bin_edges).sum()\n",
    "    e_matrix = binned_etof.to_pandas()\n",
    "\n",
    "\n",
    "    ion_list = ion_matrix.index.to_list()\n",
    "    ion_list.append(0)\n",
    "    e_list = e_matrix.index.to_list()\n",
    "    truefalse = np.equal(ion_list,e_list)\n",
    "    first_instance = np.argmax(~truefalse)\n",
    "\n",
    "    new_e_matrix = e_matrix.drop(e_list[first_instance])\n",
    "\n",
    "\n",
    "    nevents_pulse = dfpulse[dfpulse.pulseId.isin(ion_matrix.index.to_numpy())].nevents_pulse\n",
    "\n",
    "    covyx, pcovyx, corryx, pcorryx = calc_corrs(ion_matrix.values, new_e_matrix.values, nevents_pulse, alpha)\n",
    "\n",
    "\n",
    "    ion_tick_positions = np.linspace(0, nbins_ion_tof, 5).astype(int)\n",
    "    formatted_ion_tick_labels = np.linspace(0, max_ion_limit, 5)\n",
    "\n",
    "    e_tick_positions = np.linspace(0, nbins_e_tof, 5).astype(int)\n",
    "    formatted_e_tick_labels = np.linspace(0, max_e_limit, 5)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if log == True:\n",
    "        ax = sns.heatmap(covyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Positive Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        ax = sns.heatmap(-covyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Negative Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "    \n",
    "    elif vmax == None:\n",
    "        ax = sns.heatmap(covyx, cmap='seismic', fmt='.2f')\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        ax = sns.heatmap(covyx, cmap='seismic', fmt='.2f', vmin=vmin, vmax=vmax)\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if log == True:\n",
    "        ax = sns.heatmap(pcovyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Positive Partial Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        ax = sns.heatmap(-pcovyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Negative Partial Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "    \n",
    "    elif vmax == None:\n",
    "        ax = sns.heatmap(pcovyx, cmap='seismic', fmt='.2f')\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Partial Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        ax = sns.heatmap(pcovyx, cmap='seismic', fmt='.2f', vmin=vmin, vmax=vmax)\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Partial Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceedcbd",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4dc64c",
   "metadata": {},
   "source": [
    "## Selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc32e5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "RUNID = [389,390]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c48aa7d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND1 = 750\n",
    "UPPER_BOUND1 = 1500\n",
    "\n",
    "LOWER_BOUND2 = 1000\n",
    "UPPER_BOUND2 = 5000\n",
    "\n",
    "LOWER_BOUND3 = 5000\n",
    "UPPER_BOUND3 = 8000\n",
    "\n",
    "THRESHOLDS = [(LOWER_BOUND1, UPPER_BOUND1), (LOWER_BOUND2, UPPER_BOUND2), (LOWER_BOUND3, UPPER_BOUND3)]\n",
    "\n",
    "selections = events_selection_plots(RUNID,THRESHOLDS)\n",
    "\n",
    "selected_dfevent1, selected_dfpulse1, selected_etof1 = selections[0]\n",
    "selected_dfevent2, selected_dfpulse2, selected_etof2 = selections[1]\n",
    "selected_dfevent3, selected_dfpulse3, selected_etof3 = selections[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba95017",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND = 500\n",
    "UPPER_BOUND = 5000\n",
    "THRESHOLD = [(LOWER_BOUND,UPPER_BOUND)]\n",
    "\n",
    "selections = events_selection_plots(RUNID,THRESHOLD)\n",
    "selected_dfevent, selected_dfpulse, selected_etof = selections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e44556",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BACKGRD_BOUND = 20\n",
    "UPPER_BACKGRD_BOUND = 40\n",
    "BKGRD_THRESHOLD = [(LOWER_BACKGRD_BOUND,UPPER_BACKGRD_BOUND)]\n",
    "DOWNSAMPLING = 200000\n",
    "\n",
    "backgrd_dfevent, backgrd_dfpulse, backgrd_etof = events_selection(RUNID,BKGRD_THRESHOLD,DOWNSAMPLING)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d37cf",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "RUNID = [376,380,382,383,384,386,387,388,389,390,391,393,398,399,400,402,403,404]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b1740",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND1 = 750\n",
    "UPPER_BOUND1 = 1500\n",
    "\n",
    "LOWER_BOUND2 = 3000\n",
    "UPPER_BOUND2 = 8000\n",
    "\n",
    "LOWER_BOUND3 = 10000\n",
    "UPPER_BOUND3 = 14000\n",
    "\n",
    "THRESHOLDS = [(LOWER_BOUND1, UPPER_BOUND1), (LOWER_BOUND2, UPPER_BOUND2), (LOWER_BOUND3, UPPER_BOUND3)]\n",
    "\n",
    "ion_selections = ion_selection(RUNID,THRESHOLDS)\n",
    "\n",
    "ion_dfevent1, ion_dfpulse1 = ion_selections[0]\n",
    "ion_dfevent2, ion_dfpulse2 = ion_selections[1]\n",
    "ion_dfevent3, ion_dfpulse3 = ion_selections[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971765d4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND = 500\n",
    "UPPER_BOUND = 5000\n",
    "THRESHOLD = [(LOWER_BOUND,UPPER_BOUND)]\n",
    "\n",
    "ion_dfevent, ion_dfpulse = ion_selection(RUNID,THRESHOLD)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d3cc1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BACKGRD_BOUND = 20\n",
    "UPPER_BACKGRD_BOUND = 40\n",
    "BKGRD_THRESHOLD = [(LOWER_BACKGRD_BOUND,UPPER_BACKGRD_BOUND)]\n",
    "DOWNSAMPLING = 200000\n",
    "\n",
    "backgrd_ion_dfevent, backgrd_ion_dfpulse = ion_selection(RUNID,BKGRD_THRESHOLD,DOWNSAMPLING)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8662766",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "argon_dfevent, argon_dfpulse, argon_etof, argon_pnccd = read(138)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b289800",
   "metadata": {},
   "source": [
    "## Pulse filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61f264",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bounded_dfevent = ion_dfevent1[ion_dfevent1.tof < TIME_BETWEEN_PULSES]\n",
    "hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=1000)\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(bin_edges[:-1], hist/max(hist))\n",
    "plt.xlabel('Time of flight (s)')\n",
    "plt.ylabel('Normalized signal')\n",
    "plt.title('Ions time of flight')\n",
    "plt.xlim(0,1e-6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4675e8f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(bin_edges[:-1], hist/max(hist))\n",
    "plt.xlabel('Time of flight (s)')\n",
    "plt.ylabel('Normalized signal')\n",
    "plt.title('Ions time of flight')\n",
    "plt.xlim(0,2e-6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d32a39",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "event_numbers=['750-1500','3000-8000','10000-14000']\n",
    "k=0\n",
    "for i_df in [ion_dfevent1,ion_dfevent2,ion_dfevent3]:\n",
    "    print('event_numbers',event_numbers[k])\n",
    "    k+=1\n",
    "    for pulse_number in [None,'01','46','92']:\n",
    "        print('pulse number',pulse_number)\n",
    "        pulse_filtered_ion_tof(i_df,pulse_number,5e-7)\n",
    "print('background 20-40')\n",
    "pulse_filtered_ion_tof(backgrd_ion_dfevent,None,5e-7)\n",
    "print('argon')\n",
    "pulse_filtered_ion_tof(argon_dfevent,None,5e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567bbeb0",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63259b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X = 127\n",
    "Y = 117\n",
    "WIDTH = 13\n",
    "HEIGHT = 10\n",
    "ZONE = [X,Y,WIDTH,HEIGHT,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca981f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### To test where your square selection is, use:\n",
    "heatmap_with_zones(selected_dfevent,[ZONE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc5c04",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spatial_bkgrd_dfevent,spatial_bkgrd_dfpulse,spatial_bkgrd_etof = spatial_ion_selection(backgrd_dfevent,backgrd_dfpulse,backgrd_etof,[ZONE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24ffb0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "big_ion_tof(spatial_bkgrd_dfevent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5379f443",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#CALIBRATION_LINES = [1.312e-6, 9.26e-7, 7.56e-7, 6.65e-7, 5.97e-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b458e0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "a_fit, b_fit = \n",
    "calibrate(spatial_bkgrd_dfevent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ee876",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "a_fit, b_fit = (29497236325759.32, 2.0175071848701878)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f908cd2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "calibrated_selected_dfevent, calibrated_backgrd_dfevent = apply_calibration([selected_dfevent,backgrd_dfevent],a_fit,b_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9975ea14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "calibrated_selected_dfevent1, calibrated_backgrd_dfevent = apply_calibration([selected_dfevent1,backgrd_dfevent],a_fit,b_fit)\n",
    "calibrated_selected_dfevent2, calibrated_backgrd_dfevent = apply_calibration([selected_dfevent2,backgrd_dfevent],a_fit,b_fit)\n",
    "calibrated_selected_dfevent3, calibrated_backgrd_dfevent = apply_calibration([selected_dfevent3,backgrd_dfevent],a_fit,b_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63439c3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "calibrated_ion_dfevent, calibrated_backgrd_ion_dfevent = apply_calibration([ion_dfevent,backgrd_ion_dfevent],a_fit,b_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204513ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "MQ_LINES = [40,20,40/3,40/4,40/5]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "histselected, bin_edgesselected = np.histogram(calibrated_selected_dfevent.mq, bins=np.linspace(0,200,1000),range=(0,200))\n",
    "histgrd, bin_edgesgrd = np.histogram(calibrated_backgrd_dfevent.mq, bins=np.linspace(0,200,1000),range=(0,200))\n",
    "plt.plot(bin_edgesselected[:-1], histselected/max(histselected), linewidth = 1, c='b')\n",
    "plt.plot(bin_edgesgrd[:-1], histgrd/max(histgrd), linewidth = 1, c='g')\n",
    "plt.vlines(MQ_LINES,0,1,colors='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8893b13e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "big_mq_plot(calibrated_selected_dfevent,2500,(0,150))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
