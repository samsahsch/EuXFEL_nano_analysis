{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b43ceb6",
   "metadata": {},
   "source": [
    "### Analysis code snippets for preprocessed h5 files\n",
    "\n",
    "Organized as follows:\n",
    "1. Select runs and filter based on number of hits, including choosing ions, electron and/or photon data\n",
    "2. Filter based on pulse number\n",
    "3. Calibrate runs for m/q values\n",
    "4. Heatmap and electron time of flight plots\n",
    "5. Fish plots\n",
    "6. Intensity dependent plots including into time of flight plots, waterfall plots and heatmaps\n",
    "7. Presentation plots including fish plot, heatmaps, electron and ion data\n",
    "8. Covariances between ion data and between ion and electron data\n",
    "9. PNCCD photon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a173f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Need to install reading methods the first time:\n",
    "\n",
    "pip install --user tables   ### to read dataframe\n",
    "pip install h5netcdf        ### to read xarrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87da59e",
   "metadata": {},
   "source": [
    "# Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df658959",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038ee68",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "TIME_BETWEEN_PULSES = 3.54462e-6\n",
    "CHANNELS_PER_PULSE = 14080\n",
    "channel_time = TIME_BETWEEN_PULSES/CHANNELS_PER_PULSE\n",
    "\n",
    "\n",
    "    \n",
    "def read(runid):\n",
    "    'Read the preprocessed data of run with ID runid saved in the h5 file with a corresponding name'\n",
    "    'Outputs dataframes per event, per pulse, and xarrays etof, pnccd in that order'\n",
    "    \n",
    "    filename = '../preprocess/datarun' + str(runid) + '.h5'\n",
    "    \n",
    "    dfevent = pd.read_hdf(filename, 'dfevent')\n",
    "    dfpulse = pd.read_hdf(filename, 'dfpulse')\n",
    "    \n",
    "    etof = xr.open_dataarray(filename, group=\"etof\")\n",
    "    pnccd = xr.open_dataarray(filename, group=\"pnccd\")\n",
    "    \n",
    "    return dfevent, dfpulse, etof, pnccd\n",
    "\n",
    "\n",
    "\n",
    "def read_ions_electrons(runid,tof_limit=None):\n",
    "    'Read the preprocessed data of run with ID runid saved in the h5 file with a corresponding name'\n",
    "    'Outputs dataframes per event, per pulse, and xarrays etof in that order'\n",
    "    'tof_limit limiting electron time of flight loaded in'\n",
    "    \n",
    "    filename = '../preprocess/datarun' + str(runid) + '.h5'\n",
    "    \n",
    "    dfevent = pd.read_hdf(filename, 'dfevent')\n",
    "    dfpulse = pd.read_hdf(filename, 'dfpulse')\n",
    "    \n",
    "    etof = xr.open_dataarray(filename, group=\"etof\")\n",
    "\n",
    "    if type(tof_limit) == int:\n",
    "        max_coord = int(tof_limit/channel_time)\n",
    "        etof = etof[:max_coord]\n",
    "    \n",
    "    return dfevent, dfpulse, etof\n",
    "\n",
    "\n",
    "\n",
    "def read_ions_photons(runid):\n",
    "    'Read the preprocessed data of run with ID runid saved in the h5 file with a corresponding name'\n",
    "    'Outputs dataframes per event, per pulse, and xarrays pnccd in that order'\n",
    "    \n",
    "    filename = '../preprocess/datarun' + str(runid) + '.h5'\n",
    "    \n",
    "    dfevent = pd.read_hdf(filename, 'dfevent')\n",
    "    dfpulse = pd.read_hdf(filename, 'dfpulse')\n",
    "    \n",
    "    pnccd = xr.open_dataarray(filename, group=\"pnccd\")\n",
    "    \n",
    "    return dfevent, dfpulse, pnccd\n",
    "\n",
    "\n",
    "\n",
    "def read_ion(runid):\n",
    "    'Read the preprocessed data of run with ID runid saved in the h5 file with a corresponding name'\n",
    "    'Outputs dataframes per event and per pulse'\n",
    "    \n",
    "    filename = '../preprocess/datarun' + str(runid) + '.h5'\n",
    "    \n",
    "    dfevent = pd.read_hdf(filename, 'dfevent')\n",
    "    dfpulse = pd.read_hdf(filename, 'dfpulse')\n",
    "    \n",
    "    return dfevent, dfpulse\n",
    "\n",
    "\n",
    "\n",
    "def read_pnccd(runid):\n",
    "    'Read the preprocessed data of run with ID runid saved in the h5 file with a corresponding name'\n",
    "    'Outputs dataframes per event, per pulse, and xarrays etof, pnccd in that order'\n",
    "    \n",
    "    filename = '../preprocess/datarun' + str(runid) + '.h5'\n",
    "    pnccd = xr.open_dataarray(filename, group=\"pnccd\")\n",
    "    \n",
    "    return pnccd\n",
    "\n",
    "\n",
    "\n",
    "def events_selection(runs,thresholds,num_pulses=None):\n",
    "    'Reads one or multiple runs from h5 files'\n",
    "    'Makes a pulse selection based on the number of events per pulse between the defined thresholds'\n",
    "    'If multiple runs are passed, will merge the runs, once hit selected'\n",
    "    'Thresholds can be between one and three tuples (lower threshold, upper threshold)'\n",
    "    'Downsamples by num_pulses'\n",
    "    \n",
    "    lower_threshold1, upper_threshold1 = thresholds[0]\n",
    "    selected_dfevents1 = list()\n",
    "    selected_dfpulses1 = list()\n",
    "    selected_etofs1 = list()\n",
    "    selected_pnccds1 = list()\n",
    "    \n",
    "    if len(thresholds) > 1:\n",
    "        lower_threshold2, upper_threshold2 = thresholds[1]\n",
    "        selected_dfevents2 = list()\n",
    "        selected_dfpulses2 = list()\n",
    "        selected_etofs2 = list()\n",
    "        selected_pnccds2 = list()\n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        lower_threshold3, upper_threshold3 = thresholds[2]  \n",
    "        selected_dfevents3 = list()\n",
    "        selected_dfpulses3 = list()\n",
    "        selected_etofs3 = list()\n",
    "        selected_pnccds3 = list()\n",
    "    \n",
    "    dataframes = dict()\n",
    "    \n",
    "    if type(num_pulses) == int:\n",
    "        num_pulses_run = int(num_pulses/len(runs))\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        dfevent, dfpulse, etof, pnccd = read(run)\n",
    "        \n",
    "        selections = list()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.scatter(dfpulse.pulseId,dfpulse.nevents_pulse,c='black',label='All pulses')\n",
    "        \n",
    "        if type(num_pulses) == int:\n",
    "            dfpulse = dfpulse.sample(n=num_pulses_run)\n",
    "            \n",
    "        selected_dfpulse1 = dfpulse[lower_threshold1 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold1]\n",
    "        selected_dfevent1 = dfevent[dfevent.pulseId.isin(selected_dfpulse1.pulseId)]\n",
    "        selected_etof1 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse1.pulseId))\n",
    "        selected_pnccd1 = pnccd.sel(trainId=pnccd.coords['trainId'].isin(selected_dfpulse1.trainId))\n",
    "        selections.append((selected_dfevent1, selected_dfpulse1, selected_etof1, selected_pnccd1))\n",
    "        plt.scatter(selected_dfpulse1.pulseId,selected_dfpulse1.nevents_pulse,c='r',label=f'Between {lower_threshold1} and {upper_threshold1}')\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            \n",
    "            selected_dfpulse2 = dfpulse[lower_threshold2 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold2]\n",
    "            selected_dfevent2 = dfevent[dfevent.pulseId.isin(selected_dfpulse2.pulseId)]\n",
    "            selected_etof2 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse2.pulseId))\n",
    "            selected_pnccd2 = pnccd.sel(trainId=pnccd.coords['trainId'].isin(selected_dfpulse2.trainId))\n",
    "            selections.append((selected_dfevent2, selected_dfpulse2, selected_etof2, selected_pnccd2))\n",
    "            plt.scatter(selected_dfpulse2.pulseId,selected_dfpulse2.nevents_pulse,c='blue',label=f'Between {lower_threshold2} and {upper_threshold2}')\n",
    "            \n",
    "        if len(thresholds) > 2:\n",
    "            \n",
    "            selected_dfpulse3 = dfpulse[lower_threshold3 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold3]\n",
    "            selected_dfevent3 = dfevent[dfevent.pulseId.isin(selected_dfpulse3.pulseId)]\n",
    "            selected_etof3 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse3.pulseId))\n",
    "            selected_pnccd3 = pnccd.sel(trainId=pnccd.coords['trainId'].isin(selected_dfpulse3.trainId))\n",
    "            selections.append((selected_dfevent3, selected_dfpulse3, selected_etof3, selected_pnccd3))\n",
    "            plt.scatter(selected_dfpulse3.pulseId,selected_dfpulse3.nevents_pulse,c='g',label=f'Between {lower_threshold3} and {upper_threshold3}')  \n",
    "        \n",
    "        dataframes[run] = selections\n",
    "          \n",
    "        plt.xlabel('Pulse ID')\n",
    "        plt.ylabel('Number of events per pulse')\n",
    "        plt.legend()\n",
    "        plt.title(f'Events per pulse with respect to pulse ID for run {run}')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    for key, values in dataframes.items():\n",
    "        \n",
    "        selected_dfevents1.append(values[0][0])\n",
    "        selected_dfpulses1.append(values[0][1])\n",
    "        selected_etofs1.append(values[0][2])\n",
    "        selected_pnccds1.append(values[0][3])\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            selected_dfevents2.append(values[1][0])\n",
    "            selected_dfpulses2.append(values[1][1])\n",
    "            selected_etofs2.append(values[1][2])\n",
    "            selected_pnccds2.append(values[1][3])\n",
    "            \n",
    "        if len(thresholds) > 2: \n",
    "            selected_dfevents3.append(values[2][0])\n",
    "            selected_dfpulses3.append(values[2][1])\n",
    "            selected_etofs3.append(values[2][2])\n",
    "            selected_pnccds3.append(values[2][3])\n",
    "        \n",
    "        \n",
    "    merged_selection = list()\n",
    "    \n",
    "    merged_dfevent1 = pd.concat(selected_dfevents1)\n",
    "    merged_dfevent1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_dfpulse1 = pd.concat(selected_dfpulses1)\n",
    "    merged_dfpulse1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_etof1 = xr.concat(selected_etofs1, dim='pulseId')\n",
    "    merged_pnccd1 = xr.concat(selected_pnccds1, dim='pulseId')\n",
    "    \n",
    "    merged_selection.append((merged_dfevent1, merged_dfpulse1, merged_etof1, merged_pnccd1))\n",
    "    \n",
    "    print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold1} and {upper_threshold1} events: {len(merged_dfpulse1)}\")\n",
    "       \n",
    "        \n",
    "    if len(thresholds) > 1:\n",
    "        merged_dfevent2 = pd.concat(selected_dfevents2)\n",
    "        merged_dfevent2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse2 = pd.concat(selected_dfpulses2)\n",
    "        merged_dfpulse2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_etof2 = xr.concat(selected_etofs2, dim='pulseId')\n",
    "        merged_pnccd2 = xr.concat(selected_pnccds2, dim='pulseId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent2, merged_dfpulse2, merged_etof2, merged_pnccd2))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold2} and {upper_threshold2} events: {len(merged_dfpulse2)}\")\n",
    "    \n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        merged_dfevent3 = pd.concat(selected_dfevents3)\n",
    "        merged_dfevent3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse3 = pd.concat(selected_dfpulses3)\n",
    "        merged_dfpulse3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_etof3 = xr.concat(selected_etofs3, dim='pulseId')\n",
    "        merged_pnccd3 = xr.concat(selected_pnccds3, dim='pulseId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent3, merged_dfpulse3, merged_etof3, merged_pnccd3))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold3} and {upper_threshold3} events: {len(merged_dfpulse3)}\")\n",
    "        \n",
    "    \n",
    "    return merged_selection\n",
    "\n",
    "\n",
    "\n",
    "def events_selection_ions_electrons(runs,thresholds,num_pulses=None,tof_limit=None):\n",
    "    'Reads one or multiple runs from h5 files'\n",
    "    'Makes a pulse selection based on the number of events per pulse between the defined thresholds'\n",
    "    'If multiple runs are passed, will merge the runs, once hit selected'\n",
    "    'Thresholds can be between one and three tuples (lower threshold, upper threshold)'\n",
    "    'Downsamples by num_pulses'\n",
    "    \n",
    "    lower_threshold1, upper_threshold1 = thresholds[0]\n",
    "    selected_dfevents1 = list()\n",
    "    selected_dfpulses1 = list()\n",
    "    selected_etofs1 = list()\n",
    "    \n",
    "    if len(thresholds) > 1:\n",
    "        lower_threshold2, upper_threshold2 = thresholds[1]\n",
    "        selected_dfevents2 = list()\n",
    "        selected_dfpulses2 = list()\n",
    "        selected_etofs2 = list()\n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        lower_threshold3, upper_threshold3 = thresholds[2]  \n",
    "        selected_dfevents3 = list()\n",
    "        selected_dfpulses3 = list()\n",
    "        selected_etofs3 = list()\n",
    "    \n",
    "    dataframes = dict()\n",
    "    \n",
    "    if type(num_pulses) == int:\n",
    "        num_pulses_run = int(num_pulses/len(runs))\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        dfevent, dfpulse, etof = read_ions_electrons(run,tof_limit)\n",
    "        \n",
    "        selections = list()\n",
    "        \n",
    "        if type(num_pulses) == int:\n",
    "            dfpulse = dfpulse.sample(n=num_pulses_run)\n",
    "            \n",
    "        selected_dfpulse1 = dfpulse[lower_threshold1 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold1]\n",
    "        selected_dfevent1 = dfevent[dfevent.pulseId.isin(selected_dfpulse1.pulseId)]\n",
    "        selected_etof1 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse1.pulseId))\n",
    "        selections.append((selected_dfevent1, selected_dfpulse1, selected_etof1))\n",
    "        plt.scatter(selected_dfpulse1.pulseId,selected_dfpulse1.nevents_pulse,c='r',label=f'Between {lower_threshold1} and {upper_threshold1}')\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            \n",
    "            selected_dfpulse2 = dfpulse[lower_threshold2 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold2]\n",
    "            selected_dfevent2 = dfevent[dfevent.pulseId.isin(selected_dfpulse2.pulseId)]\n",
    "            selected_etof2 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse2.pulseId))\n",
    "            selections.append((selected_dfevent2, selected_dfpulse2, selected_etof2))\n",
    "            plt.scatter(selected_dfpulse2.pulseId,selected_dfpulse2.nevents_pulse,c='blue',label=f'Between {lower_threshold2} and {upper_threshold2}')\n",
    "            \n",
    "        if len(thresholds) > 2:\n",
    "            \n",
    "            selected_dfpulse3 = dfpulse[lower_threshold3 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold3]\n",
    "            selected_dfevent3 = dfevent[dfevent.pulseId.isin(selected_dfpulse3.pulseId)]\n",
    "            selected_etof3 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse3.pulseId))\n",
    "            selections.append((selected_dfevent3, selected_dfpulse3, selected_etof3))\n",
    "            plt.scatter(selected_dfpulse3.pulseId,selected_dfpulse3.nevents_pulse,c='g',label=f'Between {lower_threshold3} and {upper_threshold3}')  \n",
    "        \n",
    "        dataframes[run] = selections\n",
    "        \n",
    "    for key, values in dataframes.items():\n",
    "        \n",
    "        selected_dfevents1.append(values[0][0])\n",
    "        selected_dfpulses1.append(values[0][1])\n",
    "        selected_etofs1.append(values[0][2])\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            selected_dfevents2.append(values[1][0])\n",
    "            selected_dfpulses2.append(values[1][1])\n",
    "            selected_etofs2.append(values[1][2])\n",
    "            \n",
    "        if len(thresholds) > 2: \n",
    "            selected_dfevents3.append(values[2][0])\n",
    "            selected_dfpulses3.append(values[2][1])\n",
    "            selected_etofs3.append(values[2][2])\n",
    "        \n",
    "    merged_selection = list()\n",
    "    \n",
    "    merged_dfevent1 = pd.concat(selected_dfevents1)\n",
    "    merged_dfevent1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_dfpulse1 = pd.concat(selected_dfpulses1)\n",
    "    merged_dfpulse1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_etof1 = xr.concat(selected_etofs1, dim='pulseId')\n",
    "    \n",
    "    merged_selection.append((merged_dfevent1, merged_dfpulse1, merged_etof1))\n",
    "    \n",
    "    print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold1} and {upper_threshold1} events: {len(merged_dfpulse1)}\")\n",
    "           \n",
    "    if len(thresholds) > 1:\n",
    "        merged_dfevent2 = pd.concat(selected_dfevents2)\n",
    "        merged_dfevent2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse2 = pd.concat(selected_dfpulses2)\n",
    "        merged_dfpulse2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_etof2 = xr.concat(selected_etofs2, dim='pulseId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent2, merged_dfpulse2, merged_etof2))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold2} and {upper_threshold2} events: {len(merged_dfpulse2)}\") \n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        merged_dfevent3 = pd.concat(selected_dfevents3)\n",
    "        merged_dfevent3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse3 = pd.concat(selected_dfpulses3)\n",
    "        merged_dfpulse3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_etof3 = xr.concat(selected_etofs3, dim='pulseId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent3, merged_dfpulse3, merged_etof3))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold3} and {upper_threshold3} events: {len(merged_dfpulse3)}\")\n",
    "        \n",
    "    return merged_selection\n",
    "\n",
    "\n",
    "\n",
    "def events_selection_ions_photons(runs,thresholds,num_pulses=None):\n",
    "    'Reads one or multiple runs from h5 files'\n",
    "    'Makes a pulse selection based on the number of events per pulse between the defined thresholds'\n",
    "    'If multiple runs are passed, will merge the runs, once hit selected'\n",
    "    'Thresholds can be between one and three tuples (lower threshold, upper threshold)'\n",
    "    'Downsamples by num_pulses'\n",
    "    \n",
    "    lower_threshold1, upper_threshold1 = thresholds[0]\n",
    "    selected_dfevents1 = list()\n",
    "    selected_dfpulses1 = list()\n",
    "    selected_pnccds1 = list()\n",
    "    \n",
    "    if len(thresholds) > 1:\n",
    "        lower_threshold2, upper_threshold2 = thresholds[1]\n",
    "        selected_dfevents2 = list()\n",
    "        selected_dfpulses2 = list()\n",
    "        selected_pnccds2 = list()\n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        lower_threshold3, upper_threshold3 = thresholds[2]  \n",
    "        selected_dfevents3 = list()\n",
    "        selected_dfpulses3 = list()\n",
    "        selected_pnccds3 = list()\n",
    "    \n",
    "    dataframes = dict()\n",
    "    \n",
    "    if type(num_pulses) == int:\n",
    "        num_pulses_run = int(num_pulses/len(runs))\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        print('Processing run number',run)\n",
    "        \n",
    "        dfevent, dfpulse, pnccd = read_ions_photons(run)\n",
    "        \n",
    "        selections = list()\n",
    "        \n",
    "        if type(num_pulses) == int:\n",
    "            dfpulse = dfpulse.sample(n=num_pulses_run)\n",
    "            \n",
    "        selected_dfpulse1 = dfpulse[lower_threshold1 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold1]\n",
    "        selected_dfevent1 = dfevent[dfevent.pulseId.isin(selected_dfpulse1.pulseId)]\n",
    "        selected_pnccd1 = pnccd.sel(trainId=pnccd.coords['trainId'].isin(selected_dfpulse1.trainId))\n",
    "        selections.append((selected_dfevent1, selected_dfpulse1, selected_pnccd1))\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            \n",
    "            selected_dfpulse2 = dfpulse[lower_threshold2 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold2]\n",
    "            selected_dfevent2 = dfevent[dfevent.pulseId.isin(selected_dfpulse2.pulseId)]\n",
    "            selected_pnccd2 = pnccd.sel(trainId=pnccd.coords['trainId'].isin(selected_dfpulse2.trainId))\n",
    "            selections.append((selected_dfevent2, selected_dfpulse2, selected_pnccd2))\n",
    "            \n",
    "        if len(thresholds) > 2:\n",
    "            \n",
    "            selected_dfpulse3 = dfpulse[lower_threshold3 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold3]\n",
    "            selected_dfevent3 = dfevent[dfevent.pulseId.isin(selected_dfpulse3.pulseId)]\n",
    "            selected_pnccd3 = pnccd.sel(trainId=pnccd.coords['trainId'].isin(selected_dfpulse3.trainId))\n",
    "            selections.append((selected_dfevent3, selected_dfpulse3, selected_pnccd3))\n",
    "            \n",
    "        dataframes[run] = selections\n",
    "        \n",
    "    for key, values in dataframes.items():\n",
    "        \n",
    "        selected_dfevents1.append(values[0][0])\n",
    "        selected_dfpulses1.append(values[0][1])\n",
    "        selected_pnccds1.append(values[0][2])\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            selected_dfevents2.append(values[1][0])\n",
    "            selected_dfpulses2.append(values[1][1])\n",
    "            selected_pnccds2.append(values[1][2])\n",
    "            \n",
    "        if len(thresholds) > 2: \n",
    "            selected_dfevents3.append(values[2][0])\n",
    "            selected_dfpulses3.append(values[2][1])\n",
    "            selected_pnccds3.append(values[2][2])\n",
    "        \n",
    "        \n",
    "    merged_selection = list()\n",
    "    \n",
    "    merged_dfevent1 = pd.concat(selected_dfevents1)\n",
    "    merged_dfevent1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_dfpulse1 = pd.concat(selected_dfpulses1)\n",
    "    merged_dfpulse1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_pnccd1 = xr.concat(selected_pnccds1, dim='trainId')\n",
    "    \n",
    "    merged_selection.append((merged_dfevent1, merged_dfpulse1, merged_pnccd1))\n",
    "    \n",
    "    print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold1} and {upper_threshold1} events: {len(merged_dfpulse1)}\")\n",
    "       \n",
    "        \n",
    "    if len(thresholds) > 1:\n",
    "        merged_dfevent2 = pd.concat(selected_dfevents2)\n",
    "        merged_dfevent2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse2 = pd.concat(selected_dfpulses2)\n",
    "        merged_dfpulse2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_pnccd2 = xr.concat(selected_pnccds2, dim='trainId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent2, merged_dfpulse2, merged_pnccd2))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold2} and {upper_threshold2} events: {len(merged_dfpulse2)}\")\n",
    "    \n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        merged_dfevent3 = pd.concat(selected_dfevents3)\n",
    "        merged_dfevent3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse3 = pd.concat(selected_dfpulses3)\n",
    "        merged_dfpulse3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_pnccd3 = xr.concat(selected_pnccds3, dim='trainId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent3, merged_dfpulse3, merged_pnccd3))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold3} and {upper_threshold3} events: {len(merged_dfpulse3)}\")\n",
    "\n",
    "    \n",
    "    return merged_selection\n",
    "\n",
    "\n",
    "\n",
    "def ion_selection(runs,thresholds,num_pulses=None):\n",
    "    'Only handles ion data'\n",
    "    'Reads one or multiple runs from h5 files'\n",
    "    'Makes a pulse selection based on the number of events per pulse between the defined thresholds'\n",
    "    'If multiple runs are passed, will merge the runs, once hit selected'\n",
    "    'Thresholds can be between one and three tuples (lower threshold, upper threshold)'\n",
    "    'Downsamples by num_pulses'\n",
    "    \n",
    "    lower_threshold1, upper_threshold1 = thresholds[0]\n",
    "    selected_dfevents1 = list()\n",
    "    selected_dfpulses1 = list()\n",
    "    \n",
    "    if len(thresholds) > 1:\n",
    "        lower_threshold2, upper_threshold2 = thresholds[1]\n",
    "        selected_dfevents2 = list()\n",
    "        selected_dfpulses2 = list()\n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        lower_threshold3, upper_threshold3 = thresholds[2]  \n",
    "        selected_dfevents3 = list()\n",
    "        selected_dfpulses3 = list()\n",
    "    \n",
    "    dataframes = dict()\n",
    "    \n",
    "    if type(num_pulses) == int:\n",
    "        num_pulses_run = int(num_pulses/len(runs))\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        print('Handling run', run)\n",
    "        dfevent, dfpulse = read_ion(run)\n",
    "        \n",
    "        selections = list()\n",
    "        # plt.figure()\n",
    "        # plt.scatter(dfpulse.pulseId,dfpulse.nevents_pulse,c='black',label='All pulses')\n",
    "        \n",
    "        if type(num_pulses) == int:\n",
    "            dfpulse = dfpulse.sample(n=num_pulses_run)\n",
    "            \n",
    "        selected_dfpulse1 = dfpulse[lower_threshold1 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold1]\n",
    "        selected_dfevent1 = dfevent[dfevent.pulseId.isin(selected_dfpulse1.pulseId)]\n",
    "        selections.append((selected_dfevent1, selected_dfpulse1))\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            \n",
    "            selected_dfpulse2 = dfpulse[lower_threshold2 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold2]\n",
    "            selected_dfevent2 = dfevent[dfevent.pulseId.isin(selected_dfpulse2.pulseId)]\n",
    "            selections.append((selected_dfevent2, selected_dfpulse2))\n",
    "            \n",
    "        if len(thresholds) > 2:\n",
    "            \n",
    "            selected_dfpulse3 = dfpulse[lower_threshold3 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold3]\n",
    "            selected_dfevent3 = dfevent[dfevent.pulseId.isin(selected_dfpulse3.pulseId)]\n",
    "            selections.append((selected_dfevent3, selected_dfpulse3))\n",
    "        \n",
    "        dataframes[run] = selections\n",
    "          \n",
    "        # plt.xlabel('Pulse ID')\n",
    "        # plt.ylabel('Number of events per pulse')\n",
    "        # plt.legend()\n",
    "        # plt.title(f'Events per pulse with respect to pulse ID for run {run}')\n",
    "        # plt.show()\n",
    "\n",
    "        \n",
    "    for key, values in dataframes.items():\n",
    "        \n",
    "        selected_dfevents1.append(values[0][0])\n",
    "        selected_dfpulses1.append(values[0][1])\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            selected_dfevents2.append(values[1][0])\n",
    "            selected_dfpulses2.append(values[1][1])\n",
    "            \n",
    "        if len(thresholds) > 2: \n",
    "            selected_dfevents3.append(values[2][0])\n",
    "            selected_dfpulses3.append(values[2][1])\n",
    "        \n",
    "        \n",
    "    merged_selection = list()\n",
    "    \n",
    "    merged_dfevent1 = pd.concat(selected_dfevents1)\n",
    "    merged_dfevent1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_dfpulse1 = pd.concat(selected_dfpulses1)\n",
    "    merged_dfpulse1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_selection.append((merged_dfevent1, merged_dfpulse1))\n",
    "    \n",
    "    print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold1} and {upper_threshold1} events: {len(merged_dfpulse1)}\")\n",
    "       \n",
    "        \n",
    "    if len(thresholds) > 1:\n",
    "        merged_dfevent2 = pd.concat(selected_dfevents2)\n",
    "        merged_dfevent2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse2 = pd.concat(selected_dfpulses2)\n",
    "        merged_dfpulse2.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        merged_selection.append((merged_dfevent2, merged_dfpulse2))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold2} and {upper_threshold2} events: {len(merged_dfpulse2)}\")\n",
    "    \n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        merged_dfevent3 = pd.concat(selected_dfevents3)\n",
    "        merged_dfevent3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse3 = pd.concat(selected_dfpulses3)\n",
    "        merged_dfpulse3.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        merged_selection.append((merged_dfevent3, merged_dfpulse3))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold3} and {upper_threshold3} events: {len(merged_dfpulse3)}\")\n",
    "        \n",
    "    \n",
    "    return merged_selection\n",
    "\n",
    "\n",
    "\n",
    "def heatmap(dfevent):\n",
    "    'Creates heatmap of the ions hits, based on a dfevent dataframe'\n",
    "    \n",
    "    counts_df = dfevent.groupby(['x', 'y']).size().reset_index(name='count')\n",
    "    heatmap_data = counts_df.pivot(index='y', columns='x', values='count')\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = sns.heatmap(heatmap_data, cmap='viridis',cbar_kws={'label': 'Number of events'})\n",
    "    plt.title('Ion heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "def ion_tof(dfevent,xlimits=(0,TIME_BETWEEN_PULSES),nbins=1000):\n",
    "    'Plots ion time of flight data using dfevent dataframe'\n",
    "    \n",
    "    bounded_dfevent = dfevent[dfevent.tof > xlimits[0]][dfevent.tof < xlimits[1]]\n",
    "    hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=nbins)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(bin_edges[:-1], hist)\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Number of hits per bin')\n",
    "    plt.title('Ions time of flight')\n",
    "    # plt.xlim(xlimits[0],xlimits[1])\n",
    "    plt.show()   \n",
    "    \n",
    "    \n",
    "    \n",
    "def e_tof(etof):\n",
    "    'Plots electron time of flight data using etof xarray data'\n",
    "    \n",
    "    channel_time = TIME_BETWEEN_PULSES/CHANNELS_PER_PULSE\n",
    "    \n",
    "    xaxis = np.arange(14080)*channel_time\n",
    "    avg_selected_etof = -np.mean(etof, axis=0)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(xaxis,avg_selected_etof/max(avg_selected_etof))\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Normalized signal')\n",
    "    plt.title('Electrons time of flight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def events_selection_plots(runs,thresholds,downsampling=None):\n",
    "    'Runs functions events_selection, heatmap, e_tof, ion_tof'\n",
    "    'Downsamples by downsampling integer value if one is given'\n",
    "    \n",
    "    selections = events_selection(runs,thresholds,downsampling)\n",
    "    \n",
    "    print(f'\\n Plots for selection between {thresholds[0][0]} and {thresholds[0][1]} events:')\n",
    "    selected_dfevent1, selected_dfpulse1, selected_etof1, selected_pnccd1 = selections[0]\n",
    "    heatmap(selected_dfevent1)\n",
    "    ion_tof(selected_dfevent1)\n",
    "    e_tof(selected_etof1)\n",
    "    \n",
    "    if len(selections) > 1:\n",
    "        print(f'Plots for selection between {thresholds[1][0]} and {thresholds[1][1]} events:')\n",
    "        selected_dfevent2, selected_dfpulse2, selected_etof2, selected_pnccd2 = selections[1]\n",
    "        heatmap(selected_dfevent2)\n",
    "        ion_tof(selected_dfevent2)\n",
    "        e_tof(selected_etof2)\n",
    "    \n",
    "    elif len(selections) > 2:\n",
    "        print(f'Plots for selection between {thresholds[2][0]} and {thresholds[2][1]} events:')\n",
    "        selected_dfevent3, selected_dfpulse3, selected_etof3, selected_pnccd3 = selections[2]\n",
    "        heatmap(selected_dfevent3)\n",
    "        ion_tof(selected_dfevent3)\n",
    "        e_tof(selected_etof3)\n",
    "    \n",
    "    return selections\n",
    "\n",
    "\n",
    "\n",
    "def pulse_filtered_ion_tof(dfevent,pulse_number=None,xlim=TIME_BETWEEN_PULSES):\n",
    "    'Plots ion time of flight data using dfevent dataframe'\n",
    "    \n",
    "    if pulse_number != None:\n",
    "        pulse_filtered_dfevent = dfevent[dfevent.pulseId.astype(str).str.endswith(pulse_number)]\n",
    "    else:\n",
    "        pulse_filtered_dfevent = dfevent\n",
    "    \n",
    "    bounded_dfevent = pulse_filtered_dfevent[pulse_filtered_dfevent.tof < TIME_BETWEEN_PULSES]\n",
    "    hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=1000)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(bin_edges[:-1], hist/max(hist))\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Normalized signal')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.xlim(0,xlim)\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(bin_edges[:-1], hist/max(hist))\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Normalized signal')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.xlim(0,TIME_BETWEEN_PULSES)\n",
    "    plt.yscale('log')\n",
    "    plt.show()  \n",
    "    \n",
    "    \n",
    "    \n",
    "def heatmap_with_zones(dfevent,zones):\n",
    "    'Creates heatmap of the ions hits, based on a dfevent dataframe'\n",
    "    'Draws a rectangle around zones defined by a list of tuples where each tuple represents a tilted zone (xstart, ystart, width, height, angle in degrees)'\n",
    "    \n",
    "    counts_df = dfevent.groupby(['x', 'y']).size().reset_index(name='count')\n",
    "    heatmap_data = counts_df.pivot(index='y', columns='x', values='count')\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = sns.heatmap(heatmap_data, cmap='viridis', cbar_kws={'label': 'Number of events'})\n",
    "    \n",
    "    xlim = int(ax.get_xticklabels()[0].get_text())\n",
    "    ylim = int(ax.get_yticklabels()[0].get_text())\n",
    "\n",
    "    for zone in zones:\n",
    "        x, y, width, height, angle = zone\n",
    "        x_adjusted = x - xlim\n",
    "        y_adjusted = y - ylim\n",
    "        \n",
    "        rect = plt.Rectangle((x_adjusted, y_adjusted), width, height, fill=False, edgecolor='red', lw=1, angle=angle)\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.title('Ion heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "        \n",
    "def spatial_selection(dfevent,dfpulse,etof,zones):\n",
    "    'Square selection from the heatmap using spatial coordinates'\n",
    "    'Zone is a tuple representing a zone that is not tilted (xstart, ystart, width, height)'\n",
    "    'Returns spatially selected dfevent,dfpulse,etof'\n",
    "    \n",
    "    heatmap_with_zones(dfevent,zones)\n",
    "    \n",
    "    selected_dfevents = []\n",
    "    \n",
    "    for zone in zones:\n",
    "        \n",
    "        xstart,ystart,width,height,angle = zone\n",
    "    \n",
    "        spatial_selected_dfevent = dfevent[dfevent.x > xstart][dfevent.x < xstart+width][dfevent.y > ystart][dfevent.y < ystart+height]\n",
    "        selected_dfevents.append(spatial_selected_dfevent)\n",
    "        \n",
    "    merged_dfevent = pd.concat(selected_dfevents)\n",
    "    merged_dfevent.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    spatial_selected_dfpulse = dfpulse[dfpulse.pulseId.isin(merged_dfevent.pulseId)]\n",
    "    spatial_selected_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(merged_dfevent.pulseId))\n",
    "    \n",
    "    return merged_dfevent,spatial_selected_dfpulse,spatial_selected_etof\n",
    "\n",
    "\n",
    "\n",
    "def spatial_ion_selection(dfevent,dfpulse,zones):\n",
    "    'Square ion selection from the heatmap using spatial coordinates'\n",
    "    'Zone is a tuple representing a zone that is not tilted (xstart, ystart, width, height)'\n",
    "    'Returns spatially selected dfevent,dfpulse'\n",
    "    \n",
    "    heatmap_with_zones(dfevent,zones)\n",
    "    \n",
    "    selected_dfevents = []\n",
    "    \n",
    "    for zone in zones:\n",
    "        \n",
    "        xstart,ystart,width,height,angle = zone\n",
    "    \n",
    "        spatial_selected_dfevent = dfevent[dfevent.x > xstart][dfevent.x < xstart+width][dfevent.y > ystart][dfevent.y < ystart+height]\n",
    "        selected_dfevents.append(spatial_selected_dfevent)\n",
    "        \n",
    "    merged_dfevent = pd.concat(selected_dfevents)\n",
    "    merged_dfevent.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    spatial_selected_dfpulse = dfpulse[dfpulse.pulseId.isin(merged_dfevent.pulseId)]\n",
    "    \n",
    "    return merged_dfevent,spatial_selected_dfpulse\n",
    "\n",
    "\n",
    "\n",
    "def big_ion_tof(dfevent):\n",
    "    'Plots widget of big ion time of flight data using dfevent dataframe'\n",
    "    \n",
    "    bounded_dfevent = dfevent[dfevent.tof < TIME_BETWEEN_PULSES]\n",
    "    hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=1000)\n",
    "    \n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.plot(bin_edges[:-1], hist, c='g')\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Number of hits per bin')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    \n",
    "def autoscale_y(ax,margin=0.1):\n",
    "    \"\"\"This function rescales the y-axis based on the data that is visible given the current xlim of the axis.\n",
    "    ax -- a matplotlib axes object\n",
    "    margin -- the fraction of the total height of the y-data to pad the upper and lower ylims\"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    def get_bottom_top(line):\n",
    "        xd = line.get_xdata()\n",
    "        yd = line.get_ydata()\n",
    "        lo,hi = ax.get_xlim()\n",
    "        y_displayed = yd[((xd>lo) & (xd<hi))]\n",
    "        h = np.max(y_displayed) - np.min(y_displayed)\n",
    "        bot = np.min(y_displayed)-margin*h\n",
    "        top = np.max(y_displayed)+margin*h\n",
    "        return bot,top\n",
    "\n",
    "    lines = ax.get_lines()\n",
    "    bot,top = np.inf, -np.inf\n",
    "\n",
    "    for line in lines:\n",
    "        new_bot, new_top = get_bottom_top(line)\n",
    "        if new_bot < bot: bot = new_bot\n",
    "        if new_top > top: top = new_top\n",
    "\n",
    "    ax.set_ylim(bot,top)\n",
    "    \n",
    "    \n",
    "    \n",
    "def zoomed_ion_tof(dfevent,anchor):\n",
    "    'Plots zoom around anchor point of ion time of flight data using dfevent dataframe'\n",
    "    \n",
    "    bounded_dfevent = dfevent[dfevent.tof < TIME_BETWEEN_PULSES]\n",
    "    hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=1000)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(bin_edges[:-1], hist, c='g')\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Number of hits per bin')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.xlim(anchor-1e-7,anchor+1e-7)\n",
    "    autoscale_y(ax)\n",
    "    ax.axvline(x=anchor, color='black', linestyle='--')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def power_law(x, a, b):\n",
    "    'Calibration fit power law'\n",
    "    return a * x**b\n",
    "\n",
    "\n",
    "\n",
    "def compute_calibration(calibration_lines):\n",
    "\n",
    "    # Corresponding m/q argon values\n",
    "    mq_lines = [40,20,40/3,40/4,40/5]\n",
    "    \n",
    "    # Initial guesses for parameters a and b\n",
    "    initial_guess = [1.6e13, 2]#[1.9e20, 3]\n",
    "    \n",
    "    # Perform the curve fitting\n",
    "    params, covariance = curve_fit(power_law, calibration_lines, mq_lines, p0=initial_guess, maxfev=10000)\n",
    "\n",
    "    # Extract the fitted values for a and b\n",
    "    a_fit, b_fit = params\n",
    "\n",
    "    print(f\"The fit looks as follows: m/q = {a_fit:.2e} * tof^{b_fit:.2f}\")\n",
    "    \n",
    "    return a_fit, b_fit\n",
    "\n",
    "\n",
    "\n",
    "def calibrate(backgrd_dfevent):\n",
    "    'Computes calibration by least mean squares using backgrd_dfevent'\n",
    "    'Uses user input to compute fit based on displayed plots'\n",
    "    \n",
    "    # Show a large widget ion tof\n",
    "    big_ion_tof(backgrd_dfevent)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "\n",
    "        # Ask for five numbers input\n",
    "        anchors = []\n",
    "        for i in range(5):\n",
    "            value = input(f\"Enter value Ar{i + 1}: \")\n",
    "            try:\n",
    "                anchors.append(float(value))\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a number.\")\n",
    "\n",
    "        # Show five additional plots based on inputs\n",
    "        %matplotlib inline\n",
    "        for anchor in anchors:\n",
    "            zoomed_ion_tof(backgrd_dfevent,anchor)\n",
    "\n",
    "        # Ask if the user is done\n",
    "        done_response = input(\"Are you done? (y/n): \").strip().lower()\n",
    "        if done_response == 'y':\n",
    "            done = True\n",
    "    \n",
    "    # Compute calibration fit\n",
    "    a_fit, b_fit = compute_calibration(anchors)\n",
    "    \n",
    "    return a_fit, b_fit\n",
    "\n",
    "\n",
    "\n",
    "def apply_calibration(dfevents,a_fit,b_fit):\n",
    "    'Applies calibration to each dfevent of the list of dfevents and outputs calibrated_dfevents list of dataframes with m/q column'\n",
    "        \n",
    "    calibrated_dfevents = list()\n",
    "        \n",
    "    for dfevent in dfevents:\n",
    "        dfevent['mq'] = a_fit * dfevent.tof ** b_fit\n",
    "        calibrated_dfevents.append(dfevent)\n",
    "        \n",
    "    return calibrated_dfevents\n",
    "\n",
    "\n",
    "\n",
    "def mq_selection(calibrated_dfevent,dfpulse,etof,lower_mq,upper_mq):\n",
    "    'Selects based on m/q values. Need to input calibrated_dfevent! Returns m/q selected dfevent,dfpulse,etof.'\n",
    "    \n",
    "    mqselected_dfevent = calibrated_dfevent[lower_mq < calibrated_dfevent.mq][calibrated_dfevent.mq < upper_mq]\n",
    "    mqselected_dfpulse = dfpulse[dfpulse.pulseId.isin(mqselected_dfevent.pulseId)]\n",
    "    mqselected_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(mqselected_dfevent.pulseId))\n",
    "    \n",
    "    return mqselected_dfevent,mqselected_dfpulse,mqselected_etof\n",
    "\n",
    "\n",
    "\n",
    "def find_rectangle_corners(zone):\n",
    "    \n",
    "    x, y, width, height, angle_degrees = zone\n",
    "    \n",
    "    angle_radians = np.deg2rad(angle_degrees)\n",
    "    c, s = np.cos(angle_radians), np.sin(angle_radians)\n",
    "    \n",
    "    # Calculate the coordinates of the other three corners\n",
    "    corners = np.array([\n",
    "        [x, y],\n",
    "        [x + width * c, y + width * s],\n",
    "        [x + width * c - height * s, y + width * s + height * c],\n",
    "        [x - height * s, y + height * c]\n",
    "    ])\n",
    "    \n",
    "    return corners\n",
    "\n",
    "\n",
    "\n",
    "def find_integer_coordinates(corners, zone):\n",
    "    \n",
    "    min_x, min_y = np.floor(np.min(corners, axis=0))\n",
    "    max_x, max_y = np.ceil(np.max(corners, axis=0))\n",
    "\n",
    "    integer_coordinates = []\n",
    "    for x in range(int(min_x), int(max_x) + 1):\n",
    "        for y in range(int(min_y), int(max_y) + 1):\n",
    "            if is_inside(x, y, corners, zone):\n",
    "                integer_coordinates.append((x, y))\n",
    "    \n",
    "    return integer_coordinates\n",
    "\n",
    "\n",
    "\n",
    "def is_inside(x, y, corners, zone):\n",
    "    \n",
    "    ox, oy, width, height, angle_degrees = zone\n",
    "    \n",
    "    angle_radians = np.deg2rad(angle_degrees)\n",
    "    c, s = np.cos(angle_radians), np.sin(angle_radians)\n",
    "    \n",
    "    rotated_x = (x-ox)*c + (y-oy)*s + ox\n",
    "    rotated_y = -(x-ox)*s + (y-oy)*c + oy\n",
    "    \n",
    "    return ox <= rotated_x <= ox + width and oy <= rotated_y <= oy + height\n",
    "\n",
    "\n",
    "\n",
    "def tilted_spatial_ion_selection(dfevent,dfpulse,etof,zones):\n",
    "    'Selection from the heatmap using spatial coordinates'\n",
    "    'Zones is a list of tuple representing zones - tilted or not - (xstart, ystart, width, height, angle in degrees)'\n",
    "    'Returns spatially selected dfevent,dfpulse,etof'\n",
    "    \n",
    "    heatmap_with_zones(dfevent,zones)\n",
    "    \n",
    "    integer_coordinates = []\n",
    "    for zone in zones:\n",
    "        corners = find_rectangle_corners(zone)\n",
    "        integer_coordinates.extend(find_integer_coordinates(corners, zone))\n",
    "    \n",
    "    x_coords, y_coords = zip(*integer_coordinates)\n",
    "    \n",
    "    spatial_selected_dfevent = dfevent[dfevent.x.isin(x_coords)][dfevent.y.isin(y_coords)]\n",
    "    spatial_selected_dfpulse = dfpulse[dfpulse.pulseId.isin(spatial_selected_dfevent.pulseId)]\n",
    "    spatial_selected_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(spatial_selected_dfevent.pulseId))\n",
    "    \n",
    "    return spatial_selected_dfevent,spatial_selected_dfpulse,spatial_selected_etof\n",
    "\n",
    "\n",
    "\n",
    "def fish_plot_ion_selection(dfevent,zone):\n",
    "    'Selection from the heatmap using spatial coordinates'\n",
    "    'Zone is a tuple representing a zone - tilted or not - (xstart, ystart, width, height, angle in degrees)'\n",
    "    'Returns spatially selected dfevent'\n",
    "    \n",
    "    heatmap_with_zones(dfevent,[zone])\n",
    "    \n",
    "    corners = find_rectangle_corners(zone)\n",
    "    integer_coordinates = find_integer_coordinates(corners, zone)\n",
    "    \n",
    "    x_coords, y_coords = zip(*integer_coordinates)\n",
    "    \n",
    "    spatial_selected_dfevent = dfevent[dfevent.x.isin(x_coords)][dfevent.y.isin(y_coords)]\n",
    "    \n",
    "    return spatial_selected_dfevent\n",
    "    \n",
    "\n",
    "\n",
    "def fish_plot_x(dfevent,zone,tof_bins=1000,mq_bins=500):\n",
    "    'Produces fish plots along x with respect to time of flight and m/q from dfevent dataframe and a zone defined as (startx, starty, width, height, angle in degrees)'\n",
    "    \n",
    "    fish_dfevent = fish_plot_ion_selection(dfevent,zone)\n",
    "    \n",
    "    tof_bin_edges = np.linspace(0,TIME_BETWEEN_PULSES,tof_bins+1)\n",
    "    fish_dfevent['tof_binned'] = pd.cut(fish_dfevent['tof'], bins=tof_bin_edges, labels=tof_bin_edges[:-1].astype('str'))\n",
    "    tof_pivot_table = fish_dfevent.pivot_table(index='x', columns='tof_binned', aggfunc='size', fill_value=0)\n",
    "    max_tof_value = tof_pivot_table.values.max()\n",
    "    normalized_tof = tof_pivot_table.values / max_tof_value\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "    fish_dfevent['mq_binned'] = pd.cut(fish_dfevent['mq'], bins=mq_bin_edges, labels=mq_bin_edges[:-1].astype('str'))\n",
    "    mq_pivot_table = fish_dfevent.pivot_table(index='x', columns='mq_binned', aggfunc='size', fill_value=0)\n",
    "    max_mq_value = mq_pivot_table.values.max()\n",
    "    normalized_mq = mq_pivot_table.values / max_mq_value\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(30, 12))\n",
    "    \n",
    "    cax_tof = axes[0].imshow(normalized_tof, cmap='viridis', aspect='auto', norm=LogNorm(), extent=[tof_bin_edges.min(), tof_bin_edges.max(), 0, 1])\n",
    "    axes[0].set_xlabel('Time of flight (s)')\n",
    "    axes[0].set_xlim(0,5e-7)\n",
    "    axes[0].set_ylabel('x')\n",
    "    axes[0].set_yticklabels(np.linspace(256,0,6,dtype=int))\n",
    "    axes[0].set_title('Fish plot along x with respect to time of flight')\n",
    "    cbar = plt.colorbar(cax_tof, ax=axes[0], label='Normalized number of events', norm=LogNorm())\n",
    "    \n",
    "    cax_mq = axes[1].imshow(normalized_mq, cmap='viridis', aspect='auto', norm=LogNorm(), extent=[mq_bin_edges.min(), mq_bin_edges.max(), 0, 1])\n",
    "    axes[1].set_xlabel('m/q')\n",
    "    axes[1].set_ylabel('x')\n",
    "    axes[1].set_yticklabels(np.linspace(256,0,6,dtype=int))\n",
    "    axes[1].set_title('Fish plot along x with respect to m/q')\n",
    "    cbar = plt.colorbar(cax_mq, ax=axes[1], label='Normalized number of events', norm=LogNorm())\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "def fish_plot_y(dfevent,zone,tof_bins=1000,mq_bins=500):\n",
    "    'Produces a fish plot along y from dfevent dataframe and a zone defined as (startx, starty, width, height, angle in degrees)'\n",
    "    \n",
    "    fish_dfevent = fish_plot_ion_selection(dfevent,zone)\n",
    "    \n",
    "    tof_bin_edges = np.linspace(0,TIME_BETWEEN_PULSES,tof_bins+1)\n",
    "    fish_dfevent['tof_binned'] = pd.cut(fish_dfevent['tof'], bins=tof_bin_edges, labels=tof_bin_edges[:-1].astype('str'))\n",
    "    tof_pivot_table = fish_dfevent.pivot_table(index='y', columns='tof_binned', aggfunc='size', fill_value=0)\n",
    "    max_tof_value = tof_pivot_table.values.max()\n",
    "    normalized_tof = tof_pivot_table.values / max_tof_value\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "    fish_dfevent['mq_binned'] = pd.cut(fish_dfevent['mq'], bins=mq_bin_edges, labels=mq_bin_edges[:-1].astype('str'))\n",
    "    mq_pivot_table = fish_dfevent.pivot_table(index='y', columns='mq_binned', aggfunc='size', fill_value=0)\n",
    "    max_mq_value = mq_pivot_table.values.max()\n",
    "    normalized_mq = mq_pivot_table.values / max_mq_value\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(30, 12))\n",
    "    \n",
    "    cax_tof = axes[0].imshow(normalized_tof, cmap='viridis', aspect='auto', norm=LogNorm(), extent=[tof_bin_edges.min(), tof_bin_edges.max(), 0, 1])\n",
    "    axes[0].set_xlabel('Time of flight (s)')\n",
    "    axes[0].set_ylabel('y')\n",
    "    axes[0].set_yticklabels(np.linspace(256,0,6,dtype=int))\n",
    "    axes[0].set_title('Fish plot along y with respect to time of flight')\n",
    "    cbar = plt.colorbar(cax_tof, ax=axes[0], label='Normalized number of events', norm=LogNorm())\n",
    "    \n",
    "    cax_mq = axes[1].imshow(normalized_mq, cmap='viridis', aspect='auto', norm=LogNorm(), extent=[mq_bin_edges.min(), mq_bin_edges.max(), 0, 1])\n",
    "    axes[1].set_xlabel('m/q')\n",
    "    axes[1].set_ylabel('y')\n",
    "    axes[1].set_yticklabels(np.linspace(256,0,6,dtype=int))\n",
    "    axes[1].set_title('Fish plot along y with respect to m/q')\n",
    "    cbar = plt.colorbar(cax_mq, ax=axes[1], label='Normalized number of events', norm=LogNorm())\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def big_mq_plot(dfevent,nbins_mq=1500,xlimits=(0,200)):\n",
    "    'Plots big intensity vs m/q plot using dfevent'\n",
    "    \n",
    "    x_lower, x_upper = xlimits\n",
    "    \n",
    "    plt.figure(figsize=(18,8))\n",
    "        \n",
    "    hist, bin_edges = np.histogram(dfevent.mq, bins=np.linspace(0,200,nbins_mq+1))\n",
    "    plt.plot(bin_edges[:-1], hist/max(hist))\n",
    "    \n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Relatively normalized number of hits per bin')\n",
    "    plt.title('Normalized ions time of flight')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1621cdee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def nevents_binning(dfevent,dfpulse,etof,nbins_events,nbins_mq):\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse) and nbins sized array of histograms'\n",
    "    'hists is divided by number of pulses in a certain number of events bin'\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfevents = []\n",
    "    filtered_dfpulses = []\n",
    "    filtered_etofs = []\n",
    "    hists = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "        filtered_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(filtered_dfpulse.pulseId))\n",
    "\n",
    "        filtered_dfevents.append(filtered_dfevent)\n",
    "        filtered_dfpulses.append(filtered_dfpulse)\n",
    "        filtered_etofs.append(filtered_etof)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.mq, bins=np.linspace(0,200,nbins_mq+1),range=(0,200))\n",
    "        hists.append(hist/len(filtered_dfpulse))\n",
    "        \n",
    "    return filtered_dfevents, filtered_dfpulses, filtered_etofs, np.array(hists), bins\n",
    "\n",
    "\n",
    "\n",
    "def nevents_binning_tof(dfevent,dfpulse,etof,nbins_events,nbins_tof):\n",
    "    'Bins into time of flight bins'\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse) and nbins sized array of histograms'\n",
    "    'hists is divided by number of pulses in a certain number of events bin'\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfevents = []\n",
    "    filtered_dfpulses = []\n",
    "    filtered_etofs = []\n",
    "    hists = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "        filtered_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(filtered_dfpulse.pulseId))\n",
    "\n",
    "        filtered_dfevents.append(filtered_dfevent)\n",
    "        filtered_dfpulses.append(filtered_dfpulse)\n",
    "        filtered_etofs.append(filtered_etof)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.tof, bins=np.linspace(0,TIME_BETWEEN_PULSES,nbins_tof+1),range=(0,TIME_BETWEEN_PULSES))\n",
    "        hists.append(hist/len(filtered_dfpulse))\n",
    "        \n",
    "    return filtered_dfevents, filtered_dfpulses, filtered_etofs, np.array(hists), bins\n",
    "\n",
    "\n",
    "\n",
    "def nions_binning(dfevent,dfpulse,nbins_events,nbins_mq):\n",
    "    'Only handles ions'\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse) and nbins sized array of histograms'\n",
    "    'hists is divided by number of pulses in a certain number of events bin'\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfevents = []\n",
    "    filtered_dfpulses = []\n",
    "    hists = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "\n",
    "        filtered_dfevents.append(filtered_dfevent)\n",
    "        filtered_dfpulses.append(filtered_dfpulse)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.mq, bins=np.linspace(0,200,nbins_mq+1),range=(0,200))\n",
    "        hists.append(hist/len(filtered_dfpulse))\n",
    "        \n",
    "    return filtered_dfevents, filtered_dfpulses, np.array(hists), bins\n",
    "\n",
    "\n",
    "\n",
    "def nions_binning_tof(dfevent,dfpulse,nbins_events,nbins_tof):\n",
    "    'Bins into time of flight bins'\n",
    "    'Only handles ions'\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse) and nbins sized array of histograms'\n",
    "    'hists is divided by number of pulses in a certain number of events bin'\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfevents = []\n",
    "    filtered_dfpulses = []\n",
    "    hists = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "\n",
    "        filtered_dfevents.append(filtered_dfevent)\n",
    "        filtered_dfpulses.append(filtered_dfpulse)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.tof, bins=np.linspace(0,TIME_BETWEEN_PULSES,nbins_tof+1),range=(0,TIME_BETWEEN_PULSES))\n",
    "        hists.append(hist/len(filtered_dfpulse))\n",
    "        \n",
    "    return filtered_dfevents, filtered_dfpulses, np.array(hists), bins\n",
    "\n",
    "\n",
    "\n",
    "def nevents_binning_plot(dfevent,dfpulse,nbins_events,nbins_mq,xlimits=(0,200)):\n",
    "    'Bins by m/q'\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse)'\n",
    "    \n",
    "    x_lower, x_upper = xlimits\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfs = []\n",
    "    plt.figure(figsize=(20,8))\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "\n",
    "        filtered_dfs.append((filtered_dfevent,filtered_dfpulse))\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.mq, bins=np.linspace(0,200,nbins_mq),range=(0,200))\n",
    "        \n",
    "        plt.plot(bin_edges[:-1], hist/max(hist), label=f'{start_edge}-{end_edge}')\n",
    "        \n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Relatively normalized number of hits per bin')\n",
    "    plt.title('Normalized ions time of flight')\n",
    "    plt.legend()\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()   \n",
    "        \n",
    "    return filtered_dfs\n",
    "\n",
    "    \n",
    "\n",
    "def nevents_binning_plot_tof(dfevent,dfpulse,nbins_events,nbins_tof,xlimits=(0,TIME_BETWEEN_PULSES)):\n",
    "    'Bins by time of flight'\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse)'\n",
    "    \n",
    "    x_lower, x_upper = xlimits\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfs = []\n",
    "    plt.figure(figsize=(20,8))\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "\n",
    "        filtered_dfs.append((filtered_dfevent,filtered_dfpulse))\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.tof, bins=np.linspace(0,TIME_BETWEEN_PULSES,nbins_tof),range=(0,TIME_BETWEEN_PULSES))\n",
    "        \n",
    "        plt.plot(bin_edges[:-1], hist/max(hist), label=f'{start_edge}-{end_edge}')\n",
    "        \n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Relatively normalized number of hits per bin')\n",
    "    plt.title('Normalized ions time of flight')\n",
    "    plt.legend()\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()   \n",
    "        \n",
    "    return filtered_dfs\n",
    "\n",
    "\n",
    "\n",
    "def nevents_binning_cov(dfevent,dfpulse,etof,nbins_events,nbins_ion_tof,nbins_e_tof,max_ion_limit=TIME_BETWEEN_PULSES,max_e_limit=TIME_BETWEEN_PULSES):\n",
    "    'Binning dfevent and etof by numbers of events, and number of bins along time of flight'\n",
    "    'Can select maximal time limit for electrons and ions'\n",
    "    \n",
    "    channel_time = TIME_BETWEEN_PULSES/CHANNELS_PER_PULSE\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    max_int_ion_limit = int(max_ion_limit/channel_time)\n",
    "    new_int_ion_limit = max_int_ion_limit - max_int_ion_limit % nbins_ion_tof\n",
    "    new_ion_limit = new_int_ion_limit*channel_time\n",
    "    \n",
    "    max_int_e_limit = int(max_e_limit/channel_time)\n",
    "    new_int_e_limit = max_int_e_limit - max_int_e_limit % nbins_e_tof\n",
    "    e_group_size = int(new_int_e_limit/nbins_e_tof)\n",
    "    \n",
    "    shortened_dfevent = dfevent[dfevent.tof < new_ion_limit]\n",
    "    shortened_etof = etof[:,:new_int_e_limit]\n",
    "    \n",
    "    hists = []\n",
    "    hists_etof = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = shortened_dfevent[shortened_dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "        filtered_etof = shortened_etof.sel(pulseId=shortened_etof.coords['pulseId'].isin(filtered_dfpulse.pulseId))\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.tof, bins=nbins_ion_tof)\n",
    "        hists.append(hist)\n",
    "        \n",
    "        numpy_etof = filtered_etof.to_numpy()\n",
    "        reshaped_etof = numpy_etof.reshape((numpy_etof.shape[0], -1, e_group_size))\n",
    "        summed_etof = np.sum(reshaped_etof, axis=-1)\n",
    "        avg_etof = -np.mean(summed_etof, axis=0)\n",
    "        hists_etof.append(avg_etof)\n",
    "        \n",
    "    hists = np.array(hists)\n",
    "    hists_etof = np.array(hists_etof)\n",
    "        \n",
    "    return hists, hists_etof, bins\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
