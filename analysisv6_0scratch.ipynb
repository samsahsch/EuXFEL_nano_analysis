{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b43ceb6",
   "metadata": {},
   "source": [
    "### Analysis code snippets for preprocessed h5 files\n",
    "\n",
    "Organized as follows:\n",
    "1. Select runs and filter based on number of hits, including choosing ions, electron and/or photon data\n",
    "2. Filter based on pulse number\n",
    "3. Calibrate runs for m/q values\n",
    "4. Heatmap and electron time of flight plots\n",
    "5. Fish plots\n",
    "6. Intensity dependent plots including into time of flight plots, waterfall plots and heatmaps\n",
    "7. Presentation plots including fish plot, heatmaps, electron and ion data\n",
    "8. Covariances between ion data and between ion and electron data\n",
    "9. PNCCD photon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a173f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Need to install reading methods the first time:\n",
    "\n",
    "pip install --user tables   ### to read dataframe\n",
    "pip install h5netcdf        ### to read xarrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87da59e",
   "metadata": {},
   "source": [
    "# Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df658959",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038ee68",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "TIME_BETWEEN_PULSES = 3.54462e-6\n",
    "CHANNELS_PER_PULSE = 14080\n",
    "channel_time = TIME_BETWEEN_PULSES/CHANNELS_PER_PULSE\n",
    "\n",
    "\n",
    "    \n",
    "def read(runid):\n",
    "    'Read the preprocessed data of run with ID runid saved in the h5 file with a corresponding name'\n",
    "    'Outputs dataframes per event, per pulse, and xarrays etof, pnccd in that order'\n",
    "    \n",
    "    filename = '../preprocess/datarun' + str(runid) + '.h5'\n",
    "    \n",
    "    dfevent = pd.read_hdf(filename, 'dfevent')\n",
    "    dfpulse = pd.read_hdf(filename, 'dfpulse')\n",
    "    \n",
    "    etof = xr.open_dataarray(filename, group=\"etof\")\n",
    "    pnccd = xr.open_dataarray(filename, group=\"pnccd\")\n",
    "    \n",
    "    return dfevent, dfpulse, etof, pnccd\n",
    "\n",
    "\n",
    "\n",
    "def read_ions_electrons(runid,tof_limit=None):\n",
    "    'Read the preprocessed data of run with ID runid saved in the h5 file with a corresponding name'\n",
    "    'Outputs dataframes per event, per pulse, and xarrays etof in that order'\n",
    "    'tof_limit limiting electron time of flight loaded in'\n",
    "    \n",
    "    filename = '../preprocess/datarun' + str(runid) + '.h5'\n",
    "    \n",
    "    dfevent = pd.read_hdf(filename, 'dfevent')\n",
    "    dfpulse = pd.read_hdf(filename, 'dfpulse')\n",
    "    \n",
    "    etof = xr.open_dataarray(filename, group=\"etof\")\n",
    "\n",
    "    if type(tof_limit) == int:\n",
    "        max_coord = int(tof_limit/channel_time)\n",
    "        etof = etof[:max_coord]\n",
    "    \n",
    "    return dfevent, dfpulse, etof\n",
    "\n",
    "\n",
    "\n",
    "def read_ions_photons(runid):\n",
    "    'Read the preprocessed data of run with ID runid saved in the h5 file with a corresponding name'\n",
    "    'Outputs dataframes per event, per pulse, and xarrays pnccd in that order'\n",
    "    \n",
    "    filename = '../preprocess/datarun' + str(runid) + '.h5'\n",
    "    \n",
    "    dfevent = pd.read_hdf(filename, 'dfevent')\n",
    "    dfpulse = pd.read_hdf(filename, 'dfpulse')\n",
    "    \n",
    "    pnccd = xr.open_dataarray(filename, group=\"pnccd\")\n",
    "    \n",
    "    return dfevent, dfpulse, pnccd\n",
    "\n",
    "\n",
    "\n",
    "def read_ion(runid):\n",
    "    'Read the preprocessed data of run with ID runid saved in the h5 file with a corresponding name'\n",
    "    'Outputs dataframes per event and per pulse'\n",
    "    \n",
    "    filename = '../preprocess/datarun' + str(runid) + '.h5'\n",
    "    \n",
    "    dfevent = pd.read_hdf(filename, 'dfevent')\n",
    "    dfpulse = pd.read_hdf(filename, 'dfpulse')\n",
    "    \n",
    "    return dfevent, dfpulse\n",
    "\n",
    "\n",
    "\n",
    "def read_pnccd(runid):\n",
    "    'Read the preprocessed data of run with ID runid saved in the h5 file with a corresponding name'\n",
    "    'Outputs dataframes per event, per pulse, and xarrays etof, pnccd in that order'\n",
    "    \n",
    "    filename = '../preprocess/datarun' + str(runid) + '.h5'\n",
    "    pnccd = xr.open_dataarray(filename, group=\"pnccd\")\n",
    "    \n",
    "    return pnccd\n",
    "\n",
    "\n",
    "\n",
    "def events_selection(runs,thresholds,num_pulses=None):\n",
    "    'Reads one or multiple runs from h5 files'\n",
    "    'Makes a pulse selection based on the number of events per pulse between the defined thresholds'\n",
    "    'If multiple runs are passed, will merge the runs, once hit selected'\n",
    "    'Thresholds can be between one and three tuples (lower threshold, upper threshold)'\n",
    "    'Downsamples by num_pulses'\n",
    "    \n",
    "    lower_threshold1, upper_threshold1 = thresholds[0]\n",
    "    selected_dfevents1 = list()\n",
    "    selected_dfpulses1 = list()\n",
    "    selected_etofs1 = list()\n",
    "    selected_pnccds1 = list()\n",
    "    \n",
    "    if len(thresholds) > 1:\n",
    "        lower_threshold2, upper_threshold2 = thresholds[1]\n",
    "        selected_dfevents2 = list()\n",
    "        selected_dfpulses2 = list()\n",
    "        selected_etofs2 = list()\n",
    "        selected_pnccds2 = list()\n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        lower_threshold3, upper_threshold3 = thresholds[2]  \n",
    "        selected_dfevents3 = list()\n",
    "        selected_dfpulses3 = list()\n",
    "        selected_etofs3 = list()\n",
    "        selected_pnccds3 = list()\n",
    "    \n",
    "    dataframes = dict()\n",
    "    \n",
    "    if type(num_pulses) == int:\n",
    "        num_pulses_run = int(num_pulses/len(runs))\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        dfevent, dfpulse, etof, pnccd = read(run)\n",
    "        \n",
    "        selections = list()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.scatter(dfpulse.pulseId,dfpulse.nevents_pulse,c='black',label='All pulses')\n",
    "        \n",
    "        if type(num_pulses) == int:\n",
    "            dfpulse = dfpulse.sample(n=num_pulses_run)\n",
    "            \n",
    "        selected_dfpulse1 = dfpulse[lower_threshold1 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold1]\n",
    "        selected_dfevent1 = dfevent[dfevent.pulseId.isin(selected_dfpulse1.pulseId)]\n",
    "        selected_etof1 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse1.pulseId))\n",
    "        selected_pnccd1 = pnccd.sel(trainId=pnccd.coords['trainId'].isin(selected_dfpulse1.trainId))\n",
    "        selections.append((selected_dfevent1, selected_dfpulse1, selected_etof1, selected_pnccd1))\n",
    "        plt.scatter(selected_dfpulse1.pulseId,selected_dfpulse1.nevents_pulse,c='r',label=f'Between {lower_threshold1} and {upper_threshold1}')\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            \n",
    "            selected_dfpulse2 = dfpulse[lower_threshold2 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold2]\n",
    "            selected_dfevent2 = dfevent[dfevent.pulseId.isin(selected_dfpulse2.pulseId)]\n",
    "            selected_etof2 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse2.pulseId))\n",
    "            selected_pnccd2 = pnccd.sel(trainId=pnccd.coords['trainId'].isin(selected_dfpulse2.trainId))\n",
    "            selections.append((selected_dfevent2, selected_dfpulse2, selected_etof2, selected_pnccd2))\n",
    "            plt.scatter(selected_dfpulse2.pulseId,selected_dfpulse2.nevents_pulse,c='blue',label=f'Between {lower_threshold2} and {upper_threshold2}')\n",
    "            \n",
    "        if len(thresholds) > 2:\n",
    "            \n",
    "            selected_dfpulse3 = dfpulse[lower_threshold3 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold3]\n",
    "            selected_dfevent3 = dfevent[dfevent.pulseId.isin(selected_dfpulse3.pulseId)]\n",
    "            selected_etof3 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse3.pulseId))\n",
    "            selected_pnccd3 = pnccd.sel(trainId=pnccd.coords['trainId'].isin(selected_dfpulse3.trainId))\n",
    "            selections.append((selected_dfevent3, selected_dfpulse3, selected_etof3, selected_pnccd3))\n",
    "            plt.scatter(selected_dfpulse3.pulseId,selected_dfpulse3.nevents_pulse,c='g',label=f'Between {lower_threshold3} and {upper_threshold3}')  \n",
    "        \n",
    "        dataframes[run] = selections\n",
    "          \n",
    "        plt.xlabel('Pulse ID')\n",
    "        plt.ylabel('Number of events per pulse')\n",
    "        plt.legend()\n",
    "        plt.title(f'Events per pulse with respect to pulse ID for run {run}')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    for key, values in dataframes.items():\n",
    "        \n",
    "        selected_dfevents1.append(values[0][0])\n",
    "        selected_dfpulses1.append(values[0][1])\n",
    "        selected_etofs1.append(values[0][2])\n",
    "        selected_pnccds1.append(values[0][3])\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            selected_dfevents2.append(values[1][0])\n",
    "            selected_dfpulses2.append(values[1][1])\n",
    "            selected_etofs2.append(values[1][2])\n",
    "            selected_pnccds2.append(values[1][3])\n",
    "            \n",
    "        if len(thresholds) > 2: \n",
    "            selected_dfevents3.append(values[2][0])\n",
    "            selected_dfpulses3.append(values[2][1])\n",
    "            selected_etofs3.append(values[2][2])\n",
    "            selected_pnccds3.append(values[2][3])\n",
    "        \n",
    "        \n",
    "    merged_selection = list()\n",
    "    \n",
    "    merged_dfevent1 = pd.concat(selected_dfevents1)\n",
    "    merged_dfevent1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_dfpulse1 = pd.concat(selected_dfpulses1)\n",
    "    merged_dfpulse1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_etof1 = xr.concat(selected_etofs1, dim='pulseId')\n",
    "    merged_pnccd1 = xr.concat(selected_pnccds1, dim='pulseId')\n",
    "    \n",
    "    merged_selection.append((merged_dfevent1, merged_dfpulse1, merged_etof1, merged_pnccd1))\n",
    "    \n",
    "    print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold1} and {upper_threshold1} events: {len(merged_dfpulse1)}\")\n",
    "       \n",
    "        \n",
    "    if len(thresholds) > 1:\n",
    "        merged_dfevent2 = pd.concat(selected_dfevents2)\n",
    "        merged_dfevent2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse2 = pd.concat(selected_dfpulses2)\n",
    "        merged_dfpulse2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_etof2 = xr.concat(selected_etofs2, dim='pulseId')\n",
    "        merged_pnccd2 = xr.concat(selected_pnccds2, dim='pulseId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent2, merged_dfpulse2, merged_etof2, merged_pnccd2))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold2} and {upper_threshold2} events: {len(merged_dfpulse2)}\")\n",
    "    \n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        merged_dfevent3 = pd.concat(selected_dfevents3)\n",
    "        merged_dfevent3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse3 = pd.concat(selected_dfpulses3)\n",
    "        merged_dfpulse3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_etof3 = xr.concat(selected_etofs3, dim='pulseId')\n",
    "        merged_pnccd3 = xr.concat(selected_pnccds3, dim='pulseId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent3, merged_dfpulse3, merged_etof3, merged_pnccd3))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold3} and {upper_threshold3} events: {len(merged_dfpulse3)}\")\n",
    "        \n",
    "    \n",
    "    return merged_selection\n",
    "\n",
    "\n",
    "\n",
    "def events_selection_ions_electrons(runs,thresholds,num_pulses=None,tof_limit=None):\n",
    "    'Reads one or multiple runs from h5 files'\n",
    "    'Makes a pulse selection based on the number of events per pulse between the defined thresholds'\n",
    "    'If multiple runs are passed, will merge the runs, once hit selected'\n",
    "    'Thresholds can be between one and three tuples (lower threshold, upper threshold)'\n",
    "    'Downsamples by num_pulses'\n",
    "    \n",
    "    lower_threshold1, upper_threshold1 = thresholds[0]\n",
    "    selected_dfevents1 = list()\n",
    "    selected_dfpulses1 = list()\n",
    "    selected_etofs1 = list()\n",
    "    \n",
    "    if len(thresholds) > 1:\n",
    "        lower_threshold2, upper_threshold2 = thresholds[1]\n",
    "        selected_dfevents2 = list()\n",
    "        selected_dfpulses2 = list()\n",
    "        selected_etofs2 = list()\n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        lower_threshold3, upper_threshold3 = thresholds[2]  \n",
    "        selected_dfevents3 = list()\n",
    "        selected_dfpulses3 = list()\n",
    "        selected_etofs3 = list()\n",
    "    \n",
    "    dataframes = dict()\n",
    "    \n",
    "    if type(num_pulses) == int:\n",
    "        num_pulses_run = int(num_pulses/len(runs))\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        dfevent, dfpulse, etof = read_ions_electrons(run,tof_limit)\n",
    "        \n",
    "        selections = list()\n",
    "        \n",
    "        if type(num_pulses) == int:\n",
    "            dfpulse = dfpulse.sample(n=num_pulses_run)\n",
    "            \n",
    "        selected_dfpulse1 = dfpulse[lower_threshold1 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold1]\n",
    "        selected_dfevent1 = dfevent[dfevent.pulseId.isin(selected_dfpulse1.pulseId)]\n",
    "        selected_etof1 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse1.pulseId))\n",
    "        selections.append((selected_dfevent1, selected_dfpulse1, selected_etof1))\n",
    "        plt.scatter(selected_dfpulse1.pulseId,selected_dfpulse1.nevents_pulse,c='r',label=f'Between {lower_threshold1} and {upper_threshold1}')\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            \n",
    "            selected_dfpulse2 = dfpulse[lower_threshold2 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold2]\n",
    "            selected_dfevent2 = dfevent[dfevent.pulseId.isin(selected_dfpulse2.pulseId)]\n",
    "            selected_etof2 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse2.pulseId))\n",
    "            selections.append((selected_dfevent2, selected_dfpulse2, selected_etof2))\n",
    "            plt.scatter(selected_dfpulse2.pulseId,selected_dfpulse2.nevents_pulse,c='blue',label=f'Between {lower_threshold2} and {upper_threshold2}')\n",
    "            \n",
    "        if len(thresholds) > 2:\n",
    "            \n",
    "            selected_dfpulse3 = dfpulse[lower_threshold3 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold3]\n",
    "            selected_dfevent3 = dfevent[dfevent.pulseId.isin(selected_dfpulse3.pulseId)]\n",
    "            selected_etof3 = etof.sel(pulseId=etof.coords['pulseId'].isin(selected_dfpulse3.pulseId))\n",
    "            selections.append((selected_dfevent3, selected_dfpulse3, selected_etof3))\n",
    "            plt.scatter(selected_dfpulse3.pulseId,selected_dfpulse3.nevents_pulse,c='g',label=f'Between {lower_threshold3} and {upper_threshold3}')  \n",
    "        \n",
    "        dataframes[run] = selections\n",
    "        \n",
    "    for key, values in dataframes.items():\n",
    "        \n",
    "        selected_dfevents1.append(values[0][0])\n",
    "        selected_dfpulses1.append(values[0][1])\n",
    "        selected_etofs1.append(values[0][2])\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            selected_dfevents2.append(values[1][0])\n",
    "            selected_dfpulses2.append(values[1][1])\n",
    "            selected_etofs2.append(values[1][2])\n",
    "            \n",
    "        if len(thresholds) > 2: \n",
    "            selected_dfevents3.append(values[2][0])\n",
    "            selected_dfpulses3.append(values[2][1])\n",
    "            selected_etofs3.append(values[2][2])\n",
    "        \n",
    "    merged_selection = list()\n",
    "    \n",
    "    merged_dfevent1 = pd.concat(selected_dfevents1)\n",
    "    merged_dfevent1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_dfpulse1 = pd.concat(selected_dfpulses1)\n",
    "    merged_dfpulse1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_etof1 = xr.concat(selected_etofs1, dim='pulseId')\n",
    "    \n",
    "    merged_selection.append((merged_dfevent1, merged_dfpulse1, merged_etof1))\n",
    "    \n",
    "    print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold1} and {upper_threshold1} events: {len(merged_dfpulse1)}\")\n",
    "           \n",
    "    if len(thresholds) > 1:\n",
    "        merged_dfevent2 = pd.concat(selected_dfevents2)\n",
    "        merged_dfevent2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse2 = pd.concat(selected_dfpulses2)\n",
    "        merged_dfpulse2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_etof2 = xr.concat(selected_etofs2, dim='pulseId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent2, merged_dfpulse2, merged_etof2))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold2} and {upper_threshold2} events: {len(merged_dfpulse2)}\") \n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        merged_dfevent3 = pd.concat(selected_dfevents3)\n",
    "        merged_dfevent3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse3 = pd.concat(selected_dfpulses3)\n",
    "        merged_dfpulse3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_etof3 = xr.concat(selected_etofs3, dim='pulseId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent3, merged_dfpulse3, merged_etof3))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold3} and {upper_threshold3} events: {len(merged_dfpulse3)}\")\n",
    "        \n",
    "    return merged_selection\n",
    "\n",
    "\n",
    "\n",
    "def events_selection_ions_photons(runs,thresholds,num_pulses=None):\n",
    "    'Reads one or multiple runs from h5 files'\n",
    "    'Makes a pulse selection based on the number of events per pulse between the defined thresholds'\n",
    "    'If multiple runs are passed, will merge the runs, once hit selected'\n",
    "    'Thresholds can be between one and three tuples (lower threshold, upper threshold)'\n",
    "    'Downsamples by num_pulses'\n",
    "    \n",
    "    lower_threshold1, upper_threshold1 = thresholds[0]\n",
    "    selected_dfevents1 = list()\n",
    "    selected_dfpulses1 = list()\n",
    "    selected_pnccds1 = list()\n",
    "    \n",
    "    if len(thresholds) > 1:\n",
    "        lower_threshold2, upper_threshold2 = thresholds[1]\n",
    "        selected_dfevents2 = list()\n",
    "        selected_dfpulses2 = list()\n",
    "        selected_pnccds2 = list()\n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        lower_threshold3, upper_threshold3 = thresholds[2]  \n",
    "        selected_dfevents3 = list()\n",
    "        selected_dfpulses3 = list()\n",
    "        selected_pnccds3 = list()\n",
    "    \n",
    "    dataframes = dict()\n",
    "    \n",
    "    if type(num_pulses) == int:\n",
    "        num_pulses_run = int(num_pulses/len(runs))\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        print('Processing run number',run)\n",
    "        \n",
    "        dfevent, dfpulse, pnccd = read_ions_photons(run)\n",
    "        \n",
    "        selections = list()\n",
    "        \n",
    "        if type(num_pulses) == int:\n",
    "            dfpulse = dfpulse.sample(n=num_pulses_run)\n",
    "            \n",
    "        selected_dfpulse1 = dfpulse[lower_threshold1 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold1]\n",
    "        selected_dfevent1 = dfevent[dfevent.pulseId.isin(selected_dfpulse1.pulseId)]\n",
    "        selected_pnccd1 = pnccd.sel(trainId=pnccd.coords['trainId'].isin(selected_dfpulse1.trainId))\n",
    "        selections.append((selected_dfevent1, selected_dfpulse1, selected_pnccd1))\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            \n",
    "            selected_dfpulse2 = dfpulse[lower_threshold2 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold2]\n",
    "            selected_dfevent2 = dfevent[dfevent.pulseId.isin(selected_dfpulse2.pulseId)]\n",
    "            selected_pnccd2 = pnccd.sel(trainId=pnccd.coords['trainId'].isin(selected_dfpulse2.trainId))\n",
    "            selections.append((selected_dfevent2, selected_dfpulse2, selected_pnccd2))\n",
    "            \n",
    "        if len(thresholds) > 2:\n",
    "            \n",
    "            selected_dfpulse3 = dfpulse[lower_threshold3 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold3]\n",
    "            selected_dfevent3 = dfevent[dfevent.pulseId.isin(selected_dfpulse3.pulseId)]\n",
    "            selected_pnccd3 = pnccd.sel(trainId=pnccd.coords['trainId'].isin(selected_dfpulse3.trainId))\n",
    "            selections.append((selected_dfevent3, selected_dfpulse3, selected_pnccd3))\n",
    "            \n",
    "        dataframes[run] = selections\n",
    "        \n",
    "    for key, values in dataframes.items():\n",
    "        \n",
    "        selected_dfevents1.append(values[0][0])\n",
    "        selected_dfpulses1.append(values[0][1])\n",
    "        selected_pnccds1.append(values[0][2])\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            selected_dfevents2.append(values[1][0])\n",
    "            selected_dfpulses2.append(values[1][1])\n",
    "            selected_pnccds2.append(values[1][2])\n",
    "            \n",
    "        if len(thresholds) > 2: \n",
    "            selected_dfevents3.append(values[2][0])\n",
    "            selected_dfpulses3.append(values[2][1])\n",
    "            selected_pnccds3.append(values[2][2])\n",
    "        \n",
    "        \n",
    "    merged_selection = list()\n",
    "    \n",
    "    merged_dfevent1 = pd.concat(selected_dfevents1)\n",
    "    merged_dfevent1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_dfpulse1 = pd.concat(selected_dfpulses1)\n",
    "    merged_dfpulse1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_pnccd1 = xr.concat(selected_pnccds1, dim='trainId')\n",
    "    \n",
    "    merged_selection.append((merged_dfevent1, merged_dfpulse1, merged_pnccd1))\n",
    "    \n",
    "    print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold1} and {upper_threshold1} events: {len(merged_dfpulse1)}\")\n",
    "       \n",
    "        \n",
    "    if len(thresholds) > 1:\n",
    "        merged_dfevent2 = pd.concat(selected_dfevents2)\n",
    "        merged_dfevent2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse2 = pd.concat(selected_dfpulses2)\n",
    "        merged_dfpulse2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_pnccd2 = xr.concat(selected_pnccds2, dim='trainId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent2, merged_dfpulse2, merged_pnccd2))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold2} and {upper_threshold2} events: {len(merged_dfpulse2)}\")\n",
    "    \n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        merged_dfevent3 = pd.concat(selected_dfevents3)\n",
    "        merged_dfevent3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse3 = pd.concat(selected_dfpulses3)\n",
    "        merged_dfpulse3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_pnccd3 = xr.concat(selected_pnccds3, dim='trainId')\n",
    "        \n",
    "        merged_selection.append((merged_dfevent3, merged_dfpulse3, merged_pnccd3))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold3} and {upper_threshold3} events: {len(merged_dfpulse3)}\")\n",
    "\n",
    "    \n",
    "    return merged_selection\n",
    "\n",
    "\n",
    "\n",
    "def ion_selection(runs,thresholds,num_pulses=None):\n",
    "    'Only handles ion data'\n",
    "    'Reads one or multiple runs from h5 files'\n",
    "    'Makes a pulse selection based on the number of events per pulse between the defined thresholds'\n",
    "    'If multiple runs are passed, will merge the runs, once hit selected'\n",
    "    'Thresholds can be between one and three tuples (lower threshold, upper threshold)'\n",
    "    'Downsamples by num_pulses'\n",
    "    \n",
    "    lower_threshold1, upper_threshold1 = thresholds[0]\n",
    "    selected_dfevents1 = list()\n",
    "    selected_dfpulses1 = list()\n",
    "    \n",
    "    if len(thresholds) > 1:\n",
    "        lower_threshold2, upper_threshold2 = thresholds[1]\n",
    "        selected_dfevents2 = list()\n",
    "        selected_dfpulses2 = list()\n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        lower_threshold3, upper_threshold3 = thresholds[2]  \n",
    "        selected_dfevents3 = list()\n",
    "        selected_dfpulses3 = list()\n",
    "    \n",
    "    dataframes = dict()\n",
    "    \n",
    "    if type(num_pulses) == int:\n",
    "        num_pulses_run = int(num_pulses/len(runs))\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        print('Handling run', run)\n",
    "        dfevent, dfpulse = read_ion(run)\n",
    "        \n",
    "        selections = list()\n",
    "        # plt.figure()\n",
    "        # plt.scatter(dfpulse.pulseId,dfpulse.nevents_pulse,c='black',label='All pulses')\n",
    "        \n",
    "        if type(num_pulses) == int:\n",
    "            dfpulse = dfpulse.sample(n=num_pulses_run)\n",
    "            \n",
    "        selected_dfpulse1 = dfpulse[lower_threshold1 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold1]\n",
    "        selected_dfevent1 = dfevent[dfevent.pulseId.isin(selected_dfpulse1.pulseId)]\n",
    "        selections.append((selected_dfevent1, selected_dfpulse1))\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            \n",
    "            selected_dfpulse2 = dfpulse[lower_threshold2 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold2]\n",
    "            selected_dfevent2 = dfevent[dfevent.pulseId.isin(selected_dfpulse2.pulseId)]\n",
    "            selections.append((selected_dfevent2, selected_dfpulse2))\n",
    "            \n",
    "        if len(thresholds) > 2:\n",
    "            \n",
    "            selected_dfpulse3 = dfpulse[lower_threshold3 < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold3]\n",
    "            selected_dfevent3 = dfevent[dfevent.pulseId.isin(selected_dfpulse3.pulseId)]\n",
    "            selections.append((selected_dfevent3, selected_dfpulse3))\n",
    "        \n",
    "        dataframes[run] = selections\n",
    "          \n",
    "        # plt.xlabel('Pulse ID')\n",
    "        # plt.ylabel('Number of events per pulse')\n",
    "        # plt.legend()\n",
    "        # plt.title(f'Events per pulse with respect to pulse ID for run {run}')\n",
    "        # plt.show()\n",
    "\n",
    "        \n",
    "    for key, values in dataframes.items():\n",
    "        \n",
    "        selected_dfevents1.append(values[0][0])\n",
    "        selected_dfpulses1.append(values[0][1])\n",
    "        \n",
    "        if len(thresholds) > 1:\n",
    "            selected_dfevents2.append(values[1][0])\n",
    "            selected_dfpulses2.append(values[1][1])\n",
    "            \n",
    "        if len(thresholds) > 2: \n",
    "            selected_dfevents3.append(values[2][0])\n",
    "            selected_dfpulses3.append(values[2][1])\n",
    "        \n",
    "        \n",
    "    merged_selection = list()\n",
    "    \n",
    "    merged_dfevent1 = pd.concat(selected_dfevents1)\n",
    "    merged_dfevent1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_dfpulse1 = pd.concat(selected_dfpulses1)\n",
    "    merged_dfpulse1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    merged_selection.append((merged_dfevent1, merged_dfpulse1))\n",
    "    \n",
    "    print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold1} and {upper_threshold1} events: {len(merged_dfpulse1)}\")\n",
    "       \n",
    "        \n",
    "    if len(thresholds) > 1:\n",
    "        merged_dfevent2 = pd.concat(selected_dfevents2)\n",
    "        merged_dfevent2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse2 = pd.concat(selected_dfpulses2)\n",
    "        merged_dfpulse2.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        merged_selection.append((merged_dfevent2, merged_dfpulse2))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold2} and {upper_threshold2} events: {len(merged_dfpulse2)}\")\n",
    "    \n",
    "    \n",
    "    if len(thresholds) > 2:\n",
    "        merged_dfevent3 = pd.concat(selected_dfevents3)\n",
    "        merged_dfevent3.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        merged_dfpulse3 = pd.concat(selected_dfpulses3)\n",
    "        merged_dfpulse3.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        merged_selection.append((merged_dfevent3, merged_dfpulse3))\n",
    "        \n",
    "        print(f\"Number of pulses selected across {len(runs)} run(s) between {lower_threshold3} and {upper_threshold3} events: {len(merged_dfpulse3)}\")\n",
    "        \n",
    "    \n",
    "    return merged_selection\n",
    "\n",
    "\n",
    "\n",
    "def heatmap(dfevent):\n",
    "    'Creates heatmap of the ions hits, based on a dfevent dataframe'\n",
    "    \n",
    "    counts_df = dfevent.groupby(['x', 'y']).size().reset_index(name='count')\n",
    "    heatmap_data = counts_df.pivot(index='y', columns='x', values='count')\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = sns.heatmap(heatmap_data, cmap='viridis',cbar_kws={'label': 'Number of events'})\n",
    "    plt.title('Ion heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "def ion_tof(dfevent,xlimits=(0,TIME_BETWEEN_PULSES),nbins=1000):\n",
    "    'Plots ion time of flight data using dfevent dataframe'\n",
    "    \n",
    "    bounded_dfevent = dfevent[dfevent.tof > xlimits[0]][dfevent.tof < xlimits[1]]\n",
    "    hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=nbins)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(bin_edges[:-1], hist)\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Number of hits per bin')\n",
    "    plt.title('Ions time of flight')\n",
    "    # plt.xlim(xlimits[0],xlimits[1])\n",
    "    plt.show()   \n",
    "    \n",
    "    \n",
    "    \n",
    "def e_tof(etof):\n",
    "    'Plots electron time of flight data using etof xarray data'\n",
    "    \n",
    "    channel_time = TIME_BETWEEN_PULSES/CHANNELS_PER_PULSE\n",
    "    \n",
    "    xaxis = np.arange(14080)*channel_time\n",
    "    avg_selected_etof = -np.mean(etof, axis=0)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(xaxis,avg_selected_etof/max(avg_selected_etof))\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Normalized signal')\n",
    "    plt.title('Electrons time of flight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def events_selection_plots(runs,thresholds,downsampling=None):\n",
    "    'Runs functions events_selection, heatmap, e_tof, ion_tof'\n",
    "    'Downsamples by downsampling integer value if one is given'\n",
    "    \n",
    "    selections = events_selection(runs,thresholds,downsampling)\n",
    "    \n",
    "    print(f'\\n Plots for selection between {thresholds[0][0]} and {thresholds[0][1]} events:')\n",
    "    selected_dfevent1, selected_dfpulse1, selected_etof1, selected_pnccd1 = selections[0]\n",
    "    heatmap(selected_dfevent1)\n",
    "    ion_tof(selected_dfevent1)\n",
    "    e_tof(selected_etof1)\n",
    "    \n",
    "    if len(selections) > 1:\n",
    "        print(f'Plots for selection between {thresholds[1][0]} and {thresholds[1][1]} events:')\n",
    "        selected_dfevent2, selected_dfpulse2, selected_etof2, selected_pnccd2 = selections[1]\n",
    "        heatmap(selected_dfevent2)\n",
    "        ion_tof(selected_dfevent2)\n",
    "        e_tof(selected_etof2)\n",
    "    \n",
    "    elif len(selections) > 2:\n",
    "        print(f'Plots for selection between {thresholds[2][0]} and {thresholds[2][1]} events:')\n",
    "        selected_dfevent3, selected_dfpulse3, selected_etof3, selected_pnccd3 = selections[2]\n",
    "        heatmap(selected_dfevent3)\n",
    "        ion_tof(selected_dfevent3)\n",
    "        e_tof(selected_etof3)\n",
    "    \n",
    "    return selections\n",
    "\n",
    "\n",
    "\n",
    "def pulse_filtered_ion_tof(dfevent,pulse_number=None,xlim=TIME_BETWEEN_PULSES):\n",
    "    'Plots ion time of flight data using dfevent dataframe'\n",
    "    \n",
    "    if pulse_number != None:\n",
    "        pulse_filtered_dfevent = dfevent[dfevent.pulseId.astype(str).str.endswith(pulse_number)]\n",
    "    else:\n",
    "        pulse_filtered_dfevent = dfevent\n",
    "    \n",
    "    bounded_dfevent = pulse_filtered_dfevent[pulse_filtered_dfevent.tof < TIME_BETWEEN_PULSES]\n",
    "    hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=1000)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(bin_edges[:-1], hist/max(hist))\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Normalized signal')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.xlim(0,xlim)\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(bin_edges[:-1], hist/max(hist))\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Normalized signal')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.xlim(0,TIME_BETWEEN_PULSES)\n",
    "    plt.yscale('log')\n",
    "    plt.show()  \n",
    "    \n",
    "    \n",
    "    \n",
    "def heatmap_with_zones(dfevent,zones):\n",
    "    'Creates heatmap of the ions hits, based on a dfevent dataframe'\n",
    "    'Draws a rectangle around zones defined by a list of tuples where each tuple represents a tilted zone (xstart, ystart, width, height, angle in degrees)'\n",
    "    \n",
    "    counts_df = dfevent.groupby(['x', 'y']).size().reset_index(name='count')\n",
    "    heatmap_data = counts_df.pivot(index='y', columns='x', values='count')\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = sns.heatmap(heatmap_data, cmap='viridis', cbar_kws={'label': 'Number of events'})\n",
    "    \n",
    "    xlim = int(ax.get_xticklabels()[0].get_text())\n",
    "    ylim = int(ax.get_yticklabels()[0].get_text())\n",
    "\n",
    "    for zone in zones:\n",
    "        x, y, width, height, angle = zone\n",
    "        x_adjusted = x - xlim\n",
    "        y_adjusted = y - ylim\n",
    "        \n",
    "        rect = plt.Rectangle((x_adjusted, y_adjusted), width, height, fill=False, edgecolor='red', lw=1, angle=angle)\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.title('Ion heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "        \n",
    "def spatial_selection(dfevent,dfpulse,etof,zones):\n",
    "    'Square selection from the heatmap using spatial coordinates'\n",
    "    'Zone is a tuple representing a zone that is not tilted (xstart, ystart, width, height)'\n",
    "    'Returns spatially selected dfevent,dfpulse,etof'\n",
    "    \n",
    "    heatmap_with_zones(dfevent,zones)\n",
    "    \n",
    "    selected_dfevents = []\n",
    "    \n",
    "    for zone in zones:\n",
    "        \n",
    "        xstart,ystart,width,height,angle = zone\n",
    "    \n",
    "        spatial_selected_dfevent = dfevent[dfevent.x > xstart][dfevent.x < xstart+width][dfevent.y > ystart][dfevent.y < ystart+height]\n",
    "        selected_dfevents.append(spatial_selected_dfevent)\n",
    "        \n",
    "    merged_dfevent = pd.concat(selected_dfevents)\n",
    "    merged_dfevent.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    spatial_selected_dfpulse = dfpulse[dfpulse.pulseId.isin(merged_dfevent.pulseId)]\n",
    "    spatial_selected_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(merged_dfevent.pulseId))\n",
    "    \n",
    "    return merged_dfevent,spatial_selected_dfpulse,spatial_selected_etof\n",
    "\n",
    "\n",
    "\n",
    "def spatial_ion_selection(dfevent,dfpulse,zones):\n",
    "    'Square ion selection from the heatmap using spatial coordinates'\n",
    "    'Zone is a tuple representing a zone that is not tilted (xstart, ystart, width, height)'\n",
    "    'Returns spatially selected dfevent,dfpulse'\n",
    "    \n",
    "    heatmap_with_zones(dfevent,zones)\n",
    "    \n",
    "    selected_dfevents = []\n",
    "    \n",
    "    for zone in zones:\n",
    "        \n",
    "        xstart,ystart,width,height,angle = zone\n",
    "    \n",
    "        spatial_selected_dfevent = dfevent[dfevent.x > xstart][dfevent.x < xstart+width][dfevent.y > ystart][dfevent.y < ystart+height]\n",
    "        selected_dfevents.append(spatial_selected_dfevent)\n",
    "        \n",
    "    merged_dfevent = pd.concat(selected_dfevents)\n",
    "    merged_dfevent.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    spatial_selected_dfpulse = dfpulse[dfpulse.pulseId.isin(merged_dfevent.pulseId)]\n",
    "    \n",
    "    return merged_dfevent,spatial_selected_dfpulse\n",
    "\n",
    "\n",
    "\n",
    "def big_ion_tof(dfevent):\n",
    "    'Plots widget of big ion time of flight data using dfevent dataframe'\n",
    "    \n",
    "    bounded_dfevent = dfevent[dfevent.tof < TIME_BETWEEN_PULSES]\n",
    "    hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=1000)\n",
    "    \n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.plot(bin_edges[:-1], hist, c='g')\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Number of hits per bin')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    \n",
    "def autoscale_y(ax,margin=0.1):\n",
    "    \"\"\"This function rescales the y-axis based on the data that is visible given the current xlim of the axis.\n",
    "    ax -- a matplotlib axes object\n",
    "    margin -- the fraction of the total height of the y-data to pad the upper and lower ylims\"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    def get_bottom_top(line):\n",
    "        xd = line.get_xdata()\n",
    "        yd = line.get_ydata()\n",
    "        lo,hi = ax.get_xlim()\n",
    "        y_displayed = yd[((xd>lo) & (xd<hi))]\n",
    "        h = np.max(y_displayed) - np.min(y_displayed)\n",
    "        bot = np.min(y_displayed)-margin*h\n",
    "        top = np.max(y_displayed)+margin*h\n",
    "        return bot,top\n",
    "\n",
    "    lines = ax.get_lines()\n",
    "    bot,top = np.inf, -np.inf\n",
    "\n",
    "    for line in lines:\n",
    "        new_bot, new_top = get_bottom_top(line)\n",
    "        if new_bot < bot: bot = new_bot\n",
    "        if new_top > top: top = new_top\n",
    "\n",
    "    ax.set_ylim(bot,top)\n",
    "    \n",
    "    \n",
    "    \n",
    "def zoomed_ion_tof(dfevent,anchor):\n",
    "    'Plots zoom around anchor point of ion time of flight data using dfevent dataframe'\n",
    "    \n",
    "    bounded_dfevent = dfevent[dfevent.tof < TIME_BETWEEN_PULSES]\n",
    "    hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=1000)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(bin_edges[:-1], hist, c='g')\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Number of hits per bin')\n",
    "    plt.title('Ions time of flight')\n",
    "    plt.xlim(anchor-1e-7,anchor+1e-7)\n",
    "    autoscale_y(ax)\n",
    "    ax.axvline(x=anchor, color='black', linestyle='--')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def power_law(x, a, b):\n",
    "    'Calibration fit power law'\n",
    "    return a * x**b\n",
    "\n",
    "\n",
    "\n",
    "def compute_calibration(calibration_lines):\n",
    "\n",
    "    # Corresponding m/q argon values\n",
    "    mq_lines = [40,20,40/3,40/4,40/5]\n",
    "    \n",
    "    # Initial guesses for parameters a and b\n",
    "    initial_guess = [1.6e13, 2]#[1.9e20, 3]\n",
    "    \n",
    "    # Perform the curve fitting\n",
    "    params, covariance = curve_fit(power_law, calibration_lines, mq_lines, p0=initial_guess, maxfev=10000)\n",
    "\n",
    "    # Extract the fitted values for a and b\n",
    "    a_fit, b_fit = params\n",
    "\n",
    "    print(f\"The fit looks as follows: m/q = {a_fit:.2e} * tof^{b_fit:.2f}\")\n",
    "    \n",
    "    return a_fit, b_fit\n",
    "\n",
    "\n",
    "\n",
    "def calibrate(backgrd_dfevent):\n",
    "    'Computes calibration by least mean squares using backgrd_dfevent'\n",
    "    'Uses user input to compute fit based on displayed plots'\n",
    "    \n",
    "    # Show a large widget ion tof\n",
    "    big_ion_tof(backgrd_dfevent)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "\n",
    "        # Ask for five numbers input\n",
    "        anchors = []\n",
    "        for i in range(5):\n",
    "            value = input(f\"Enter value Ar{i + 1}: \")\n",
    "            try:\n",
    "                anchors.append(float(value))\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a number.\")\n",
    "\n",
    "        # Show five additional plots based on inputs\n",
    "        %matplotlib inline\n",
    "        for anchor in anchors:\n",
    "            zoomed_ion_tof(backgrd_dfevent,anchor)\n",
    "\n",
    "        # Ask if the user is done\n",
    "        done_response = input(\"Are you done? (y/n): \").strip().lower()\n",
    "        if done_response == 'y':\n",
    "            done = True\n",
    "    \n",
    "    # Compute calibration fit\n",
    "    a_fit, b_fit = compute_calibration(anchors)\n",
    "    \n",
    "    return a_fit, b_fit\n",
    "\n",
    "\n",
    "\n",
    "def apply_calibration(dfevents,a_fit,b_fit):\n",
    "    'Applies calibration to each dfevent of the list of dfevents and outputs calibrated_dfevents list of dataframes with m/q column'\n",
    "        \n",
    "    calibrated_dfevents = list()\n",
    "        \n",
    "    for dfevent in dfevents:\n",
    "        dfevent['mq'] = a_fit * dfevent.tof ** b_fit\n",
    "        calibrated_dfevents.append(dfevent)\n",
    "        \n",
    "    return calibrated_dfevents\n",
    "\n",
    "\n",
    "\n",
    "def mq_selection(calibrated_dfevent,dfpulse,etof,lower_mq,upper_mq):\n",
    "    'Selects based on m/q values. Need to input calibrated_dfevent! Returns m/q selected dfevent,dfpulse,etof.'\n",
    "    \n",
    "    mqselected_dfevent = calibrated_dfevent[lower_mq < calibrated_dfevent.mq][calibrated_dfevent.mq < upper_mq]\n",
    "    mqselected_dfpulse = dfpulse[dfpulse.pulseId.isin(mqselected_dfevent.pulseId)]\n",
    "    mqselected_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(mqselected_dfevent.pulseId))\n",
    "    \n",
    "    return mqselected_dfevent,mqselected_dfpulse,mqselected_etof\n",
    "\n",
    "\n",
    "\n",
    "def find_rectangle_corners(zone):\n",
    "    \n",
    "    x, y, width, height, angle_degrees = zone\n",
    "    \n",
    "    angle_radians = np.deg2rad(angle_degrees)\n",
    "    c, s = np.cos(angle_radians), np.sin(angle_radians)\n",
    "    \n",
    "    # Calculate the coordinates of the other three corners\n",
    "    corners = np.array([\n",
    "        [x, y],\n",
    "        [x + width * c, y + width * s],\n",
    "        [x + width * c - height * s, y + width * s + height * c],\n",
    "        [x - height * s, y + height * c]\n",
    "    ])\n",
    "    \n",
    "    return corners\n",
    "\n",
    "\n",
    "\n",
    "def find_integer_coordinates(corners, zone):\n",
    "    \n",
    "    min_x, min_y = np.floor(np.min(corners, axis=0))\n",
    "    max_x, max_y = np.ceil(np.max(corners, axis=0))\n",
    "\n",
    "    integer_coordinates = []\n",
    "    for x in range(int(min_x), int(max_x) + 1):\n",
    "        for y in range(int(min_y), int(max_y) + 1):\n",
    "            if is_inside(x, y, corners, zone):\n",
    "                integer_coordinates.append((x, y))\n",
    "    \n",
    "    return integer_coordinates\n",
    "\n",
    "\n",
    "\n",
    "def is_inside(x, y, corners, zone):\n",
    "    \n",
    "    ox, oy, width, height, angle_degrees = zone\n",
    "    \n",
    "    angle_radians = np.deg2rad(angle_degrees)\n",
    "    c, s = np.cos(angle_radians), np.sin(angle_radians)\n",
    "    \n",
    "    rotated_x = (x-ox)*c + (y-oy)*s + ox\n",
    "    rotated_y = -(x-ox)*s + (y-oy)*c + oy\n",
    "    \n",
    "    return ox <= rotated_x <= ox + width and oy <= rotated_y <= oy + height\n",
    "\n",
    "\n",
    "\n",
    "def tilted_spatial_ion_selection(dfevent,dfpulse,etof,zones):\n",
    "    'Selection from the heatmap using spatial coordinates'\n",
    "    'Zones is a list of tuple representing zones - tilted or not - (xstart, ystart, width, height, angle in degrees)'\n",
    "    'Returns spatially selected dfevent,dfpulse,etof'\n",
    "    \n",
    "    heatmap_with_zones(dfevent,zones)\n",
    "    \n",
    "    integer_coordinates = []\n",
    "    for zone in zones:\n",
    "        corners = find_rectangle_corners(zone)\n",
    "        integer_coordinates.extend(find_integer_coordinates(corners, zone))\n",
    "    \n",
    "    x_coords, y_coords = zip(*integer_coordinates)\n",
    "    \n",
    "    spatial_selected_dfevent = dfevent[dfevent.x.isin(x_coords)][dfevent.y.isin(y_coords)]\n",
    "    spatial_selected_dfpulse = dfpulse[dfpulse.pulseId.isin(spatial_selected_dfevent.pulseId)]\n",
    "    spatial_selected_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(spatial_selected_dfevent.pulseId))\n",
    "    \n",
    "    return spatial_selected_dfevent,spatial_selected_dfpulse,spatial_selected_etof\n",
    "\n",
    "\n",
    "\n",
    "def fish_plot_ion_selection(dfevent,zone):\n",
    "    'Selection from the heatmap using spatial coordinates'\n",
    "    'Zone is a tuple representing a zone - tilted or not - (xstart, ystart, width, height, angle in degrees)'\n",
    "    'Returns spatially selected dfevent'\n",
    "    \n",
    "    heatmap_with_zones(dfevent,[zone])\n",
    "    \n",
    "    corners = find_rectangle_corners(zone)\n",
    "    integer_coordinates = find_integer_coordinates(corners, zone)\n",
    "    \n",
    "    x_coords, y_coords = zip(*integer_coordinates)\n",
    "    \n",
    "    spatial_selected_dfevent = dfevent[dfevent.x.isin(x_coords)][dfevent.y.isin(y_coords)]\n",
    "    \n",
    "    return spatial_selected_dfevent\n",
    "    \n",
    "\n",
    "\n",
    "def fish_plot_x(dfevent,zone,tof_bins=1000,mq_bins=500):\n",
    "    'Produces fish plots along x with respect to time of flight and m/q from dfevent dataframe and a zone defined as (startx, starty, width, height, angle in degrees)'\n",
    "    \n",
    "    fish_dfevent = fish_plot_ion_selection(dfevent,zone)\n",
    "    \n",
    "    tof_bin_edges = np.linspace(0,TIME_BETWEEN_PULSES,tof_bins+1)\n",
    "    fish_dfevent['tof_binned'] = pd.cut(fish_dfevent['tof'], bins=tof_bin_edges, labels=tof_bin_edges[:-1].astype('str'))\n",
    "    tof_pivot_table = fish_dfevent.pivot_table(index='x', columns='tof_binned', aggfunc='size', fill_value=0)\n",
    "    max_tof_value = tof_pivot_table.values.max()\n",
    "    normalized_tof = tof_pivot_table.values / max_tof_value\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "    fish_dfevent['mq_binned'] = pd.cut(fish_dfevent['mq'], bins=mq_bin_edges, labels=mq_bin_edges[:-1].astype('str'))\n",
    "    mq_pivot_table = fish_dfevent.pivot_table(index='x', columns='mq_binned', aggfunc='size', fill_value=0)\n",
    "    max_mq_value = mq_pivot_table.values.max()\n",
    "    normalized_mq = mq_pivot_table.values / max_mq_value\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(30, 12))\n",
    "    \n",
    "    cax_tof = axes[0].imshow(normalized_tof, cmap='viridis', aspect='auto', norm=LogNorm(), extent=[tof_bin_edges.min(), tof_bin_edges.max(), 0, 1])\n",
    "    axes[0].set_xlabel('Time of flight (s)')\n",
    "    axes[0].set_xlim(0,5e-7)\n",
    "    axes[0].set_ylabel('x')\n",
    "    axes[0].set_yticklabels(np.linspace(256,0,6,dtype=int))\n",
    "    axes[0].set_title('Fish plot along x with respect to time of flight')\n",
    "    cbar = plt.colorbar(cax_tof, ax=axes[0], label='Normalized number of events', norm=LogNorm())\n",
    "    \n",
    "    cax_mq = axes[1].imshow(normalized_mq, cmap='viridis', aspect='auto', norm=LogNorm(), extent=[mq_bin_edges.min(), mq_bin_edges.max(), 0, 1])\n",
    "    axes[1].set_xlabel('m/q')\n",
    "    axes[1].set_ylabel('x')\n",
    "    axes[1].set_yticklabels(np.linspace(256,0,6,dtype=int))\n",
    "    axes[1].set_title('Fish plot along x with respect to m/q')\n",
    "    cbar = plt.colorbar(cax_mq, ax=axes[1], label='Normalized number of events', norm=LogNorm())\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "def fish_plot_y(dfevent,zone,tof_bins=1000,mq_bins=500):\n",
    "    'Produces a fish plot along y from dfevent dataframe and a zone defined as (startx, starty, width, height, angle in degrees)'\n",
    "    \n",
    "    fish_dfevent = fish_plot_ion_selection(dfevent,zone)\n",
    "    \n",
    "    tof_bin_edges = np.linspace(0,TIME_BETWEEN_PULSES,tof_bins+1)\n",
    "    fish_dfevent['tof_binned'] = pd.cut(fish_dfevent['tof'], bins=tof_bin_edges, labels=tof_bin_edges[:-1].astype('str'))\n",
    "    tof_pivot_table = fish_dfevent.pivot_table(index='y', columns='tof_binned', aggfunc='size', fill_value=0)\n",
    "    max_tof_value = tof_pivot_table.values.max()\n",
    "    normalized_tof = tof_pivot_table.values / max_tof_value\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "    fish_dfevent['mq_binned'] = pd.cut(fish_dfevent['mq'], bins=mq_bin_edges, labels=mq_bin_edges[:-1].astype('str'))\n",
    "    mq_pivot_table = fish_dfevent.pivot_table(index='y', columns='mq_binned', aggfunc='size', fill_value=0)\n",
    "    max_mq_value = mq_pivot_table.values.max()\n",
    "    normalized_mq = mq_pivot_table.values / max_mq_value\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(30, 12))\n",
    "    \n",
    "    cax_tof = axes[0].imshow(normalized_tof, cmap='viridis', aspect='auto', norm=LogNorm(), extent=[tof_bin_edges.min(), tof_bin_edges.max(), 0, 1])\n",
    "    axes[0].set_xlabel('Time of flight (s)')\n",
    "    axes[0].set_ylabel('y')\n",
    "    axes[0].set_yticklabels(np.linspace(256,0,6,dtype=int))\n",
    "    axes[0].set_title('Fish plot along y with respect to time of flight')\n",
    "    cbar = plt.colorbar(cax_tof, ax=axes[0], label='Normalized number of events', norm=LogNorm())\n",
    "    \n",
    "    cax_mq = axes[1].imshow(normalized_mq, cmap='viridis', aspect='auto', norm=LogNorm(), extent=[mq_bin_edges.min(), mq_bin_edges.max(), 0, 1])\n",
    "    axes[1].set_xlabel('m/q')\n",
    "    axes[1].set_ylabel('y')\n",
    "    axes[1].set_yticklabels(np.linspace(256,0,6,dtype=int))\n",
    "    axes[1].set_title('Fish plot along y with respect to m/q')\n",
    "    cbar = plt.colorbar(cax_mq, ax=axes[1], label='Normalized number of events', norm=LogNorm())\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def big_mq_plot(dfevent,nbins_mq=1500,xlimits=(0,200)):\n",
    "    'Plots big intensity vs m/q plot using dfevent'\n",
    "    \n",
    "    x_lower, x_upper = xlimits\n",
    "    \n",
    "    plt.figure(figsize=(18,8))\n",
    "        \n",
    "    hist, bin_edges = np.histogram(dfevent.mq, bins=np.linspace(0,200,nbins_mq+1))\n",
    "    plt.plot(bin_edges[:-1], hist/max(hist))\n",
    "    \n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Relatively normalized number of hits per bin')\n",
    "    plt.title('Normalized ions time of flight')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1621cdee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def nevents_binning(dfevent,dfpulse,etof,nbins_events,nbins_mq):\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse) and nbins sized array of histograms'\n",
    "    'hists is divided by number of pulses in a certain number of events bin'\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfevents = []\n",
    "    filtered_dfpulses = []\n",
    "    filtered_etofs = []\n",
    "    hists = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "        filtered_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(filtered_dfpulse.pulseId))\n",
    "\n",
    "        filtered_dfevents.append(filtered_dfevent)\n",
    "        filtered_dfpulses.append(filtered_dfpulse)\n",
    "        filtered_etofs.append(filtered_etof)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.mq, bins=np.linspace(0,200,nbins_mq+1),range=(0,200))\n",
    "        hists.append(hist/len(filtered_dfpulse))\n",
    "        \n",
    "    return filtered_dfevents, filtered_dfpulses, filtered_etofs, np.array(hists), bins\n",
    "\n",
    "\n",
    "\n",
    "def nevents_binning_tof(dfevent,dfpulse,etof,nbins_events,nbins_tof):\n",
    "    'Bins into time of flight bins'\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse) and nbins sized array of histograms'\n",
    "    'hists is divided by number of pulses in a certain number of events bin'\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfevents = []\n",
    "    filtered_dfpulses = []\n",
    "    filtered_etofs = []\n",
    "    hists = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "        filtered_etof = etof.sel(pulseId=etof.coords['pulseId'].isin(filtered_dfpulse.pulseId))\n",
    "\n",
    "        filtered_dfevents.append(filtered_dfevent)\n",
    "        filtered_dfpulses.append(filtered_dfpulse)\n",
    "        filtered_etofs.append(filtered_etof)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.tof, bins=np.linspace(0,TIME_BETWEEN_PULSES,nbins_tof+1),range=(0,TIME_BETWEEN_PULSES))\n",
    "        hists.append(hist/len(filtered_dfpulse))\n",
    "        \n",
    "    return filtered_dfevents, filtered_dfpulses, filtered_etofs, np.array(hists), bins\n",
    "\n",
    "\n",
    "\n",
    "def nions_binning(dfevent,dfpulse,nbins_events,nbins_mq):\n",
    "    'Only handles ions'\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse) and nbins sized array of histograms'\n",
    "    'hists is divided by number of pulses in a certain number of events bin'\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfevents = []\n",
    "    filtered_dfpulses = []\n",
    "    hists = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "\n",
    "        filtered_dfevents.append(filtered_dfevent)\n",
    "        filtered_dfpulses.append(filtered_dfpulse)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.mq, bins=np.linspace(0,200,nbins_mq+1),range=(0,200))\n",
    "        hists.append(hist/len(filtered_dfpulse))\n",
    "        \n",
    "    return filtered_dfevents, filtered_dfpulses, np.array(hists), bins\n",
    "\n",
    "\n",
    "\n",
    "def nions_binning_tof(dfevent,dfpulse,nbins_events,nbins_tof):\n",
    "    'Bins into time of flight bins'\n",
    "    'Only handles ions'\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse) and nbins sized array of histograms'\n",
    "    'hists is divided by number of pulses in a certain number of events bin'\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfevents = []\n",
    "    filtered_dfpulses = []\n",
    "    hists = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "\n",
    "        filtered_dfevents.append(filtered_dfevent)\n",
    "        filtered_dfpulses.append(filtered_dfpulse)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.tof, bins=np.linspace(0,TIME_BETWEEN_PULSES,nbins_tof+1),range=(0,TIME_BETWEEN_PULSES))\n",
    "        hists.append(hist/len(filtered_dfpulse))\n",
    "        \n",
    "    return filtered_dfevents, filtered_dfpulses, np.array(hists), bins\n",
    "\n",
    "\n",
    "\n",
    "def nevents_binning_plot(dfevent,dfpulse,nbins_events,nbins_mq,xlimits=(0,200)):\n",
    "    'Bins by m/q'\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse)'\n",
    "    \n",
    "    x_lower, x_upper = xlimits\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfs = []\n",
    "    plt.figure(figsize=(20,8))\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "\n",
    "        filtered_dfs.append((filtered_dfevent,filtered_dfpulse))\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.mq, bins=np.linspace(0,200,nbins_mq),range=(0,200))\n",
    "        \n",
    "        plt.plot(bin_edges[:-1], hist/max(hist), label=f'{start_edge}-{end_edge}')\n",
    "        \n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Relatively normalized number of hits per bin')\n",
    "    plt.title('Normalized ions time of flight')\n",
    "    plt.legend()\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()   \n",
    "        \n",
    "    return filtered_dfs\n",
    "\n",
    "    \n",
    "\n",
    "def nevents_binning_plot_tof(dfevent,dfpulse,nbins_events,nbins_tof,xlimits=(0,TIME_BETWEEN_PULSES)):\n",
    "    'Bins by time of flight'\n",
    "    'Binning dfevent dataframe into a number of bins nbins using number of events per pulse dfpulse.nevents_pulse'\n",
    "    'Outputs nbins sized list of tuples (filtered_dfevent, filtered_dfpulse)'\n",
    "    \n",
    "    x_lower, x_upper = xlimits\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    filtered_dfs = []\n",
    "    plt.figure(figsize=(20,8))\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = dfevent[dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "\n",
    "        filtered_dfs.append((filtered_dfevent,filtered_dfpulse))\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.tof, bins=np.linspace(0,TIME_BETWEEN_PULSES,nbins_tof),range=(0,TIME_BETWEEN_PULSES))\n",
    "        \n",
    "        plt.plot(bin_edges[:-1], hist/max(hist), label=f'{start_edge}-{end_edge}')\n",
    "        \n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Relatively normalized number of hits per bin')\n",
    "    plt.title('Normalized ions time of flight')\n",
    "    plt.legend()\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()   \n",
    "        \n",
    "    return filtered_dfs\n",
    "\n",
    "\n",
    "\n",
    "def nevents_binning_cov(dfevent,dfpulse,etof,nbins_events,nbins_ion_tof,nbins_e_tof,max_ion_limit=TIME_BETWEEN_PULSES,max_e_limit=TIME_BETWEEN_PULSES):\n",
    "    'Binning dfevent and etof by numbers of events, and number of bins along time of flight'\n",
    "    'Can select maximal time limit for electrons and ions'\n",
    "    \n",
    "    channel_time = TIME_BETWEEN_PULSES/CHANNELS_PER_PULSE\n",
    "    \n",
    "    nevents_min = min(dfpulse.nevents_pulse)\n",
    "    nevents_max = max(dfpulse.nevents_pulse)\n",
    "    \n",
    "    bins = np.linspace(nevents_min,nevents_max,nbins_events+1).astype(int)\n",
    "    \n",
    "    max_int_ion_limit = int(max_ion_limit/channel_time)\n",
    "    new_int_ion_limit = max_int_ion_limit - max_int_ion_limit % nbins_ion_tof\n",
    "    new_ion_limit = new_int_ion_limit*channel_time\n",
    "    \n",
    "    max_int_e_limit = int(max_e_limit/channel_time)\n",
    "    new_int_e_limit = max_int_e_limit - max_int_e_limit % nbins_e_tof\n",
    "    e_group_size = int(new_int_e_limit/nbins_e_tof)\n",
    "    \n",
    "    shortened_dfevent = dfevent[dfevent.tof < new_ion_limit]\n",
    "    shortened_etof = etof[:,:new_int_e_limit]\n",
    "    \n",
    "    hists = []\n",
    "    hists_etof = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "\n",
    "        start_edge = bins[i]\n",
    "        end_edge = bins[i + 1]\n",
    "\n",
    "        filtered_dfpulse = dfpulse[(dfpulse.nevents_pulse >= start_edge) & (dfpulse.nevents_pulse < end_edge)]\n",
    "        filtered_dfevent = shortened_dfevent[shortened_dfevent.pulseId.isin(filtered_dfpulse.pulseId)]\n",
    "        filtered_etof = shortened_etof.sel(pulseId=shortened_etof.coords['pulseId'].isin(filtered_dfpulse.pulseId))\n",
    "        \n",
    "        hist, bin_edges = np.histogram(filtered_dfevent.tof, bins=nbins_ion_tof)\n",
    "        hists.append(hist)\n",
    "        \n",
    "        numpy_etof = filtered_etof.to_numpy()\n",
    "        reshaped_etof = numpy_etof.reshape((numpy_etof.shape[0], -1, e_group_size))\n",
    "        summed_etof = np.sum(reshaped_etof, axis=-1)\n",
    "        avg_etof = -np.mean(summed_etof, axis=0)\n",
    "        hists_etof.append(avg_etof)\n",
    "        \n",
    "    hists = np.array(hists)\n",
    "    hists_etof = np.array(hists_etof)\n",
    "        \n",
    "    return hists, hists_etof, bins\n",
    "\n",
    "\n",
    "\n",
    "def stacked_ion_tof_max(hists,nbins_tof,bins,xlimits=(0,TIME_BETWEEN_PULSES),backgrd_dfevent=None):\n",
    "    \"Plots ion tof for each number of events defined on top of each other\"\n",
    "    \"Can determine number of bins along time of flight and limits along x\"\n",
    "    \n",
    "    precision = TIME_BETWEEN_PULSES/nbins_tof\n",
    "    x_lower, x_upper = xlimits\n",
    "    hist_lower, hist_upper = int(x_lower/precision), int(x_upper/precision)\n",
    "    \n",
    "    x_edges = np.linspace(x_lower, x_upper, hist_upper-hist_lower)\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    \n",
    "    for i in range(len(hists)):\n",
    "        \n",
    "        shortened_hist = hists[i][hist_lower:hist_upper]\n",
    "        plt.plot(x_edges, shortened_hist/max(shortened_hist), label=f'{bins[i]}-{bins[i+1]}')\n",
    "        \n",
    "    if isinstance(backgrd_dfevent, pd.DataFrame):\n",
    "        hist, bin_edges = np.histogram(backgrd_dfevent.tof, bins=np.linspace(0,TIME_BETWEEN_PULSES,nbins_tof+1),range=(0,TIME_BETWEEN_PULSES))\n",
    "        shortened_hist = hist[hist_lower:hist_upper]\n",
    "        plt.plot(x_edges, shortened_hist/max(shortened_hist), label='Background')\n",
    "\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Individually normalized signal')\n",
    "    plt.title('Normalized ions time of flight')\n",
    "    plt.legend()\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def stacked_ion_tof_sum(hists,nbins_tof,bins,xlimits=(0,TIME_BETWEEN_PULSES),backgrd_dfevent=None):\n",
    "    \"Plots ion tof for each number of events defined on top of each other\"\n",
    "    \"Can determine number of bins along time of flight and limits along x\"\n",
    "    \n",
    "    precision = TIME_BETWEEN_PULSES/nbins_tof\n",
    "    x_lower, x_upper = xlimits\n",
    "    hist_lower, hist_upper = int(x_lower/precision), int(x_upper/precision)\n",
    "    \n",
    "    x_edges = np.linspace(x_lower, x_upper, hist_upper-hist_lower)\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    \n",
    "    for i in range(len(hists)):\n",
    "        \n",
    "        shortened_hist = hists[i][hist_lower:hist_upper]\n",
    "        plt.plot(x_edges, shortened_hist/sum(shortened_hist), label=f'{bins[i]}-{bins[i+1]}')\n",
    "        \n",
    "    if isinstance(backgrd_dfevent, pd.DataFrame):\n",
    "        hist, bin_edges = np.histogram(backgrd_dfevent.tof, bins=np.linspace(0,TIME_BETWEEN_PULSES,nbins_tof+1),range=(0,TIME_BETWEEN_PULSES))\n",
    "        shortened_hist = hist[hist_lower:hist_upper]\n",
    "        plt.plot(x_edges, shortened_hist/sum(shortened_hist), label='Background')\n",
    "\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Individually normalized signal')\n",
    "    plt.title('Normalized ions time of flight')\n",
    "    plt.legend()\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show() \n",
    "    \n",
    "\n",
    "\n",
    "def waterfall_rel(hists,nbins_mq,xlimits=(0,200)):\n",
    "    \"Waterfall plot of relative normalization with respect to m/q using hists, which is a list of histograms\"\n",
    "\n",
    "    x_lower, x_upper = xlimits\n",
    "    nbins_events = len(hists)\n",
    "    bin_edges = np.linspace(0, 200, nbins_mq+1)\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    colormap = plt.cm.inferno\n",
    "    color_index = np.linspace(0.2, 0.8, nbins_events)\n",
    "\n",
    "    for i in range(nbins_events):\n",
    "        \n",
    "        hist_norm = hists[i] / max(hists[i]) + i\n",
    "\n",
    "        line_color = colormap(color_index[i])\n",
    "        plt.plot(bin_edges[:-1], hist_norm, color=line_color)\n",
    "\n",
    "    plt.title('Relative waterfall plot')\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Relative normalized counts')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "def nevents_heatmap_rel(hists,nbins_mq,bins,xlimits=(0,200)):\n",
    "    \"Heatmap of relative normalized counts with number of events slices on the y axis, with respect to m/q on the x axis using hists, which is a list of histograms\"\n",
    "    \n",
    "    precision = 200/nbins_mq\n",
    "    x_lower, x_upper = xlimits\n",
    "    hist_lower, hist_upper = int(x_lower/precision), int(x_upper/precision)\n",
    "    nbins_events = len(hists)\n",
    "    hists_norm = []\n",
    "\n",
    "    for i in range(nbins_events):\n",
    "\n",
    "        shortened_hist = hists[i][hist_lower:hist_upper]\n",
    "        hist_norm = shortened_hist / max(shortened_hist)\n",
    "        hists_norm.append(hist_norm)\n",
    "\n",
    "    x_edges = np.linspace(x_lower, x_upper, hist_upper-hist_lower)\n",
    "    y_edges = bins[:-1]\n",
    "    X, Y = np.meshgrid(x_edges, y_edges)\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    c = plt.pcolormesh(X, Y, hists_norm, shading='auto')\n",
    "    plt.colorbar(c, label='Relative normalized counts', extend='max')\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Number of events slice')\n",
    "    plt.title('Relative heatmap for number of events slices with respect to m/q')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def nevents_heatmap_rel_tof(hists,nbins_tof,bins,xlimits=(0,TIME_BETWEEN_PULSES)):\n",
    "    \"Heatmap of relative normalized counts with number of events slices on the y axis, with respect to tof on the x axis using hists, which is a list of histograms\"\n",
    "    \n",
    "    precision = TIME_BETWEEN_PULSES/nbins_tof\n",
    "    x_lower, x_upper = xlimits\n",
    "    hist_lower, hist_upper = int(x_lower/precision), int(x_upper/precision)\n",
    "    nbins_events = len(hists)\n",
    "    hists_norm = []\n",
    "\n",
    "    for i in range(nbins_events):\n",
    "\n",
    "        shortened_hist = hists[i][hist_lower:hist_upper]\n",
    "        hist_norm = shortened_hist / max(shortened_hist)\n",
    "        hists_norm.append(hist_norm)\n",
    "\n",
    "    x_edges = np.linspace(x_lower, x_upper, hist_upper-hist_lower)\n",
    "    X, Y = np.meshgrid(x_edges, bins[:-1])\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    c = plt.pcolormesh(X, Y, hists_norm, shading='auto')\n",
    "    plt.colorbar(c, label='Relative normalized counts', extend='max')\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Number of events slice')\n",
    "    plt.title('Relative heatmap for number of events slices with respect to tof')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    # plt.yticks(bins[:-1])\n",
    "    plt.show()\n",
    "   \n",
    "    \n",
    "    \n",
    "def waterfall_abs(hists,nbins_mq,xlimits=(0,200)):\n",
    "    \"Waterfall plot of absolute normalization with respect to m/q using hists, which is a list of histograms\"\n",
    "\n",
    "    x_lower, x_upper = xlimits\n",
    "    nbins_events = len(hists)\n",
    "    bin_edges = np.linspace(0, 200, nbins_mq+1)\n",
    "    hists_norm = hists/np.max(hists)\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    colormap = plt.cm.inferno\n",
    "    color_index = np.linspace(0.2, 0.8, nbins_events)\n",
    "\n",
    "    for i in range(nbins_events):\n",
    "\n",
    "        line_color = colormap(color_index[i])\n",
    "        plt.plot(bin_edges[:-1], hists_norm[i] + i, color=line_color)\n",
    "\n",
    "    plt.title('Absolute waterfall plot')\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Relative normalized counts')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "def nevents_heatmap_abs(hists,nbins_mq,bins,xlimits=(0,200)):\n",
    "    \"Heatmap of absolute normalized counts with number of events slices on the y axis, with respect to m/q on the x axis using hists, which is a list of histograms\"\n",
    "    \n",
    "    precision = 200/nbins_mq\n",
    "    x_lower, x_upper = xlimits\n",
    "    hist_lower, hist_upper = int(x_lower/precision), int(x_upper/precision)\n",
    "    hists_shortened = hists[:,hist_lower:hist_upper]\n",
    "    nbins_events = len(hists_shortened)\n",
    "    hists_norm = hists_shortened/np.max(hists_shortened)\n",
    "\n",
    "    x_edges = np.linspace(0, 200, nbins_mq)\n",
    "    y_edges = bins[:-1]\n",
    "    X, Y = np.meshgrid(x_edges, y_edges)\n",
    "    \n",
    "    plt.figure(figsize=(20, 8))\n",
    "    c = plt.pcolormesh(X, Y, hists_norm, shading='auto')\n",
    "    plt.colorbar(c, label='Relative normalized counts', extend='max')\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Number of events slice')\n",
    "    plt.title('Absolute heatmap for number of events slices with respect to m/q')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def nevents_heatmap_abs_tof(hists,nbins_tof,bins,xlimits=(0,TIME_BETWEEN_PULSES)):\n",
    "    \"Heatmap of absolute normalized counts with number of events slices on the y axis, with respect to tof on the x axis using hists, which is a list of histograms\"\n",
    "    \n",
    "    precision = TIME_BETWEEN_PULSES/nbins_tof\n",
    "    x_lower, x_upper = xlimits\n",
    "    hist_lower, hist_upper = int(x_lower/precision), int(x_upper/precision)\n",
    "    hists_shortened = hists[:,hist_lower:hist_upper]\n",
    "    nbins_events = len(hists_shortened)\n",
    "    hists_norm = hists_shortened/np.max(hists_shortened)\n",
    "\n",
    "    x_edges = np.linspace(x_lower, x_upper, hist_upper-hist_lower)\n",
    "    X, Y = np.meshgrid(x_edges, bins[:-1])\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    c = plt.pcolormesh(X, Y, hists_norm, shading='auto')\n",
    "    plt.colorbar(c, label='Relative normalized counts', extend='max')\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Number of events slice')\n",
    "    plt.title('Absolute heatmap for number of events slices with respect to tof')\n",
    "    plt.xlim(x_lower, x_upper)\n",
    "    # plt.yticks(bins[:-1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def waterfall_etof(filtered_etofs,xlimits=(0,200)):\n",
    "    'Waterfall plot of etof data using list of etofs filtered_etofs'\n",
    "\n",
    "    x_lower, x_upper = xlimits\n",
    "    nbins = len(filtered_etofs)\n",
    "    channel_time = TIME_BETWEEN_PULSES/CHANNELS_PER_PULSE\n",
    "    xaxis = np.arange(14080)*channel_time\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    colormap = plt.cm.inferno\n",
    "    color_index = np.linspace(0.2, 0.8, nbins)\n",
    "\n",
    "    for i in range(nbins):\n",
    "        \n",
    "        summed_etof = -np.sum(filtered_etofs[i],axis=0)\n",
    "        line_color = colormap(color_index[i])\n",
    "        plt.plot(xaxis, summed_etof/np.max(summed_etof) + i, color=line_color)\n",
    "\n",
    "    plt.title('Relative electron waterfall plot')\n",
    "    plt.xlabel('Time of flight (s)')\n",
    "    plt.ylabel('Normalized signal')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "def mq_np_covariance(dfevent,mq_bins=200,log=True,vmin=None,vmax=None):\n",
    "    'Produces a positive and a negative covariance map of m/q vs m/q employing the numpy cov function'\n",
    "    'Uses dfevent as input, can select number of mq bins, can produce plot as log, standard, or between defined ranges'\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "\n",
    "    dfevent['mq_bin'] = pd.cut(dfevent['mq'], bins=mq_bin_edges)\n",
    "\n",
    "    result_matrix = pd.crosstab(dfevent['pulseId'], dfevent['mq_bin'])\n",
    "    result_numpy_matrix = result_matrix.values\n",
    "    \n",
    "    cov_matrix = np.cov(result_numpy_matrix, rowvar=False)\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if log == True:\n",
    "        ax = sns.heatmap(cov_matrix, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "    elif vmax == None:\n",
    "        ax = sns.heatmap(cov_matrix, cmap='viridis', fmt='.2f')\n",
    "    else:\n",
    "        ax = sns.heatmap(cov_matrix, cmap='viridis', fmt='.2f', vmin=0, vmax=vmax)\n",
    "\n",
    "    tick_positions = np.linspace(0, mq_bins, 11)\n",
    "    tick_labels = np.linspace(0, 200, 11).astype(int)\n",
    "\n",
    "    ax.set_xticks(tick_positions)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    ax.set_yticks(tick_positions)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.title('Positive Numpy Covariance Heatmap  m/q vs m/q')\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('m/q')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if log == True:\n",
    "        ax = sns.heatmap(-cov_matrix, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "    elif vmin == None:\n",
    "        ax = sns.heatmap(-cov_matrix, cmap='viridis', fmt='.2f')\n",
    "    else:\n",
    "        ax = sns.heatmap(-cov_matrix, cmap='viridis', fmt='.2f', vmin=0, vmax=-vmin)\n",
    "\n",
    "    tick_positions = np.linspace(0, mq_bins, 11)\n",
    "    tick_labels = np.linspace(0, 200, 11).astype(int)\n",
    "\n",
    "    ax.set_xticks(tick_positions)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    ax.set_yticks(tick_positions)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.title('Negative Numpy Covariance Heatmap  m/q vs m/q')\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('m/q')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def mq_covariance_1d(dfevent,mq_bin_range,mq_bins=200):\n",
    "    'Produces 1d covariance of an m/q bin range vs m/q employing the numpy cov function'\n",
    "    'Uses dfevent as input, can select number of mq bins'\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "\n",
    "    dfevent['mq_bin'] = pd.cut(dfevent['mq'], bins=mq_bin_edges)\n",
    "\n",
    "    result_matrix = pd.crosstab(dfevent['pulseId'], dfevent['mq_bin'])\n",
    "    result_numpy_matrix = result_matrix.values\n",
    "\n",
    "    array_hyd = result_matrix.values[:,mq_bin_range[0]:mq_bin_range[1]].sum(axis=1)\n",
    "    shape = result_numpy_matrix.shape[1]\n",
    "\n",
    "    # Calculate the covariance between each row of result_numpy_matrix and array_hyd\n",
    "    covariances = np.array([np.cov(np.column_stack((result_numpy_matrix[:, j], array_hyd)), rowvar=False)[0, 1] for j in range(shape)])\n",
    "\n",
    "    xaxis = np.linspace(0,200,shape)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xaxis,covariances)\n",
    "    plt.xlabel('m/q')\n",
    "    plt.ylabel('Covariance with m/q')\n",
    "    plt.title(f'Covariance Plot between m/q bin range {mq_bin_range} and m/q')\n",
    "    ax.set_yscale('symlog', linthresh=10)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def fix_missing_row(dfevent,dfpulse,mq_bins=200):\n",
    "    'Fixes the missing row in dfevent dataframe when computing the cross-tabulation of pulseId and mq_bin'\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "\n",
    "    dfevent['mq_bin'] = pd.cut(dfevent['mq'], bins=mq_bin_edges)\n",
    "\n",
    "    result_matrix = pd.crosstab(dfevent['pulseId'], dfevent['mq_bin'])\n",
    "    result_numpy_matrix = result_matrix.values\n",
    "    \n",
    "    resultlist = result_matrix.index.to_list()\n",
    "    resultlist.append(0)\n",
    "    selectedlist = dfpulse[dfpulse.pulseId.isin(dfevent.pulseId)].pulseId.to_list()\n",
    "    truefalse = np.equal(resultlist,selectedlist)\n",
    "    first_instance = np.argmax(~truefalse)\n",
    "    missing_pulse = int(dfpulse.iloc[first_instance].pulseId)\n",
    "\n",
    "    new_dfevent = dfevent[dfevent.pulseId != missing_pulse]\n",
    "    \n",
    "    return new_dfevent\n",
    "\n",
    "\n",
    "\n",
    "def calc_corrs(array1, array2, pcovparams, alpha=1):\n",
    "    print('calculating covariance')\n",
    "\n",
    "    assert len(pcovparams)==len(array1)==len(array2)\n",
    "    numshots=len(array1)\n",
    "    \n",
    "    # heavy stuff\n",
    "    syx=np.einsum('ij,ik->jk', array1, array2)\n",
    "    print('calculated syx')\n",
    "    syi=np.einsum('ij,i->j', array1, pcovparams)\n",
    "    print('calculated syi')\n",
    "    six=np.einsum('ij,i->j', array2, pcovparams)\n",
    "    print('calculated six')\n",
    "\n",
    "    # lighter stuff\n",
    "    sy=array1.sum(axis=0)\n",
    "    sx=array2.sum(axis=0)\n",
    "    si=pcovparams.sum(axis=0)\n",
    "    \n",
    "    syy=(array1**2).sum(axis=0)\n",
    "    sxx=(array2**2).sum(axis=0)\n",
    "    sii=(pcovparams**2).sum()\n",
    "\n",
    "    sysx=np.outer(sy, sx)\n",
    "    sisx=si*sx\n",
    "    sysi=sy*si\n",
    "    \n",
    "    # calculate covariances\n",
    "    covyx=(syx-sysx/numshots)/(numshots-1)\n",
    "    covyi=(syi-sysi/numshots)/(numshots-1)\n",
    "    covix=(six-sisx/numshots)/(numshots-1)\n",
    "\n",
    "    covyy=(syy-sy**2/numshots)/(numshots-1)\n",
    "    covxx=(sxx-sx**2/numshots)/(numshots-1)\n",
    "    covii=(sii-si**2/numshots)/(numshots-1) # renamed from varii\n",
    "\n",
    "    # calculate partial covariances\n",
    "    pcovyx=(numshots-1)/(numshots-2) * (covyx - alpha * np.outer(covyi, covix)/covii)\n",
    "    pcovyy=(numshots-1)/(numshots-2) * (covyy - (covyi**2)/covii)\n",
    "    pcovxx=(numshots-1)/(numshots-2) * (covxx - (covix**2)/covii)\n",
    "    \n",
    "    # calculate correlation\n",
    "    corryx = covyx / np.sqrt(np.outer(covyy, covxx))\n",
    "    # calculate partial correlation\n",
    "    pcorryx = pcovyx / np.sqrt(np.outer(pcovyy, pcovxx))\n",
    "    \n",
    "    return covyx, pcovyx, corryx, pcorryx\n",
    "\n",
    "\n",
    "\n",
    "def mq_covariance(dfevent,dfpulse,mq_bins=200,log=True,vmin=None,vmax=None):\n",
    "    'Produces covariance maps of m/q vs m/q employing the calc_corrs function'\n",
    "    'Uses dfevent and dfpulse as inputs, can select number of mq bins, can produce plot as log, standard, or between defined ranges'\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "\n",
    "    dfevent['mq_bin'] = pd.cut(dfevent['mq'], bins=mq_bin_edges)\n",
    "\n",
    "    result_matrix = pd.crosstab(dfevent['pulseId'], dfevent['mq_bin'])\n",
    "    result_numpy_matrix = result_matrix.values\n",
    "    \n",
    "    nevents_pulse = dfpulse[dfpulse.pulseId.isin(dfevent.pulseId)].nevents_pulse\n",
    "    \n",
    "    covyx, pcovyx, corryx, pcorryx = calc_corrs(result_numpy_matrix, result_numpy_matrix, nevents_pulse)\n",
    "    \n",
    "    \n",
    "    tick_positions = np.linspace(0, mq_bins, 11)\n",
    "    tick_labels = np.linspace(0, 200, 11).astype(int)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if log == True:\n",
    "        ax = sns.heatmap(covyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Positive Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        ax = sns.heatmap(-covyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Negative Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "    \n",
    "    elif vmax == None:\n",
    "        ax = sns.heatmap(covyx, cmap='seismic', fmt='.2f')\n",
    "        \n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        ax = sns.heatmap(covyx, cmap='seismic', fmt='.2f', vmin=vmin, vmax=vmax)\n",
    "        \n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "def mq_partial_covariance(dfevent,dfpulse,mq_bins=200,alpha=1,log=True,vmin=None,vmax=None):\n",
    "    'Produces partial covariance maps of m/q vs m/q employing the calc_corrs function'\n",
    "    'Uses dfevent and dfpulse as inputs, can select number of mq bins and factor alpha, can produce plot as log, standard, or between defined ranges'\n",
    "    \n",
    "    mq_bin_edges = np.linspace(0,200,mq_bins+1)\n",
    "\n",
    "    dfevent['mq_bin'] = pd.cut(dfevent['mq'], bins=mq_bin_edges)\n",
    "\n",
    "    result_matrix = pd.crosstab(dfevent['pulseId'], dfevent['mq_bin'])\n",
    "    result_numpy_matrix = result_matrix.values\n",
    "    \n",
    "    nevents_pulse = dfpulse[dfpulse.pulseId.isin(dfevent.pulseId)].nevents_pulse\n",
    "    \n",
    "    covyx, pcovyx, corryx, pcorryx = calc_corrs(result_numpy_matrix, -result_numpy_matrix, nevents_pulse, alpha)\n",
    "    \n",
    "    \n",
    "    tick_positions = np.linspace(0, mq_bins, 11)\n",
    "    tick_labels = np.linspace(0, 200, 11).astype(int)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if log == True:\n",
    "        ax = sns.heatmap(pcovyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Positive Partial Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        ax = sns.heatmap(-pcovyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Negative Partial Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "    \n",
    "    elif vmax == None:\n",
    "        ax = sns.heatmap(pcovyx, cmap='seismic', fmt='.2f')\n",
    "        \n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Partial Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        ax = sns.heatmap(pcovyx, cmap='seismic', fmt='.2f', vmin=vmin, vmax=vmax)\n",
    "        \n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels(tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        plt.title('Partial Covariance Heatmap m/q vs m/q')\n",
    "        plt.xlabel('m/q')\n",
    "        plt.ylabel('m/q')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def ion_ion_covariance(dfevent, dfpulse, nbins_ion_tof, max_ion_limit=TIME_BETWEEN_PULSES, alpha=1, log=True, vmin=None, vmax=None):\n",
    "    'Produces numpy covariance maps of ion tof vs ion tof employing the calc_corrs function'\n",
    "    \n",
    "    # Create bins for ion TOF\n",
    "    ion_tof_bin_edges = np.linspace(0, max_ion_limit, nbins_ion_tof+1)\n",
    "    dfevent['tof_bin'] = pd.cut(dfevent['tof'], bins=ion_tof_bin_edges)\n",
    "\n",
    "    # Create ion matrix\n",
    "    ion_matrix = pd.crosstab(dfevent['pulseId'], dfevent['tof_bin'])\n",
    "    \n",
    "    # Get number of events per pulse\n",
    "    nevents_pulse = dfpulse[dfpulse.pulseId.isin(ion_matrix.index.to_numpy())].nevents_pulse\n",
    "\n",
    "    # Calculate correlations\n",
    "    covyx, pcovyx, corryx, pcorryx = calc_corrs(ion_matrix.values, ion_matrix.values, nevents_pulse, alpha)\n",
    "\n",
    "    # Setup tick positions and labels\n",
    "    ion_tick_positions = np.linspace(0, nbins_ion_tof, 5).astype(int)\n",
    "    formatted_ion_tick_labels = np.linspace(0, max_ion_limit, 5)\n",
    "    \n",
    "    # Plotting functions\n",
    "    def plot_heatmap(data, title, is_negative=False):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        if log:\n",
    "            data_to_plot = -data if is_negative else data\n",
    "            ax = sns.heatmap(data_to_plot, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "        elif vmax is None:\n",
    "            ax = sns.heatmap(data, cmap='seismic', fmt='.2f')\n",
    "        else:\n",
    "            ax = sns.heatmap(data, cmap='seismic', fmt='.2f', vmin=vmin, vmax=vmax)\n",
    "            \n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(ion_tick_positions)\n",
    "        ax.set_xticklabels(formatted_ion_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title(title)\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Ion tof')\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot covariance maps\n",
    "    if log:\n",
    "        plot_heatmap(covyx, 'Positive Covariance Heatmap ion tof vs ion tof')\n",
    "        plot_heatmap(covyx, 'Negative Covariance Heatmap ion tof vs ion tof', is_negative=True)\n",
    "    else:\n",
    "        plot_heatmap(covyx, 'Covariance Heatmap ion tof vs ion tof')\n",
    "    \n",
    "    # Plot partial covariance maps\n",
    "    if log:\n",
    "        plot_heatmap(pcovyx, 'Positive Partial Covariance Heatmap ion tof vs ion tof')\n",
    "        plot_heatmap(pcovyx, 'Negative Partial Covariance Heatmap ion tof vs ion tof', is_negative=True)\n",
    "    else:\n",
    "        plot_heatmap(pcovyx, 'Partial Covariance Heatmap ion tof vs ion tof')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def etof_ion_covariance(dfevent,dfpulse,etof,nbins_ion_tof,nbins_e_tof,max_ion_limit=TIME_BETWEEN_PULSES,max_e_limit=TIME_BETWEEN_PULSES,alpha=1,log=True,vmin=None,vmax=None):\n",
    "    'Produces numpy covariance maps of etof vs ion employing the calc_corrs function'\n",
    "    'Uses dfevent and etof as inputs, can select number of bins along ion tof and electron tof, can produce plot as log, standard, or between defined ranges, and set alpha'\n",
    "    'Can select maximal time limit for electrons and ions'\n",
    "    \n",
    "    ion_tof_bin_edges = np.linspace(0,max_ion_limit,nbins_ion_tof+1)\n",
    "    dfevent['tof_bin'] = pd.cut(dfevent['tof'], bins=ion_tof_bin_edges)\n",
    "\n",
    "    ion_matrix = pd.crosstab(dfevent['pulseId'], dfevent['tof_bin'])\n",
    "\n",
    "\n",
    "    coords_etof = etof.assign_coords(data=np.arange(0,TIME_BETWEEN_PULSES,channel_time))\n",
    "\n",
    "    e_tof_bin_edges = np.linspace(0,max_e_limit,nbins_e_tof+1)\n",
    "    binned_etof = coords_etof.groupby_bins(\"data\", e_tof_bin_edges).sum()\n",
    "    e_matrix = binned_etof.to_pandas()\n",
    "    \n",
    "    ion_list = ion_matrix.index.to_list()\n",
    "    # ion_list.append(0)\n",
    "    e_list = e_matrix.index.to_list()\n",
    "    truefalse = np.equal(ion_list,e_list)\n",
    "    first_instance = np.argmax(~truefalse)\n",
    "\n",
    "    new_e_matrix = e_matrix#.drop(e_list[first_instance])\n",
    "\n",
    "\n",
    "    nevents_pulse = dfpulse[dfpulse.pulseId.isin(ion_matrix.index.to_numpy())].nevents_pulse\n",
    "\n",
    "    covyx, pcovyx, corryx, pcorryx = calc_corrs(ion_matrix.values, -new_e_matrix.values, nevents_pulse, alpha)\n",
    "\n",
    "\n",
    "    ion_tick_positions = np.linspace(0, nbins_ion_tof, 5).astype(int)\n",
    "    formatted_ion_tick_labels = np.linspace(0, max_ion_limit, 5)\n",
    "\n",
    "    e_tick_positions = np.linspace(0, nbins_e_tof, 5).astype(int)\n",
    "    formatted_e_tick_labels = np.linspace(0, max_e_limit, 5)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if log == True:\n",
    "        ax = sns.heatmap(covyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Positive Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        ax = sns.heatmap(-covyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Negative Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "    \n",
    "    elif vmax == None:\n",
    "        ax = sns.heatmap(covyx, cmap='seismic', fmt='.2f')\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        ax = sns.heatmap(covyx, cmap='seismic', fmt='.2f', vmin=vmin, vmax=vmax)\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if log == True:\n",
    "        ax = sns.heatmap(pcovyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Positive Partial Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        ax = sns.heatmap(-pcovyx, cmap='viridis', fmt='.2f', norm=LogNorm())\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Negative Partial Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "    \n",
    "    elif vmax == None:\n",
    "        ax = sns.heatmap(pcovyx, cmap='seismic', fmt='.2f')\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Partial Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        ax = sns.heatmap(pcovyx, cmap='seismic', fmt='.2f', vmin=vmin, vmax=vmax)\n",
    "        ax.set_yticks(ion_tick_positions)\n",
    "        ax.set_yticklabels(formatted_ion_tick_labels)\n",
    "        ax.set_xticks(e_tick_positions)\n",
    "        ax.set_xticklabels(formatted_e_tick_labels)\n",
    "        ax.invert_yaxis()\n",
    "        plt.title('Partial Covariance Heatmap etof vs ion tof')\n",
    "        plt.ylabel('Ion tof')\n",
    "        plt.xlabel('Electron tof')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "def getBadPixelMask(avg_dark, dark_thr, std_dark, std_thr):\n",
    "    mask = np.ones_like(avg_dark)\n",
    "\n",
    "    mask[avg_dark>dark_thr]=0\n",
    "    mask[std_dark>std_thr]=0\n",
    "    mask[std_dark==0]=0\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "def correct_pnccd(pnccd, dark_pnccd):\n",
    "    'Correct pnccd using dark run pnccd input'\n",
    "    \n",
    "    avg_dark= dark_pnccd.mean(axis=0)\n",
    "    std_dark= dark_pnccd.std(axis=0)\n",
    "    \n",
    "    mask = getBadPixelMask(avg_dark, 60000, std_dark, 600)\n",
    "    \n",
    "    corr_pnccd = (pnccd - avg_dark)*mask\n",
    "    \n",
    "    pretty_pnccd = corr_pnccd.isel(dim_0=slice(412, 512), dim_1=slice(412, 612))\n",
    "    \n",
    "    return pretty_pnccd\n",
    "    \n",
    "    \n",
    "    \n",
    "def pnccd_image(corr_pnccd, trainId):\n",
    "    'Show pnccd image for given train id'\n",
    "    \n",
    "    image_data = corr_pnccd.sel(trainId=trainId).squeeze()\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image_data, vmin=10)\n",
    "    plt.title(f'PNCCD image of train {trainId}')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def integrate_pnccd(corr_pnccd, trainId, prnt=True):\n",
    "    'Integrate upper half of pnncd for given train id'\n",
    "    \n",
    "    image_data = corr_pnccd.sel(trainId=trainId).squeeze()\n",
    "    number = np.round(image_data.where(image_data > 10).sum().item())\n",
    "    \n",
    "    if prnt:\n",
    "        print(f'Integrating yields {number}')\n",
    "    else:\n",
    "        return number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22648dc",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e699e32",
   "metadata": {},
   "source": [
    "## Selections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d00f5f8",
   "metadata": {},
   "source": [
    "### with pnccd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b7d71",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "RUNID = [232,233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034220f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND1 = 100\n",
    "UPPER_BOUND1 = 500\n",
    "\n",
    "LOWER_BOUND2 = 500\n",
    "UPPER_BOUND2 = 1500\n",
    "\n",
    "LOWER_BOUND3 = 2000\n",
    "UPPER_BOUND3 = 5000\n",
    "\n",
    "THRESHOLDS = [(LOWER_BOUND1, UPPER_BOUND1), (LOWER_BOUND2, UPPER_BOUND2), (LOWER_BOUND3, UPPER_BOUND3)]\n",
    "\n",
    "selections = events_selection_plots(RUNID,THRESHOLDS)\n",
    "\n",
    "selected_dfevent1, selected_dfpulse1, selected_etof1, selected_pnccd1 = selections[0]\n",
    "selected_dfevent2, selected_dfpulse2, selected_etof2, selected_pnccd2 = selections[1]\n",
    "selected_dfevent3, selected_dfpulse3, selected_etof3, selected_pnccd3 = selections[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f732de",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND1 = 5000\n",
    "UPPER_BOUND1 = 8000\n",
    "\n",
    "LOWER_BOUND2 = 8000\n",
    "UPPER_BOUND2 = 12000\n",
    "\n",
    "LOWER_BOUND3 = 12000\n",
    "UPPER_BOUND3 = 20000\n",
    "\n",
    "THRESHOLDS = [(LOWER_BOUND1, UPPER_BOUND1), (LOWER_BOUND2, UPPER_BOUND2), (LOWER_BOUND3, UPPER_BOUND3)]\n",
    "\n",
    "selections = events_selection_plots(RUNID,THRESHOLDS)\n",
    "\n",
    "selected_dfevent4, selected_dfpulse4, selected_etof4, selected_pnccd4 = selections[0]\n",
    "selected_dfevent5, selected_dfpulse5, selected_etof5, selected_pnccd5 = selections[1]\n",
    "selected_dfevent6, selected_dfpulse6, selected_etof6, selected_pnccd6 = selections[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc0b66",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND = 500\n",
    "UPPER_BOUND = 5000\n",
    "THRESHOLD = [(LOWER_BOUND,UPPER_BOUND)]\n",
    "\n",
    "selections = events_selection_plots(RUNID,THRESHOLD)\n",
    "selected_dfevent, selected_dfpulse, selected_etof, selected_pnccd = selections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed218d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BACKGRD_BOUND = 20\n",
    "UPPER_BACKGRD_BOUND = 40\n",
    "BKGRD_THRESHOLD = [(LOWER_BACKGRD_BOUND,UPPER_BACKGRD_BOUND)]\n",
    "DOWNSAMPLING = 200000\n",
    "\n",
    "backgrd_dfevent, backgrd_dfpulse, backgrd_etof, backgrd_pnccd = events_selection(RUNID,BKGRD_THRESHOLD,DOWNSAMPLING)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065c04bc",
   "metadata": {},
   "source": [
    "### only ions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41374482",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dfevent_90, dfpulse_90 = read_ion(405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd55c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dfevent_33, dfpulse_33 = read_ion(411)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30808263",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dfevent, dfpulse = read_ion(413)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e4e02",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "lower_threshold, upper_threshold = 500, 8000\n",
    "\n",
    "selected_dfpulse = dfpulse[lower_threshold < dfpulse.nevents_pulse][dfpulse.nevents_pulse < upper_threshold]\n",
    "selected_dfevent = dfevent[dfevent.pulseId.isin(selected_dfpulse.pulseId)]\n",
    "\n",
    "selected_dfpulse_90 = dfpulse_90[lower_threshold < dfpulse_90.nevents_pulse][dfpulse_90.nevents_pulse < upper_threshold]\n",
    "selected_dfevent_90 = dfevent_90[dfevent_90.pulseId.isin(selected_dfpulse_90.pulseId)]\n",
    "\n",
    "selected_dfpulse_33 = dfpulse_33[lower_threshold < dfpulse_33.nevents_pulse][dfpulse_33.nevents_pulse < upper_threshold]\n",
    "selected_dfevent_33 = dfevent_33[dfevent_33.pulseId.isin(selected_dfpulse_33.pulseId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83ca72",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bounded_dfevent = selected_dfevent[selected_dfevent.tof < TIME_BETWEEN_PULSES]\n",
    "hist, bin_edges = np.histogram(bounded_dfevent.tof, bins=1000)\n",
    "\n",
    "bounded_dfevent_90 = selected_dfevent_90[selected_dfevent_90.tof < TIME_BETWEEN_PULSES]\n",
    "hist_90, bin_edges = np.histogram(bounded_dfevent_90.tof, bins=1000)\n",
    "\n",
    "bounded_dfevent_33 = selected_dfevent_33[selected_dfevent_33.tof < TIME_BETWEEN_PULSES]\n",
    "hist_33, bin_edges = np.histogram(bounded_dfevent_33.tof, bins=1000)   \n",
    " \n",
    "plt.figure()\n",
    "plt.plot(bin_edges[:-1], hist/max(hist), label='EtOH background')\n",
    "plt.plot(bin_edges[:-1], hist_90/max(hist_90), label='90% EtOH')\n",
    "plt.plot(bin_edges[:-1], hist_33/max(hist_33), label='33% EtOH')\n",
    "plt.xlabel('Time of flight (s)')\n",
    "plt.ylabel('Number of hits per bin')\n",
    "plt.title('Ions time of flight')\n",
    "# plt.xlim(0,TIME_BETWEEN_PULSES)\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89599a30",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 7594V 500nm\n",
    "RUNIDstretch = [376,380,382,383,384,386,387,388,389,390,391,393,398,399,400,402,403,404]\n",
    "# 5400V\n",
    "# 500nm\n",
    "RUNID500 = [232,233,313,315,316,317,318,319,320,321,322,325,326,327,328,329,331,332,333,336,337,338,339,340,341,342,343,345,347,348,349]\n",
    "# 300nm\n",
    "RUNID300 = [195,196,197,198,199,200,201,202,203,205,206,207,208,213,214,215,216,217,218,219,220,221,222,223,224,225,226]\n",
    "# 100nm\n",
    "RUNID100 = [293,294,296,297,298,299,300,301,302,303,304,306,307,308,309]\n",
    "# core shell\n",
    "RUNIDcoreshell = [227,228,229,273,274,275,276,277,278,279,280,282,283,284,285,286,287]\n",
    "# water\n",
    "RUNIDwater = [211]\n",
    "# alcohol\n",
    "RUNIDstrongalcohol = [405,406,407]\n",
    "RUNIDweakalcohol = [409,411,412,413]\n",
    "# photon energy\n",
    "RUNIDphotonenergy = [440,441,441,442,443,444,445,446,447,448,449,450,451]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8851093",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND1 = 100\n",
    "UPPER_BOUND1 = 500\n",
    "\n",
    "LOWER_BOUND2 = 500\n",
    "UPPER_BOUND2 = 1500\n",
    "\n",
    "LOWER_BOUND3 = 2000\n",
    "UPPER_BOUND3 = 5000\n",
    "\n",
    "THRESHOLDS = [(LOWER_BOUND1, UPPER_BOUND1), (LOWER_BOUND2, UPPER_BOUND2), (LOWER_BOUND3, UPPER_BOUND3)]\n",
    "\n",
    "ion_selections = ion_selection(RUNID500,THRESHOLDS)\n",
    "\n",
    "ion_dfevent1, ion_dfpulse1 = ion_selections[0]\n",
    "ion_dfevent2, ion_dfpulse2 = ion_selections[1]\n",
    "ion_dfevent3, ion_dfpulse3 = ion_selections[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3839e643",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND1 = 5000\n",
    "UPPER_BOUND1 = 8000\n",
    "\n",
    "LOWER_BOUND2 = 8000\n",
    "UPPER_BOUND2 = 12000\n",
    "\n",
    "LOWER_BOUND3 = 12000\n",
    "UPPER_BOUND3 = 20000\n",
    "\n",
    "THRESHOLDS = [(LOWER_BOUND1, UPPER_BOUND1), (LOWER_BOUND2, UPPER_BOUND2), (LOWER_BOUND3, UPPER_BOUND3)]\n",
    "\n",
    "ion_selections = ion_selection(RUNID,THRESHOLDS)\n",
    "\n",
    "ion_dfevent4, ion_dfpulse4 = ion_selections[0]\n",
    "ion_dfevent5, ion_dfpulse5 = ion_selections[1]\n",
    "ion_dfevent6, ion_dfpulse6 = ion_selections[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec288e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND = 500\n",
    "UPPER_BOUND = 10000\n",
    "THRESHOLD = [(LOWER_BOUND,UPPER_BOUND)]\n",
    "\n",
    "ion_dfevent500, ion_dfpulse500 = ion_selection(RUNID500,THRESHOLD)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886e220",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND = 500\n",
    "UPPER_BOUND = 10000\n",
    "THRESHOLD = [(LOWER_BOUND,UPPER_BOUND)]\n",
    "\n",
    "ion_dfevent500, ion_dfpulse500 = ion_selection(RUNID500,THRESHOLD)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95680c81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND = 500\n",
    "UPPER_BOUND = 10000\n",
    "THRESHOLD = [(LOWER_BOUND,UPPER_BOUND)]\n",
    "\n",
    "ion_dfevent300, ion_dfpulse300 = ion_selection(RUNID300,THRESHOLD)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eedb54",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND = 500\n",
    "UPPER_BOUND = 5000\n",
    "THRESHOLD = [(LOWER_BOUND,UPPER_BOUND)]\n",
    "\n",
    "ion_dfevent100, ion_dfpulse100 = ion_selection(RUNID100,THRESHOLD)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594530c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND = 500\n",
    "UPPER_BOUND = 5000\n",
    "THRESHOLD = [(LOWER_BOUND,UPPER_BOUND)]\n",
    "\n",
    "ion_dfevent_strongalcohol, ion_dfpulse_strongalcohol = ion_selection(RUNIDstrongalcohol,THRESHOLD)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1fcd6f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND = 500\n",
    "UPPER_BOUND = 5000\n",
    "THRESHOLD = [(LOWER_BOUND,UPPER_BOUND)]\n",
    "\n",
    "ion_dfevent_weakalcohol, ion_dfpulse_weakalcohol = ion_selection(RUNIDweakalcohol,THRESHOLD)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53ee88",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND = 2500\n",
    "UPPER_BOUND = 3000\n",
    "THRESHOLD = [(LOWER_BOUND,UPPER_BOUND)]\n",
    "\n",
    "newion_dfevent300, newion_dfpulse300 = ion_selection(RUNID300,THRESHOLD)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce181c55",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LOWER_BOUND1 = 1000\n",
    "UPPER_BOUND1 = 1500\n",
    "\n",
    "LOWER_BOUND2 = 1500\n",
    "UPPER_BOUND2 = 2000\n",
    "\n",
    "LOWER_BOUND3 = 2000\n",
    "UPPER_BOUND3 = 2500\n",
    "\n",
    "THRESHOLDS = [(LOWER_BOUND1, UPPER_BOUND1), (LOWER_BOUND2, UPPER_BOUND2), (LOWER_BOUND3, UPPER_BOUND3)]\n",
    "\n",
    "ion_selections = ion_selection(RUNID300,THRESHOLDS)\n",
    "\n",
    "ion_dfevent1, ion_dfpulse1 = ion_selections[0]\n",
    "ion_dfevent2, ion_dfpulse2 = ion_selections[1]\n",
    "ion_dfevent3, ion_dfpulse3 = ion_selections[2]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
